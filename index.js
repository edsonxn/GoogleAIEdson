import 'dotenv/config';
import express from 'express';
import cors from 'cors';
import bodyParser from 'body-parser';
import { GoogleGenAI, Modality } from "@google/genai";
import OpenAI from 'openai';
import wav from 'wav';
import fs from 'fs';
import path from 'path';
import fetch from 'node-fetch';
import ApplioClient from "./applio-client.js";
import { transcribeAudio, getAudioTracks } from "./transcriber.js";
import multer from 'multer';
import axios from 'axios';
import * as cheerio from 'cheerio';
import ffmpeg from 'fluent-ffmpeg';
import { spawn } from 'child_process';
import { createCanvas, loadImage } from 'canvas';

const app = express();
const PORT = 3000;

// Configurar cliente Applio
const applioClient = new ApplioClient();

app.use(cors());
app.use(bodyParser.json({ limit: '50mb' })); // Aumentar l√≠mite para payloads grandes
app.use(bodyParser.urlencoded({ limit: '50mb', extended: true })); // Para formularios grandes
app.use(express.static('public')); // Servir HTML y assets

// Configurar multer para subida de archivos
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    const tempDir = './temp';
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    cb(null, tempDir);
  },
  filename: function (req, file, cb) {
    cb(null, Date.now() + '_' + file.originalname);
  }
});

const upload = multer({ 
  storage: storage,
  limits: {
    fileSize: 5 * 1024 * 1024 * 1024 // 5GB m√°ximo para videos grandes
  },
  fileFilter: function (req, file, cb) {
    const allowedTypes = ['audio/mp3', 'audio/wav', 'audio/mpeg', 'audio/m4a', 'video/mp4'];
    const allowedExtensions = ['.mp3', '.wav', '.m4a', '.mp4'];
    
    const isValidType = allowedTypes.includes(file.mimetype) || 
                       allowedExtensions.some(ext => file.originalname.toLowerCase().endsWith(ext));
    
    if (isValidType) {
      cb(null, true);
    } else {
      cb(new Error('Formato de archivo no soportado'));
    }
  }
});

const ai = new GoogleGenAI({
  apiKey: process.env.GOOGLE_API_KEY,
});

// Configurar cliente OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// Almac√©n de conversaciones en memoria (historial por proyecto)
const conversationStore = new Map();

// Funci√≥n helper para retry autom√°tico con Google AI
async function generateContentWithRetry(ai, params, maxRetries = 3, delay = 2000) {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      console.log(`ü§ñ Intento ${attempt}/${maxRetries} de generar contenido...`);
      const response = await ai.models.generateContent(params);
      console.log(`‚úÖ Contenido generado exitosamente en el intento ${attempt}`);
      return response;
    } catch (error) {
      console.error(`‚ùå Error en intento ${attempt}/${maxRetries}:`, error.message);
      
      if (error.status === 503 && attempt < maxRetries) {
        console.log(`‚è≥ Esperando ${delay}ms antes del siguiente intento...`);
        await new Promise(resolve => setTimeout(resolve, delay));
        delay *= 1.5; // Incrementar delay exponencialmente
      } else {
        throw error; // Si no es error 503 o es el √∫ltimo intento, lanzar error
      }
    }
  }
}

// Funci√≥n universal para generar contenido con m√∫ltiples proveedores LLM
async function generateUniversalContent(model, promptOrHistory, systemInstruction = null, maxRetries = 3) {
  console.log(`ü§ñ Generando contenido con modelo: ${model}`);
  
  // Determinar el proveedor basado en el modelo
  const isOpenAI = model.includes('gpt') || model.includes('openai');
  const isGoogle = model.includes('gemini') || model.includes('google');
  
  console.log(`üîç Proveedor detectado: ${isOpenAI ? 'OpenAI' : 'Google AI'} para modelo "${model}"`);
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      console.log(`üîÑ Intento ${attempt}/${maxRetries} con ${isOpenAI ? 'OpenAI' : 'Google AI'}...`);
      
      if (isOpenAI) {
        // Usar OpenAI
        const messages = [];
        
        if (systemInstruction) {
          messages.push({
            role: "system",
            content: systemInstruction
          });
        }
        
        // Si promptOrHistory es un array (historial de conversaci√≥n)
        if (Array.isArray(promptOrHistory)) {
          // OPTIMIZACI√ìN PARA OPENAI: Solo usar los √∫ltimos 2 mensajes para ahorrar tokens
          const recentHistory = promptOrHistory.slice(-2);
          console.log(`üîÑ OPTIMIZACI√ìN OpenAI - Usando solo los √∫ltimos ${recentHistory.length} mensajes de ${promptOrHistory.length} total`);
          
          recentHistory.forEach(h => {
            if (h.role === 'user') {
              messages.push({
                role: "user",
                content: h.parts[0].text
              });
            } else if (h.role === 'model') {
              messages.push({
                role: "assistant", 
                content: h.parts[0].text
              });
            }
          });
        } else {
          // Si es un string simple
          messages.push({
            role: "user", 
            content: promptOrHistory
          });
        }
        
        // Configurar par√°metros seg√∫n el modelo
        const requestConfig = {
          model: model,
          messages: messages
        };
        
        // NO configurar max_completion_tokens - usar l√≠mites por defecto como Gemini
        // Esto permite m√°xima memoria disponible para cada modelo
        
        // Solo agregar temperature si NO es un modelo GPT-5 (todos los GPT-5 solo soportan valor por defecto)
        if (!model.startsWith('gpt-5')) {
          requestConfig.temperature = 0.7;
        }
        
        const response = await openai.chat.completions.create(requestConfig);
        
        console.log(`‚úÖ Contenido generado exitosamente con OpenAI en intento ${attempt}`);
        return {
          text: response.choices[0].message.content
        };
        
      } else {
        // Usar Google AI (comportamiento existente)
        const params = {
          model: `models/${model}`
        };
        
        // Si promptOrHistory es un array (historial de conversaci√≥n)
        if (Array.isArray(promptOrHistory)) {
          params.contents = promptOrHistory;
        } else {
          params.contents = promptOrHistory;
        }
        
        if (systemInstruction) {
          params.config = { systemInstruction };
        }
        
        const response = await ai.models.generateContent(params);
        console.log(`‚úÖ Contenido generado exitosamente con Google AI en intento ${attempt}`);
        return response;
      }
      
    } catch (error) {
      console.error(`‚ùå Error en intento ${attempt}/${maxRetries}:`, error.message);
      
      const isRetryableError = (isOpenAI && error.status >= 500) || 
                              (!isOpenAI && error.status === 503);
      
      if (isRetryableError && attempt < maxRetries) {
        const delay = 2000 * Math.pow(1.5, attempt - 1);
        console.log(`‚è≥ Esperando ${delay}ms antes del siguiente intento...`);
        await new Promise(resolve => setTimeout(resolve, delay));
      } else {
        throw error;
      }
    }
  }
}

// Funci√≥n para optimizar historial manteniendo continuidad narrativa
function optimizeConversationHistory(conversation) {
  const historialAntes = conversation.history.length;
  
  // No optimizar si el historial es peque√±o
  if (historialAntes <= 6) {
    return;
  }
  
  console.log(`üß† OPTIMIZACI√ìN INTELIGENTE - Manteniendo continuidad narrativa...`);
  
  if (historialAntes > 8) {
    // Para series largas: mantener contexto inicial + contexto reciente
    const contextoInicial = conversation.history.slice(0, 2); // Primer cap√≠tulo
    const contextoReciente = conversation.history.slice(-6);   // √öltimos 3 cap√≠tulos
    
    conversation.history = [...contextoInicial, ...contextoReciente];
    
    console.log(`üîÑ OPTIMIZACI√ìN - Historial reestructurado de ${historialAntes} a ${conversation.history.length} mensajes`);
    console.log(`üìö ESTRATEGIA - Manteniendo: cap√≠tulo inicial (contexto base) + √∫ltimos 3 cap√≠tulos (continuidad)`);
  } else {
    // Para series medianas: mantener √∫ltimos 3 cap√≠tulos
    conversation.history = conversation.history.slice(-6);
    console.log(`üîÑ OPTIMIZACI√ìN - Historial reducido de ${historialAntes} a ${conversation.history.length} mensajes (√∫ltimos 3 cap√≠tulos)`);
  }
  
  console.log(`üí∞ AHORRO DE TOKENS - Eliminados ${historialAntes - conversation.history.length} mensajes intermedios`);
}

// Funci√≥n para estimar tokens aproximadamente (1 token ‚âà 4 caracteres en espa√±ol)
function estimateTokens(text) {
  if (!text || typeof text !== 'string') return 0;
  return Math.ceil(text.length / 4);
}

// Funci√≥n para obtener o crear una conversaci√≥n
function getOrCreateConversation(projectKey) {
  if (!conversationStore.has(projectKey)) {
    conversationStore.set(projectKey, {
      history: [],
      topic: '',
      totalSections: 0,
      currentSection: 0,
      chapterStructure: [],
      createdAt: Date.now()
    });
  }
  return conversationStore.get(projectKey);
}

// Funci√≥n para limpiar conversaciones antiguas (m√°s de 24 horas)
function cleanOldConversations() {
  const now = Date.now();
  const oneDayInMs = 24 * 60 * 60 * 1000;
  
  for (const [key, conversation] of conversationStore.entries()) {
    if (now - conversation.createdAt > oneDayInMs) {
      conversationStore.delete(key);
    }
  }
}

// Funci√≥n para obtener las voces disponibles de Applio
function getAvailableVoices() {
  try {
    const voicesPath = path.join('C:', 'applio2', 'Applio', 'logs', 'VOCES');
    console.log(`üîç Buscando voces en: ${voicesPath}`);
    
    if (!fs.existsSync(voicesPath)) {
      console.warn(`‚ö†Ô∏è Carpeta de voces no encontrada: ${voicesPath}`);
      return [{
        name: 'RemyOriginal (Default)',
        path: 'logs\\VOCES\\RemyOriginal.pth',
        displayName: 'RemyOriginal'
      }];
    }
    
    const files = fs.readdirSync(voicesPath);
    const voiceFiles = files.filter(file => file.endsWith('.pth'));
    
    console.log(`üìÇ Archivos .pth encontrados: ${voiceFiles.length}`);
    
    const voices = voiceFiles.map(file => {
      const baseName = path.basename(file, '.pth');
      return {
        name: baseName,
        path: `logs\\VOCES\\${file}`,
        displayName: baseName
      };
    });
    
    // Si no hay voces, agregar la por defecto
    if (voices.length === 0) {
      voices.push({
        name: 'RemyOriginal (Default)',
        path: 'logs\\VOCES\\RemyOriginal.pth',
        displayName: 'RemyOriginal'
      });
    }
    
    console.log(`‚úÖ Voces disponibles: ${voices.map(v => v.displayName).join(', ')}`);
    return voices;
    
  } catch (error) {
    console.error('‚ùå Error leyendo voces:', error);
    return [{
      name: 'RemyOriginal (Default)',
      path: 'logs\\VOCES\\RemyOriginal.pth',
      displayName: 'RemyOriginal'
    }];
  }
}

// Estilos predeterminados de miniatura
const defaultThumbnailStyles = {
  'default': {
    name: 'Amarillo y Blanco (Predeterminado)',
    description: 'Estilo cl√°sico con texto amarillo y blanco',
    primaryColor: 'amarillo',
    secondaryColor: 'blanco',
    instructions: 'El texto que se muestre debe de tener 2 colores, letras llamativas y brillosas con efecto luminoso, la frase menos importante de color blanco, la frase importante color amarillo, todo con contorno negro, letras brillosas con resplandor'
  },
  'gaming_red': {
    name: 'Rojo Gaming',
    description: 'Estilo gaming agresivo con rojos brillantes',
    primaryColor: 'rojo brillante',
    secondaryColor: 'blanco',
    instructions: 'El texto debe tener un estilo gaming agresivo con la frase principal en rojo brillante intenso y la secundaria en blanco, ambas con contorno negro grueso y efecto de resplandor rojo'
  },
  'neon_blue': {
    name: 'Azul Ne√≥n',
    description: 'Estilo futurista con azul ne√≥n y efectos cyberpunk',
    primaryColor: 'azul ne√≥n',
    secondaryColor: 'cyan claro',
    instructions: 'El texto debe tener un estilo futurista cyberpunk con la frase principal en azul ne√≥n brillante y la secundaria en cyan claro, con contorno oscuro y efectos de resplandor azul ne√≥n'
  },
  'retro_purple': {
    name: 'P√∫rpura Retro',
    description: 'Estilo retro gaming con p√∫rpura y rosa',
    primaryColor: 'p√∫rpura brillante',
    secondaryColor: 'rosa',
    instructions: 'El texto debe tener un estilo retro gaming de los 80s con la frase principal en p√∫rpura brillante y la secundaria en rosa, con contorno negro y efectos de resplandor p√∫rpura'
  }
};

// Funci√≥n para obtener instrucciones de estilo de miniatura
function getThumbnailStyleInstructions(styleId) {
  // Si es un estilo personalizado (enviado desde el frontend)
  if (typeof styleId === 'object' && styleId) {
    // Construir instrucciones completas usando los colores espec√≠ficos
    const primaryColor = styleId.primaryColor || 'amarillo';
    const secondaryColor = styleId.secondaryColor || 'blanco';
    const customInstructions = styleId.instructions || '';
    
    const fullInstructions = `El texto debe tener la frase principal en color ${primaryColor} brillante y la frase secundaria en color ${secondaryColor}, ambas con contorno negro grueso, letras brillosas con efecto luminoso y resplandor. Estilo visual: ${customInstructions}`;
    
    return fullInstructions;
  }
  
  // Si es un estilo predeterminado
  if (typeof styleId === 'string' && defaultThumbnailStyles[styleId]) {
    return defaultThumbnailStyles[styleId].instructions;
  }
  
  // Fallback al estilo predeterminado
  return defaultThumbnailStyles.default.instructions;
}

// Limpiar conversaciones antiguas cada hora
setInterval(cleanOldConversations, 60 * 60 * 1000);

// ================================
// SISTEMA DE GUARDADO Y CARGA DE PROYECTOS
// ================================

// Funci√≥n para guardar el estado completo del proyecto
function saveProjectState(projectData) {
  try {
    const { 
      topic, 
      folderName, 
      totalSections, 
      currentSection, 
      voice, 
      imageModel, 
      scriptStyle, 
      customStyleInstructions,
      promptModifier,
      imageCount,
      skipImages,
      googleImages,
      applioVoice
    } = projectData;
    
    const safeFolderName = folderName && folderName.trim() 
      ? createSafeFolderName(folderName.trim())
      : createSafeFolderName(topic);
    
    const outputsDir = path.join('./public/outputs');
    const projectDir = path.join(outputsDir, safeFolderName);
    
    // Crear carpetas si no existen
    if (!fs.existsSync(outputsDir)) {
      fs.mkdirSync(outputsDir, { recursive: true });
    }
    if (!fs.existsSync(projectDir)) {
      fs.mkdirSync(projectDir, { recursive: true });
    }
    
    const projectStateFile = path.join(projectDir, 'project_state.json');
    
    const projectState = {
      topic,
      folderName: safeFolderName,
      originalFolderName: folderName,
      totalSections,
      currentSection,
      voice,
      imageModel,
      scriptStyle,
      customStyleInstructions,
      promptModifier: promptModifier || '',
      imageCount: imageCount || 3,
      skipImages: skipImages || false,
      googleImages: googleImages || false,
      applioVoice: applioVoice || 'logs\\VOCES\\RemyOriginal.pth',
      createdAt: new Date().toISOString(),
      lastModified: new Date().toISOString(),
      completedSections: []
    };
    
    // Si ya existe un archivo de estado, preservar secciones completadas
    if (fs.existsSync(projectStateFile)) {
      const existingState = JSON.parse(fs.readFileSync(projectStateFile, 'utf8'));
      projectState.completedSections = existingState.completedSections || [];
      projectState.createdAt = existingState.createdAt || projectState.createdAt;
    }
    
    fs.writeFileSync(projectStateFile, JSON.stringify(projectState, null, 2), 'utf8');
    console.log(`üíæ Estado del proyecto guardado: ${projectStateFile}`);
    
    return projectState;
  } catch (error) {
    console.error('‚ùå Error guardando estado del proyecto:', error);
    return null;
  }
}

// Funci√≥n para generar metadatos de YouTube autom√°ticamente para un proyecto completo
async function generateYouTubeMetadataForProject(projectState) {
  try {
    console.log(`üé¨ Iniciando generaci√≥n autom√°tica de metadatos para: ${projectState.topic}`);
    
    const safeFolderName = projectState.folderName;
    const projectDir = path.join('./public/outputs', safeFolderName);
    const projectStateFile = path.join(projectDir, 'project_state.json');
    
    // Recopilar todos los scripts de las secciones completadas
    const allSections = [];
    for (const section of projectState.completedSections.sort((a, b) => a.section - b.section)) {
      if (section.script) {
        allSections.push(section.script);
      }
    }
    
    if (allSections.length === 0) {
      console.log(`‚ö†Ô∏è No hay secciones con script para generar metadatos`);
      return;
    }
    
    console.log(`üìù Generando metadatos con ${allSections.length} secciones`);
    
    // Combinar todas las secciones
    const fullScript = allSections.join('\n\n--- SECCI√ìN ---\n\n');
    
    // Obtener instrucciones de estilo de miniatura (usar default si no est√° especificado)
    const thumbnailStyle = projectState.thumbnailStyle || 'default';
    const thumbnailInstructions = getThumbnailStyleInstructions(thumbnailStyle);
    
    console.log(`üé® Usando estilo de miniatura: ${thumbnailStyle}`);
    
    // Generar prompt para metadatos
    const prompt = `
Bas√°ndote en el siguiente tema y gui√≥n completo del video, genera metadata optimizada para YouTube:

**TEMA:** ${projectState.topic}

**GUI√ìN COMPLETO:**
${fullScript}

Por favor genera:

1. **10 T√çTULOS CLICKBAIT** (cada uno en una l√≠nea, numerados):
   - Usa palabras que generen curiosidad como "QUE PASA CUANDO", "POR QUE", "HICE ESTO Y PASO ESTO", "NO VAS A CREER", "ESTO CAMBI√ì TODO"
   - Que sean pol√©micos pero relacionados al contenido
   - maximo 15 palabras, minimo 10.

2. **DESCRIPCI√ìN PARA VIDEO** (optimizada para SEO):
   - Entre 150-300 palabras
   - Incluye palabras clave relevantes del tema
   - Menciona el contenido principal del video
   - Incluye call-to-action para suscribirse
   - Formato atractivo con emojis

3. **25 ETIQUETAS** (separadas por comas):
   - Palabras clave relacionadas al tema
   - Tags populares del nicho correspondiente
   - T√©rminos de b√∫squeda relevantes
   - Sin espacios en tags compuestos (usar guiones o camelCase)

4. **5 PROMPTS PARA MINIATURAS DE YOUTUBE** (cada uno en una l√≠nea, numerados):
   
   FORMATO OBLIGATORIO - DEBES SEGUIR ESTA ESTRUCTURA EXACTA PARA CADA UNO DE LOS 5 PROMPTS:
   
   "Miniatura de YouTube 16:9 mostrando [descripci√≥n visual muy detallada del contenido relacionado al tema, m√≠nimo 15 palabras] con texto superpuesto '[frase clickbait espec√≠fica relacionada al contenido]' con el texto aplicando el siguiente estilo: ${thumbnailInstructions}"
   
   REGLAS ESTRICTAS - NO GENERAR PROMPTS CORTOS O INCOMPLETOS:
   - CADA prompt debe tener m√≠nimo 25 palabras de descripci√≥n visual
   - CADA prompt debe incluir una frase clickbait espec√≠fica entre comillas
   - CADA prompt debe terminar con la frase completa del estilo
   - NO generar prompts como "el texto con contorno negro" - ESO EST√Å PROHIBIDO
   - TODOS los prompts deben seguir el formato completo

REGLAS ESTRICTAS:
- EXACTAMENTE 5 prompts numerados del 1 al 5
- Cada prompt debe incluir la frase completa del estilo al final
- NO hacer referencias a estilos anteriores
`;

    // Validar que la API key est√© disponible
    if (!process.env.GOOGLE_API_KEY) {
      throw new Error('GOOGLE_API_KEY no est√° configurada en las variables de entorno');
    }

    // Llamar a la IA para generar metadatos
    const genAI = new GoogleGenAI({
      apiKey: process.env.GOOGLE_API_KEY
    });
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });
    
    console.log(`ü§ñ Enviando request a Gemini para generar metadatos...`);
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const generatedMetadata = response.text();
    
    console.log(`‚úÖ Metadatos generados exitosamente`);
    
    // Guardar metadatos en archivo separado
    const metadataFile = path.join(projectDir, `${safeFolderName}_youtube_metadata.txt`);
    const metadataContent = `METADATA DE YOUTUBE PARA: ${projectState.topic}
Generado autom√°ticamente: ${new Date().toLocaleString()}
Proyecto: ${projectState.originalFolderName || projectState.topic}
Secciones: ${projectState.completedSections.length}/${projectState.totalSections}

====================================

${generatedMetadata}

====================================
GUI√ìN COMPLETO UTILIZADO:
====================================

${fullScript}`;
    
    fs.writeFileSync(metadataFile, metadataContent, 'utf8');
    console.log(`üíæ Metadatos guardados en: ${metadataFile}`);
    
    // Actualizar estado del proyecto con los metadatos
    const updatedProjectState = JSON.parse(fs.readFileSync(projectStateFile, 'utf8'));
    updatedProjectState.youtubeMetadata = {
      generatedAt: new Date().toISOString(),
      content: generatedMetadata,
      thumbnailStyle: thumbnailStyle,
      filename: `${safeFolderName}_youtube_metadata.txt`
    };
    updatedProjectState.lastModified = new Date().toISOString();
    
    fs.writeFileSync(projectStateFile, JSON.stringify(updatedProjectState, null, 2), 'utf8');
    
    console.log(`üé¨ ¬°Metadatos de YouTube generados autom√°ticamente para el proyecto completado!`);
    
    return updatedProjectState;
    
  } catch (error) {
    console.error(`‚ùå Error generando metadatos autom√°ticos:`, error);
    throw error;
  }
}

// Funci√≥n para actualizar secci√≥n completada
function updateCompletedSection(projectData, sectionNumber, sectionData) {
  try {
    const { topic, folderName } = projectData;
    
    const safeFolderName = folderName && folderName.trim() 
      ? createSafeFolderName(folderName.trim())
      : createSafeFolderName(topic);
    
    const projectStateFile = path.join('./public/outputs', safeFolderName, 'project_state.json');
    
    if (fs.existsSync(projectStateFile)) {
      const projectState = JSON.parse(fs.readFileSync(projectStateFile, 'utf8'));
      
      // Actualizar o agregar secci√≥n completada
      const existingSectionIndex = projectState.completedSections.findIndex(s => s.section === sectionNumber);
      
      const sectionInfo = {
        section: sectionNumber,
        script: sectionData.script,
        imageCount: sectionData.images ? sectionData.images.length : 0,
        hasImages: !sectionData.imagesSkipped && !sectionData.googleImagesMode,
        googleImagesMode: sectionData.googleImagesMode || false,
        imagesSkipped: sectionData.imagesSkipped || false,
        imagePrompts: sectionData.imagePrompts || [],
        completedAt: new Date().toISOString(),
        scriptFile: sectionData.scriptFile,
        promptsFile: sectionData.promptsFile
      };
      
      if (existingSectionIndex >= 0) {
        projectState.completedSections[existingSectionIndex] = sectionInfo;
      } else {
        projectState.completedSections.push(sectionInfo);
      }
      
      // Ordenar secciones por n√∫mero
      projectState.completedSections.sort((a, b) => a.section - b.section);
      
      projectState.lastModified = new Date().toISOString();
      projectState.currentSection = Math.max(projectState.currentSection, sectionNumber);
      
      fs.writeFileSync(projectStateFile, JSON.stringify(projectState, null, 2), 'utf8');
      console.log(`‚úÖ Secci√≥n ${sectionNumber} marcada como completada en el proyecto`);
      
      // üé¨ VERIFICAR SI EL PROYECTO EST√Å COMPLETO Y GENERAR METADATOS DE YOUTUBE
      const isProjectComplete = projectState.completedSections.length >= projectState.totalSections;
      console.log(`üìä Progreso del proyecto: ${projectState.completedSections.length}/${projectState.totalSections} - Completo: ${isProjectComplete}`);
      
      if (isProjectComplete && !projectState.youtubeMetadata) {
        console.log(`üé¨ ¬°Proyecto completo! Generando metadatos de YouTube autom√°ticamente...`);
        
        // Generar metadatos autom√°ticamente en background
        setTimeout(() => {
          generateYouTubeMetadataForProject(projectState).catch(error => {
            console.error('‚ùå Error generando metadatos autom√°ticos:', error);
          });
        }, 1000); // Peque√±o delay para que la respuesta HTTP se complete primero
      }
      
      return projectState;
    }
    
    return null;
  } catch (error) {
    console.error('‚ùå Error actualizando secci√≥n completada:', error);
    return null;
  }
}

// Funci√≥n para obtener lista de proyectos disponibles
function getAvailableProjects() {
  try {
    const outputsDir = path.join('./public/outputs');
    
    if (!fs.existsSync(outputsDir)) {
      return [];
    }
    
    const projects = [];
    const folders = fs.readdirSync(outputsDir);
    
    for (const folder of folders) {
      const projectDir = path.join(outputsDir, folder);
      const projectStateFile = path.join(projectDir, 'project_state.json');
      
      if (fs.existsSync(projectStateFile) && fs.statSync(projectDir).isDirectory()) {
        try {
          const projectState = JSON.parse(fs.readFileSync(projectStateFile, 'utf8'));
          projects.push({
            ...projectState,
            folderPath: folder,
            sectionsCompleted: projectState.completedSections.length,
            lastModifiedDate: new Date(projectState.lastModified).toLocaleString()
          });
        } catch (parseError) {
          console.warn(`‚ö†Ô∏è Error leyendo proyecto ${folder}:`, parseError);
        }
      }
    }
    
    console.log(`üìä Total proyectos v√°lidos: ${projects.length}`);
    
    // Ordenar por √∫ltima modificaci√≥n (m√°s recientes primero)
    projects.sort((a, b) => new Date(b.lastModified) - new Date(a.lastModified));
    
    return projects;
  } catch (error) {
    console.error('‚ùå Error obteniendo proyectos disponibles:', error);
    return [];
  }
}

// Funci√≥n para cargar estado completo de un proyecto
function loadProjectState(folderName) {
  try {
    const projectStateFile = path.join('./public/outputs', folderName, 'project_state.json');
    
    if (!fs.existsSync(projectStateFile)) {
      return null;
    }
    
    const projectState = JSON.parse(fs.readFileSync(projectStateFile, 'utf8'));
    
    // Cargar datos adicionales de cada secci√≥n completada
    for (const section of projectState.completedSections) {
      const sectionDir = path.join('./public/outputs', folderName, `seccion_${section.section}`);
      
      // Verificar si existen las im√°genes
      if (section.hasImages && fs.existsSync(sectionDir)) {
        const imageFiles = fs.readdirSync(sectionDir).filter(file => 
          file.endsWith('.png') || file.endsWith('.jpg') || file.endsWith('.jpeg')
        );
        section.imageFiles = imageFiles.map(file => `outputs/${folderName}/seccion_${section.section}/${file}`);
      }
    }
    
    // üé¨ CARGAR METADATOS DE YOUTUBE SI EXISTEN
    const metadataFile = path.join('./public/outputs', folderName, `${folderName}_youtube_metadata.txt`);
    if (fs.existsSync(metadataFile)) {
      try {
        const metadataContent = fs.readFileSync(metadataFile, 'utf8');
        console.log(`üìΩÔ∏è Metadatos de YouTube encontrados para ${folderName}`);
        
        // Si no hay metadatos en el estado pero s√≠ en archivo, agregarlos
        if (!projectState.youtubeMetadata) {
          projectState.youtubeMetadata = {
            generatedAt: fs.statSync(metadataFile).mtime.toISOString(),
            content: metadataContent,
            filename: `${folderName}_youtube_metadata.txt`,
            fileExists: true
          };
          
          console.log(`‚úÖ Metadatos cargados desde archivo para proyecto ${folderName}`);
        } else {
          // Asegurar que el flag de archivo existe est√© presente
          projectState.youtubeMetadata.fileExists = true;
        }
      } catch (error) {
        console.error(`‚ùå Error cargando metadatos de YouTube:`, error);
      }
    }
    
    return projectState;
  } catch (error) {
    console.error('‚ùå Error cargando estado del proyecto:', error);
    return null;
  }
}

// Funci√≥n para crear nombre de carpeta seguro basado en el tema
function createSafeFolderName(topic) {
  return topic
    .toLowerCase()
    .replace(/[^a-z0-9\s]/g, '') // Remover caracteres especiales
    .replace(/\s+/g, '_') // Reemplazar espacios con guiones bajos
    .substring(0, 50); // Limitar longitud
}

// Funci√≥n para limpiar el texto del gui√≥n de contenido no deseado
function cleanScriptText(text) {
  // Validar que text sea una string
  if (!text || typeof text !== 'string') {
    console.log(`‚ö†Ô∏è WARNING - cleanScriptText recibi√≥:`, typeof text, text);
    return String(text || '').trim();
  }
  
  let cleanText = text.trim();
  
  // Remover patrones comunes de texto no deseado
  const unwantedPatterns = [
    /^Secci√≥n \d+:/gi,
    /^Gui√≥n:/gi,
    /^Texto del gui√≥n:/gi,
    /^Contenido:/gi,
    /^\*\*Secci√≥n \d+\*\*/gi,
    /^\# Secci√≥n \d+/gi,
    /^---+/g,
    /^\*\*Gui√≥n para TTS:\*\*/gi,
    /^\*\*Respuesta:\*\*/gi,
    /^Aqu√≠ est√° el gui√≥n:/gi,
    /^El gui√≥n para la secci√≥n \d+ es:/gi,
  ];
  
  // Aplicar limpieza de patrones
  unwantedPatterns.forEach(pattern => {
    cleanText = cleanText.replace(pattern, '').trim();
  });
  
  // Remover l√≠neas que parezcan comentarios o explicaciones
  const lines = cleanText.split('\n');
  const filteredLines = lines.filter(line => {
    const trimmedLine = line.trim();
    // Filtrar l√≠neas que parezcan comentarios o explicaciones
    return !trimmedLine.startsWith('*') && 
           !trimmedLine.startsWith('#') && 
           !trimmedLine.startsWith('//') &&
           !trimmedLine.startsWith('Nota:') &&
           !trimmedLine.startsWith('Aclaraci√≥n:') &&
           trimmedLine.length > 0;
  });
  
  return filteredLines.join('\n').trim();
}

// Funci√≥n para crear estructura de carpetas
function createProjectStructure(topic, section, customFolderName = null) {
  // Usar nombre personalizado si se proporciona, sino usar el tema
  const folderName = customFolderName && customFolderName.trim() 
    ? createSafeFolderName(customFolderName.trim())
    : createSafeFolderName(topic);
    
  const outputsDir = path.join('./public/outputs');
  const projectDir = path.join(outputsDir, folderName);
  const sectionDir = path.join(projectDir, `seccion_${section}`);
  
  // Crear todas las carpetas necesarias
  if (!fs.existsSync(outputsDir)) {
    fs.mkdirSync(outputsDir, { recursive: true });
  }
  if (!fs.existsSync(projectDir)) {
    fs.mkdirSync(projectDir, { recursive: true });
  }
  if (!fs.existsSync(sectionDir)) {
    fs.mkdirSync(sectionDir, { recursive: true });
  }
  
  return {
    outputsDir,
    projectDir,
    sectionDir,
    safeTopicName: folderName
  };
}

// Funci√≥n para guardar archivo de audio WAV
async function saveWaveFile(filename, pcmData, channels = 1, rate = 24000, sampleWidth = 2) {
  return new Promise((resolve, reject) => {
    const writer = new wav.FileWriter(filename, {
      channels,
      sampleRate: rate,
      bitDepth: sampleWidth * 8,
    });

    writer.on('finish', resolve);
    writer.on('error', reject);

    writer.write(pcmData);
    writer.end();
  });
}

// Funci√≥n para determinar el tono de narraci√≥n basado en el tema
function getNarrationTone(topic) {
  // Tono fijo: c√°lido y amigable para todos los temas
  return " ";
}

// Funci√≥n para generar audio del gui√≥n
async function generateStoryAudio(script, voiceName = 'Orus', sectionDir, topic, section, customNarrationStyle = null) {
  try {
    console.log(`üéµ Generando narraci√≥n del gui√≥n con voz: ${voiceName}...`);
    console.log(`üìù Script a narrar (primeros 100 caracteres): ${script.substring(0, 100)}...`);
    console.log(`üìè Longitud del script: ${script.length} caracteres`);
    
    // Verificar si el script es demasiado largo
    if (script.length > 5000) {
      console.log(`‚ö†Ô∏è Script muy largo (${script.length} caracteres), truncando a 5000...`);
      script = script.substring(0, 5000) + "...";
    }
    
    // Usar estilo de narraci√≥n personalizado si se proporciona, sino usar el tono por defecto
    let narrationTone;
    if (customNarrationStyle && customNarrationStyle.trim()) {
      narrationTone = `${customNarrationStyle.trim()}: `;
      console.log(`üé≠ Estilo de narraci√≥n personalizado: ${narrationTone}`);
    } else {
      narrationTone = getNarrationTone(topic);
      console.log(`üé≠ Tono de narraci√≥n por defecto: ${narrationTone}`);
    }
    
    // Intentar con configuraci√≥n m√°s simple
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{ 
        parts: [{ 
          text: `Narra el siguiente gui√≥n ${narrationTone}:

${script}`
        }] 
      }],
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { 
              voiceName: voiceName 
            }
          }
        }
      }
    });

    console.log(`üîç Respuesta recibida:`, {
      candidates: response.candidates?.length || 0,
      hasContent: !!response.candidates?.[0]?.content,
      hasParts: !!response.candidates?.[0]?.content?.parts,
      partsLength: response.candidates?.[0]?.content?.parts?.length || 0
    });

    const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    if (!audioData) {
      console.log(`‚ùå Estructura de respuesta completa:`, JSON.stringify(response, null, 2));
      throw new Error('No se gener√≥ audio - revisa los logs para m√°s detalles');
    }

    console.log(`‚úÖ Audio data recibido, tama√±o: ${audioData.length} caracteres`);

    const audioBuffer = Buffer.from(audioData, 'base64');
    const safeTopicName = createSafeFolderName(topic);
    const fileName = `${safeTopicName}_seccion_${section}_${Date.now()}.wav`;
    const filePath = path.join(sectionDir, fileName);
    
    await saveWaveFile(filePath, audioBuffer);
    console.log(`‚úÖ Audio generado exitosamente con voz ${voiceName} en: ${filePath}`);
    
    // Retornar la ruta relativa para acceso web
    const relativePath = path.relative('./public', filePath).replace(/\\/g, '/');
    return relativePath;
  } catch (error) {
    console.error('‚ùå Error generando audio:', error.message);
    console.error('‚ùå Error completo:', error);
    
    // Si es un error de API, intentar diagnosticar
    if (error.message && error.message.includes('API')) {
      console.error('‚ùå Posible problema con la API de Gemini TTS');
    }
    
    // Crear un archivo de texto como fallback
    console.log('üìù Generando archivo de texto como alternativa...');
    const safeTopicName = createSafeFolderName(topic);
    const textFileName = `${safeTopicName}_seccion_${section}_guion_audio_fallback.txt`;
    const textFilePath = path.join(sectionDir, textFileName);
    
    const textContent = `GUI√ìN PARA AUDIO - SECCI√ìN ${section}
===============================
Tema: ${topic}
Voz solicitada: ${voiceName}
Fecha: ${new Date().toLocaleString()}
Estado: Audio no disponible (usando texto como fallback)

CONTENIDO DEL GUI√ìN:
${script}

===============================
NOTA: Este archivo se gener√≥ porque el servicio de Text-to-Speech 
no est√° disponible temporalmente. El contenido del gui√≥n se ha 
guardado para referencia futura.
`;
    
    try {
      fs.writeFileSync(textFilePath, textContent, 'utf8');
      const textRelativePath = path.relative('./public', textFilePath).replace(/\\/g, '/');
      console.log(`üìù Archivo de texto fallback generado: ${textRelativePath}`);
    } catch (writeError) {
      console.error('‚ùå Error creando archivo de texto:', writeError);
    }
    
    throw new Error(`Error al generar audio: ${error.message}. El servicio TTS puede estar temporalmente no disponible.`);
  }
}

// Funci√≥n para generar im√°genes con diferentes modelos
async function generateImageWithModel(ai, prompt, modelType) {
  if (modelType === 'gemini2') {
    console.log(`ü§ñ Usando Gemini 2.0 Flash nativo...`);
    // Usar Gemini 2.0 nativo con responseModalities
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-preview-image-generation",
      contents: prompt,
      config: {
        responseModalities: [Modality.TEXT, Modality.IMAGE],
      },
    });

    const images = [];
    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.mimeType?.includes('image')) {
        images.push({
          image: {
            imageBytes: part.inlineData.data
          }
        });
      }
    }
    
    return {
      generatedImages: images
    };
  } else {
    console.log(`ü§ñ Usando Imagen 4.0 tradicional...`);
    // Usar Imagen 4.0 (m√©todo tradicional)
    return await ai.models.generateImages({
      model: 'imagen-4.0-generate-preview-06-06',
      prompt: prompt,
      config: {
        numberOfImages: 1,
        aspectRatio: "16:9",
      },
    });
  }
}

// =====================================
// FUNCIONES DE B√öSQUEDA Y DESCARGA DE IM√ÅGENES DE BING
// =====================================

// Funci√≥n para generar palabras clave espec√≠ficas para cada imagen usando LLM
async function generateImageKeywords(script, topic, imageCount) {
  try {
    console.log(`üß† Generando ${imageCount} conjuntos de palabras clave para im√°genes...`);
    
    const prompt = `Analiza el siguiente gui√≥n de YouTube y genera palabras clave espec√≠ficas en ingl√©s para buscar im√°genes que complementen el contenido.

TEMA: ${topic}

GUI√ìN:
${script}

INSTRUCCIONES:
1. Genera exactamente ${imageCount} conjuntos de palabras clave para b√∫squeda de im√°genes
2. Cada conjunto debe tener 2-3 palabras simples en ingl√©s
3. Usa t√©rminos CONCRETOS y VISUALES que describan objetos, personajes, escenas
4. Para videojuegos: usa "nintendo", "mario", "gaming", "retro games", "video game"
5. Para historia: usa "vintage", "retro", "classic", "old", "historical"
6. Para tecnolog√≠a: usa "computer", "console", "gaming system", "vintage tech"
7. Enf√≥cate en elementos que se pueden VER en im√°genes, no conceptos abstractos

FORMATO DE RESPUESTA (exactamente ${imageCount} l√≠neas):
[palabra1 palabra2]
[palabra1 palabra2 palabra3]
[palabra1 palabra2]
...

EJEMPLO para tema "making of Mario 64":
mario nintendo character
vintage gaming console
nintendo 64 controller
retro video game
mario jumping action
nintendo development team
classic game screenshots
mario 3d model
nintendo office 1990s
super mario gameplay

IMPORTANTE: 
- USA palabras que describan cosas VISIBLES (personajes, objetos, escenas)
- EVITA conceptos abstractos como "innovation", "challenge", "concept"
- INCLUYE nombres reconocibles cuando sea relevante (mario, nintendo, etc.)

Responde SOLO con las ${imageCount} l√≠neas de palabras clave, sin explicaciones adicionales.`;

    console.log(`ü§ñ Enviando prompt a LLM para generar keywords...`);
    
    const response = await generateUniversalContent('gemini-2.5-flash', prompt);
    const keywordsText = response.text ? response.text.trim() : response.response?.text?.() || '';
    
    console.log(`üìù Respuesta del LLM:`, keywordsText);
    
    // Procesar la respuesta para extraer las palabras clave
    const lines = keywordsText.split('\n').filter(line => line.trim().length > 0);
    const keywords = [];
    
    for (let i = 0; i < imageCount; i++) {
      if (i < lines.length) {
        // Limpiar la l√≠nea de corchetes y caracteres especiales
        const cleanLine = lines[i].replace(/[\[\]]/g, '').trim();
        keywords.push(cleanLine);
      } else {
        // Fallback si no hay suficientes l√≠neas
        keywords.push(`${topic} ${i + 1}`);
      }
    }
    
    console.log(`‚úÖ Palabras clave generadas:`, keywords);
    return keywords;
    
  } catch (error) {
    console.error('‚ùå Error generando palabras clave:', error.message);
    
    // Fallback: generar palabras clave b√°sicas
    const fallbackKeywords = [];
    for (let i = 0; i < imageCount; i++) {
      fallbackKeywords.push(`${topic} part ${i + 1}`);
    }
    
    console.log(`üîÑ Usando keywords de fallback:`, fallbackKeywords);
    return fallbackKeywords;
  }
}

// Funci√≥n para buscar y descargar im√°genes de Bing
async function searchAndDownloadBingImages(keywords, sectionDir) {
  console.log(`üîç Buscando im√°genes en Bing con ${keywords.length} conjuntos de palabras clave`);
  
  try {
    const downloadedImages = [];
    const maxRetries = 3; // M√°ximo 3 intentos por imagen
    
    // Buscar y descargar una imagen para cada conjunto de palabras clave
    for (let i = 0; i < keywords.length; i++) {
      const query = keywords[i];
      console.log(`üì∏ Buscando imagen ${i + 1}/${keywords.length} con: "${query}"`);
      
      let imageDownloaded = false;
      let retryCount = 0;
      
      // Intentar descargar la imagen con reintentos
      while (!imageDownloaded && retryCount < maxRetries) {
        try {
          // Buscar URLs de im√°genes en Bing para este query espec√≠fico
          const imageUrls = await searchBingImages(query, 5); // Buscar 5 opciones por si alguna falla
          
          if (imageUrls.length > 0) {
            // Intentar con diferentes URLs si la primera falla
            for (let urlIndex = 0; urlIndex < Math.min(imageUrls.length, 3); urlIndex++) {
              try {
                const imageUrl = imageUrls[urlIndex];
                const filename = `bing_image_${i + 1}.jpg`;
                const filepath = path.join(sectionDir, filename);
                
                console.log(`üì• Descargando imagen ${i + 1} (intento ${retryCount + 1}/${maxRetries}, URL ${urlIndex + 1}): ${imageUrl.substring(0, 80)}...`);
                
                await downloadImageFromUrl(imageUrl, filepath);
                
                downloadedImages.push({
                  filename: filename,
                  path: filepath,
                  url: imageUrl,
                  source: 'bing',
                  keywords: query,
                  caption: `Imagen ${i + 1}: ${query}`
                });
                
                console.log(`‚úÖ Descargada imagen ${i + 1}: ${filename} (${query})`);
                imageDownloaded = true;
                break; // Salir del loop de URLs
                
              } catch (urlError) {
                console.log(`‚ö†Ô∏è Error con URL ${urlIndex + 1}: ${urlError.message}`);
                continue; // Intentar con la siguiente URL
              }
            }
            
            if (!imageDownloaded) {
              retryCount++;
              if (retryCount < maxRetries) {
                console.log(`üîÑ Reintentando imagen ${i + 1} (intento ${retryCount + 1}/${maxRetries})...`);
                await new Promise(resolve => setTimeout(resolve, 2000)); // Pausa antes de reintentar
              }
            }
            
          } else {
            console.log(`‚ö†Ô∏è No se encontraron im√°genes para: "${query}"`);
            retryCount++;
            if (retryCount < maxRetries) {
              console.log(`üîÑ Reintentando b√∫squeda para "${query}" (intento ${retryCount + 1}/${maxRetries})...`);
              await new Promise(resolve => setTimeout(resolve, 2000));
            }
          }
          
        } catch (error) {
          retryCount++;
          console.error(`‚ùå Error en intento ${retryCount} para imagen ${i + 1} (${query}):`, error.message);
          if (retryCount < maxRetries) {
            console.log(`üîÑ Reintentando imagen ${i + 1} en 3 segundos...`);
            await new Promise(resolve => setTimeout(resolve, 3000));
          }
        }
      }
      
      // Si no se pudo descargar la imagen despu√©s de todos los intentos
      if (!imageDownloaded) {
        console.log(`‚ùå FALLO DEFINITIVO: No se pudo descargar imagen ${i + 1} con keywords "${query}" despu√©s de ${maxRetries} intentos`);
        
        // Crear placeholder o imagen vac√≠a para mantener la secuencia
        const filename = `bing_image_${i + 1}.jpg`;
        downloadedImages.push({
          filename: filename,
          path: null, // Sin archivo f√≠sico
          url: null,
          source: 'bing',
          keywords: query,
          caption: `Imagen ${i + 1}: ${query}`,
          failed: true // Marcar como fallida
        });
      }
      
      // Peque√±a pausa entre descargas para no sobrecargar Bing
      if (i < keywords.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
    
    const successfulDownloads = downloadedImages.filter(img => !img.failed).length;
    console.log(`üéâ Descarga completada: ${successfulDownloads}/${keywords.length} im√°genes exitosas`);
    
    if (successfulDownloads < keywords.length) {
      console.log(`‚ö†Ô∏è ADVERTENCIA: ${keywords.length - successfulDownloads} im√°genes fallaron. Los keywords seguir√°n alineados.`);
    }
    
    return downloadedImages;
    
  } catch (error) {
    console.error('‚ùå Error en b√∫squeda y descarga de Bing:', error.message);
    return [];
  }
}

// Funci√≥n para buscar im√°genes en Bing Images usando web scraping
async function searchBingImages(query, count = 5) {
  try {
    const encodedQuery = encodeURIComponent(query);
    const searchUrl = `https://www.bing.com/images/search?q=${encodedQuery}&form=HDRSC2&first=1&cw=1177&ch=778`;
    
    console.log(`üåê Buscando en Bing Images: ${query}`);
    
    const response = await axios.get(searchUrl, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Cache-Control': 'max-age=0'
      },
      timeout: 15000
    });

    const $ = cheerio.load(response.data);
    const imageUrls = [];

    // Buscar im√°genes en diferentes selectores de Bing
    const selectors = [
      'a.iusc',
      '.imgpt img',
      '.img_cont img',
      'img.mimg'
    ];

    for (const selector of selectors) {
      $(selector).each((i, elem) => {
        try {
          let imageUrl = null;
          
          if (selector === 'a.iusc') {
            // Para enlaces con metadatos JSON
            const metadata = $(elem).attr('m');
            if (metadata) {
              const parsed = JSON.parse(metadata);
              imageUrl = parsed.murl || parsed.turl;
            }
          } else {
            // Para elementos img directos
            imageUrl = $(elem).attr('src') || $(elem).attr('data-src') || $(elem).attr('data-img');
          }
          
          if (imageUrl && 
              imageUrl.startsWith('http') && 
              !imageUrl.includes('bing.com') &&
              !imageUrl.includes('microsoft.com') &&
              !imageUrl.includes('data:image') &&
              imageUrl.length > 50 &&
              imageUrls.length < count) {
            
            imageUrls.push(imageUrl);
          }
        } catch (parseError) {
          // Continuar con la siguiente imagen si hay error de parsing
        }
      });
      
      if (imageUrls.length >= count) break;
    }

    console.log(`üì∏ Bing encontr√≥: ${imageUrls.length} URLs de im√°genes`);
    return imageUrls;
    
  } catch (error) {
    console.error('‚ùå Error en b√∫squeda de Bing Images:', error.message);
    return [];
  }
}

// Funci√≥n para descargar una imagen desde URL
async function downloadImageFromUrl(url, filepath) {
  try {
    const response = await axios({
      method: 'GET',
      url: url,
      responseType: 'stream',
      timeout: 15000,
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'en-US,en;q=0.9',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache',
        'Sec-Fetch-Dest': 'image',
        'Sec-Fetch-Mode': 'no-cors',
        'Sec-Fetch-Site': 'cross-site'
      },
      maxRedirects: 5
    });

    const writer = fs.createWriteStream(filepath);
    response.data.pipe(writer);

    return new Promise((resolve, reject) => {
      writer.on('finish', () => {
        // Verificar que el archivo se escribi√≥ correctamente
        if (fs.existsSync(filepath)) {
          const stats = fs.statSync(filepath);
          if (stats.size > 1000) { // Al menos 1KB
            resolve(filepath);
          } else {
            fs.unlinkSync(filepath); // Eliminar archivo corrupto
            reject(new Error('Archivo muy peque√±o, posiblemente corrupto'));
          }
        } else {
          reject(new Error('El archivo no se cre√≥ correctamente'));
        }
      });
      writer.on('error', reject);
      
      // Timeout adicional
      setTimeout(() => {
        writer.destroy();
        reject(new Error('Timeout en descarga de imagen'));
      }, 20000);
    });
  } catch (error) {
    throw new Error(`Error descargando imagen: ${error.message}`);
  }
}

// Funci√≥n para generar prompts seg√∫n el estilo seleccionado
function generateScriptPrompt(style, topic, sections, section, customStyleInstructions = null, chapterStructure = null, previousChapterContent = null) {
  if (style === 'comedy') {
    return generateComedyPrompt(topic, sections, section, chapterStructure, previousChapterContent);
  } else if (style && style.startsWith('custom_') && customStyleInstructions) {
    return generateCustomPrompt(topic, sections, section, customStyleInstructions, chapterStructure, previousChapterContent);
  } else {
    return generateProfessionalPrompt(topic, sections, section, chapterStructure, previousChapterContent);
  }
}

// Funci√≥n para generar prompt con estilo personalizado
function generateCustomPrompt(topic, sections, section, customInstructions, chapterStructure = null, previousChapterContent = null) {
  const currentSection = section;
  const totalSections = sections;
  
  // Generar texto de estructura de cap√≠tulos si est√° disponible
  let chapterContext = '';
  if (chapterStructure && chapterStructure.length > 0) {
    chapterContext = `

ESTRUCTURA COMPLETA DE CAP√çTULOS:
${chapterStructure.map((title, index) => `${index + 1}. ${title}`).join('\n')}

CAP√çTULO ACTUAL: ${chapterStructure[section - 1] || `Cap√≠tulo ${section}`}`;
  }

  // Generar contexto de cap√≠tulos anteriores si est√° disponible
  let previousContext = '';
  if (previousChapterContent && previousChapterContent.length > 0) {
    previousContext = `

CONTEXTO DE CAP√çTULOS ANTERIORES (para continuidad narrativa):
${previousChapterContent.map((content, index) => {
      const chapterTitle = chapterStructure && chapterStructure[index] ? chapterStructure[index] : `Cap√≠tulo ${index + 1}`;
      const preview = content.length > 200 ? content.substring(0, 200) + '...' : content;
      return `üìö ${chapterTitle}:\n${preview}`;
    }).join('\n\n')}

IMPORTANTE: TOMA EN CUENTA EL CONTEXTO ANTERIOR para mantener continuidad narrativa, referencias y coherencia en el desarrollo del tema.`;
  }
  
  if (currentSection === 1) {
    // Primera secci√≥n
    return `${customInstructions}

TEMA SOLICITADO: "${topic}"
TOTAL DE SECCIONES: ${sections}${chapterContext}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} cap√≠tulos sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO EL CAP√çTULO 1 DE ${sections}.

INSTRUCCIONES GENERALES:
- Crea contenido basado exactamente en lo que el usuario ha pedido en el tema
- Si es sobre ficci√≥n, enf√≥cate en los elementos narrativos y creativos
- Si es sobre desarrollo/creaci√≥n, enf√≥cate en los aspectos reales de producci√≥n
- Si es sobre historia, enf√≥cate en hechos hist√≥ricos y datos
- Adapta tu estilo narrativo al tipo de contenido solicitado
- APLICA ESTRICTAMENTE el estilo personalizado especificado arriba
- NO REPITAS IDEAS, SI ES NECESARIO SALTE UN POCO DEL TEMA PARA EXPLORAR NUEVAS PERSPECTIVAS, PUEDES EXPLORAR CURIOSIDADES TAMBIEN, EASTER EGGS, ETC.
${chapterStructure ? `- ENF√ìCATE en el contenido espec√≠fico del CAP√çTULO 1: "${chapterStructure[0] || 'Sin t√≠tulo'}"` : ''}

ESTRUCTURA REQUERIDA PARA EL CAP√çTULO 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para este cap√≠tulo
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n el estilo personalizado establecido arriba
- Establece las bases del tema para los siguientes cap√≠tulos
${chapterStructure ? `- Desarrolla el tema espec√≠fico del cap√≠tulo: "${chapterStructure[0] || 'Sin t√≠tulo'}"` : ''}

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Cap√≠tulo 1:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n
- APLICA FIELMENTE el estilo personalizado: ${customInstructions}

IMPORTANTE: 
- Este es el PRIMER cap√≠tulo, establece los fundamentos del tema, da una bienvenida al canal
- NO incluyas despedida ya que habr√° m√°s cap√≠tulos
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    // Secciones posteriores
    return `Ahora dame el cap√≠tulo ${currentSection} de ${totalSections} del mismo tema.${chapterContext}

MANT√âN EXACTAMENTE EL MISMO ESTILO PERSONALIZADO: ${customInstructions}

ESTRUCTURA REQUERIDA PARA EL CAP√çTULO ${currentSection}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para este cap√≠tulo
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n continuidad narrativa con los cap√≠tulos anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo y enfoque que estableciste en los cap√≠tulos anteriores
- APLICA ESTRICTAMENTE el estilo personalizado: ${customInstructions}
${chapterStructure ? `- ENF√ìCATE en el contenido espec√≠fico del CAP√çTULO ${currentSection}: "${chapterStructure[currentSection - 1] || 'Sin t√≠tulo'}"` : ''}

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Cap√≠tulo ${currentSection}:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${currentSection === totalSections ? `IMPORTANTE: Como este es el √öLTIMO cap√≠tulo (${currentSection}/${totalSections}), DEBES incluir una despedida profesional al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida: "Y as√≠ concluye este episodio sobre [tema]... Si este contenido te ha resultado interesante, d√©janos un like y suscr√≠bete al canal para m√°s contenido. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos..."` : 'NO incluyas despedida ya que este no es el √∫ltimo cap√≠tulo.'}

üéØ RECORDATORIO CR√çTICO: Debes seguir fielmente este estilo: ${customInstructions}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
  
  if (currentSection === 1) {
    // Primera secci√≥n
    return `${customInstructions}

TEMA SOLICITADO: "${topic}"
TOTAL DE SECCIONES: ${sections}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} secciones sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO LA SECCI√ìN 1 DE ${sections}.

INSTRUCCIONES GENERALES:
- Crea contenido basado exactamente en lo que el usuario ha pedido en el tema
- Si es sobre ficci√≥n, enf√≥cate en los elementos narrativos y creativos
- Si es sobre desarrollo/creaci√≥n, enf√≥cate en los aspectos reales de producci√≥n
- Si es sobre historia, enf√≥cate en hechos hist√≥ricos y datos
- Adapta tu estilo narrativo al tipo de contenido solicitado
- APLICA ESTRICTAMENTE el estilo personalizado especificado arriba
- NO REPITAS IDEAS, SI ES NECESARIO SALTE UN POCO DEL TEMA PARA EXPLORAR NUEVAS PERSPECTIVAS, PUEDES EXPLORAR CURIOSIDADES TAMBIEN, EASTER EGGS, ETC.

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n el estilo personalizado establecido arriba
- Establece las bases del tema para las siguientes secciones

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n 1:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n
- APLICA FIELMENTE el estilo personalizado: ${customInstructions}

IMPORTANTE: 
- Esta es la PRIMERA secci√≥n, establece los fundamentos del tema, da una bienvenida al canal
- NO incluyas despedida ya que habr√° m√°s secciones
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    // Secciones posteriores
    return `Ahora dame la secci√≥n ${currentSection} de ${totalSections} del mismo tema.

MANT√âN EXACTAMENTE EL MISMO ESTILO PERSONALIZADO: ${customInstructions}${chapterContext}${previousContext}

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN ${currentSection}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n continuidad narrativa con las secciones anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo y enfoque que estableciste en las secciones anteriores
- CONECTA directamente con el contenido de los cap√≠tulos anteriores
- Haz referencias sutiles a informaci√≥n ya mencionada cuando sea relevante
- APLICA ESTRICTAMENTE el estilo personalizado: ${customInstructions}

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n ${currentSection}:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${currentSection === totalSections ? `IMPORTANTE: Como esta es la √öLTIMA secci√≥n (${currentSection}/${totalSections}), DEBES incluir una despedida profesional al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida: "Y as√≠ concluye este episodio sobre [tema]... Si este contenido te ha resultado interesante, d√©janos un like y suscr√≠bete al canal para m√°s contenido. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos..."` : 'NO incluyas despedida ya que esta no es la √∫ltima secci√≥n.'}

üéØ RECORDATORIO CR√çTICO: Debes seguir fielmente este estilo: ${customInstructions}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
}

// Funci√≥n para generar prompt estilo profesional (original)
function generateProfessionalPrompt(topic, sections, section, chapterStructure = null, previousChapterContent = null) {
  // Generar texto de estructura de cap√≠tulos si est√° disponible
  let chapterContext = '';
  if (chapterStructure && chapterStructure.length > 0) {
    chapterContext = `

ESTRUCTURA COMPLETA DE CAP√çTULOS:
${chapterStructure.map((title, index) => `${index + 1}. ${title}`).join('\n')}

CAP√çTULO ACTUAL: ${chapterStructure[section - 1] || `Cap√≠tulo ${section}`}`;
  }

  // Generar contexto de cap√≠tulos anteriores si est√° disponible
  let previousContext = '';
  if (previousChapterContent && previousChapterContent.length > 0) {
    previousContext = `

CONTEXTO DE CAP√çTULOS ANTERIORES (para continuidad narrativa):
${previousChapterContent.map((content, index) => {
      const chapterTitle = chapterStructure && chapterStructure[index] ? chapterStructure[index] : `Cap√≠tulo ${index + 1}`;
      const preview = content.length > 200 ? content.substring(0, 200) + '...' : content;
      return `üìö ${chapterTitle}:\n${preview}`;
    }).join('\n\n')}

IMPORTANTE: TOMA EN CUENTA EL CONTEXTO ANTERIOR para mantener continuidad narrativa, referencias y coherencia en el desarrollo del tema.`;
  }
  
  if (section === 1) {
    return `Eres un escritor profesional especializado en guiones para YouTube.

TEMA SOLICITADO: "${topic}"
TOTAL DE CAP√çTULOS: ${sections}${chapterContext}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} cap√≠tulos sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO EL CAP√çTULO 1 DE ${sections}.
al ser este el primer cap√≠tulo, da una bienvenida al canal y presenta el tema de manera atractiva.
INSTRUCCIONES GENERALES:
- Crea contenido basado exactamente en lo que el usuario ha pedido en el tema
- Si es sobre ficci√≥n, enf√≥cate en los elementos narrativos y creativos
- Si es sobre desarrollo/creaci√≥n, enf√≥cate en los aspectos reales de producci√≥n
- Si es sobre historia, enf√≥cate en hechos hist√≥ricos y datos
- Adapta tu estilo narrativo al tipo de contenido solicitado
${chapterStructure ? `- ENF√ìCATE en el contenido espec√≠fico del CAP√çTULO 1: "${chapterStructure[0] || 'Sin t√≠tulo'}"` : ''}

ESTRUCTURA REQUERIDA PARA EL CAP√çTULO 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para este cap√≠tulo
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n un tono profesional y enganchante
- Establece las bases del tema para los siguientes cap√≠tulos
${chapterStructure ? `- Desarrolla el tema espec√≠fico del cap√≠tulo: "${chapterStructure[0] || 'Sin t√≠tulo'}"` : ''}

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Cap√≠tulo 1:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

IMPORTANTE: 
- Este es el PRIMER cap√≠tulo, establece los fundamentos del tema
- NO incluyas despedida ya que habr√° m√°s cap√≠tulos
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    return `Ahora dame el cap√≠tulo ${section} de ${sections} del mismo tema.${chapterContext}${previousContext}

ESTRUCTURA REQUERIDA PARA EL CAP√çTULO ${section}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para este cap√≠tulo
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n continuidad narrativa con los cap√≠tulos anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo y enfoque que estableciste en los cap√≠tulos anteriores
- CONECTA directamente con el contenido de los cap√≠tulos anteriores
- Haz referencias sutiles a informaci√≥n ya mencionada cuando sea relevante
${chapterStructure ? `- ENF√ìCATE en el contenido espec√≠fico del CAP√çTULO ${section}: "${chapterStructure[section - 1] || 'Sin t√≠tulo'}"` : ''}

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Cap√≠tulo ${section}:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${section === sections ? `IMPORTANTE: Como este es el √öLTIMO cap√≠tulo (${section}/${sections}), DEBES incluir una despedida profesional al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida: "Y as√≠ concluye este episodio sobre [tema]... Si este contenido te ha resultado interesante, d√©janos un like y suscr√≠bete a al canal para m√°s contenido. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos..."` : 'NO incluyas despedida ya que este no es el √∫ltimo cap√≠tulo.'}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
}

// Funci√≥n para generar prompt estilo c√≥mico/sarc√°stico
function generateComedyPrompt(topic, sections, section, chapterStructure = null, previousChapterContent = null) {
  // Generar texto de estructura de cap√≠tulos si est√° disponible
  let chapterContext = '';
  if (chapterStructure && chapterStructure.length > 0) {
    chapterContext = `

ESTRUCTURA COMPLETA DE CAP√çTULOS:
${chapterStructure.map((title, index) => `${index + 1}. ${title}`).join('\n')}

CAP√çTULO ACTUAL: ${chapterStructure[section - 1] || `Cap√≠tulo ${section}`}`;
  }

  // Generar contexto de cap√≠tulos anteriores si est√° disponible
  let previousContext = '';
  if (previousChapterContent && previousChapterContent.length > 0) {
    previousContext = `

CONTEXTO DE CAP√çTULOS ANTERIORES (para continuidad narrativa):
${previousChapterContent.map((content, index) => {
      const chapterTitle = chapterStructure && chapterStructure[index] ? chapterStructure[index] : `Cap√≠tulo ${index + 1}`;
      const preview = content.length > 200 ? content.substring(0, 200) + '...' : content;
      return `üìö ${chapterTitle}:\n${preview}`;
    }).join('\n\n')}

IMPORTANTE: TOMA EN CUENTA EL CONTEXTO ANTERIOR para mantener continuidad narrativa, referencias y coherencia en el desarrollo del tema.`;
  }
  
  if (section === 1) {
    return `Eres un escritor de guiones creativo para contenido de YouTube.

Tu tarea es construir guiones con un tono sarc√°stico, ir√≥nico, con humor negro, muchas groser√≠as y un chingo de humor absurdo.

TEMA SOLICITADO: "${topic}"
TOTAL DE CAP√çTULOS: ${sections}${chapterContext}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} cap√≠tulos sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO EL CAP√çTULO 1 DE ${sections}.

üé≠ FORMATO DEL GUION:

El guion debe leerse como una actuaci√≥n, adem√°s de una narraci√≥n cronol√≥gica.
como es el primer capitulo usa una introducci√≥n llamativa para captar la atenci√≥n del espectador.
Usa m√∫ltiples voces indicadas con corchetes, por ejemplo:
[voz de narrador serio], [voz sarc√°stica], [grito desesperado], [voz de ni√±a loca], [voz de viejita], etc.

Las escenas deben sentirse teatrales, exageradas, bizarras y alucinantes.
en algunas ocasiones interpreta lo que los personajes en el guion podrian decir o pensar.
${chapterStructure ? `
üéØ ENFOQUE DEL CAP√çTULO: Centra todo el contenido en desarrollar espec√≠ficamente "${chapterStructure[0] || 'Sin t√≠tulo'}"` : ''}

ESTRUCTURA REQUERIDA PARA EL CAP√çTULO 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para este cap√≠tulo
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n un tono sarc√°stico, ir√≥nico y absurdo y muy √°cido.
- Establece las bases del tema para los siguientes cap√≠tulos
${chapterStructure ? `- Desarrolla el tema espec√≠fico del cap√≠tulo: "${chapterStructure[0] || 'Sin t√≠tulo'}"` : ''}

PALABRAS Y EXPRESIONES A USAR:
Usas algunas veces palabras como: pinche, wey, pendejo, cabr√≥n, verga, chinga tu madre, me vale verga, come verga, hijo de la verga.

RESTRICCIONES:
- No se permite usar la palabra "show"
- No se permiten chistes sobre pol√≠ticos ni ex parejas

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Cap√≠tulo 1:", "Gui√≥n:", etc.
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

IMPORTANTE: 
- Este es el PRIMER cap√≠tulo, establece los fundamentos del tema
- NO incluyas despedida ya que habr√° m√°s cap√≠tulos
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    return `Ahora dame el cap√≠tulo ${section} de ${sections} del mismo tema.${chapterContext}${previousContext}

Mant√©n el mismo estilo sarc√°stico, ir√≥nico, con humor negro y groser√≠as.

ESTRUCTURA REQUERIDA PARA EL CAP√çTULO ${section}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para este cap√≠tulo
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n continuidad narrativa con los cap√≠tulos anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo y enfoque que estableciste en los cap√≠tulos anteriores
- CONECTA directamente con el contenido de los cap√≠tulos anteriores
- Haz referencias sutiles a informaci√≥n ya mencionada cuando sea relevante
${chapterStructure ? `- ENF√ìCATE en el contenido espec√≠fico del CAP√çTULO ${section}: "${chapterStructure[section - 1] || 'Sin t√≠tulo'}"` : ''}
- M√≠nimo 250 palabras por cap√≠tulo
- Mant√©n continuidad narrativa con los cap√≠tulos anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo c√≥mico y absurdo que estableciste
${chapterStructure ? `- ENF√ìCATE en el contenido espec√≠fico del CAP√çTULO ${section}: "${chapterStructure[section - 1] || 'Sin t√≠tulo'}"` : ''}

üé≠ FORMATO DEL GUION:
- Usa m√∫ltiples voces indicadas con corchetes al menos 4 en cada p√°rrafo
- Usa onomatopeyas y efectos sonoros rid√≠culos
- Las escenas deben sentirse teatrales y exageradas

PALABRAS Y EXPRESIONES A USAR:
Usa muchas palabras como: pinche, wey, pendejo, cabr√≥n, verga, chinga tu madre, me vale verga, come verga.

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Cap√≠tulo ${section}:", "Gui√≥n:", etc.
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${section === sections ? `IMPORTANTE: Como este es el √öLTIMO cap√≠tulo (${section}/${sections}), DEBES incluir una despedida c√≥mica al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida c√≥mica: "Y as√≠ concluye este pinche episodio sobre [tema]... Si te cagaste de risa, d√©janos un like y suscr√≠bete al canal para m√°s contenido cabr√≥n. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos, wey..."` : 'NO incluyas despedida ya que este no es el √∫ltimo cap√≠tulo.'}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
}

app.post('/generate', async (req, res) => {
  try {
    const { topic, folderName, voice, totalSections, currentSection, previousSections, imageCount, promptModifier, imageModel, llmModel, skipImages, googleImages, scriptStyle, customStyleInstructions, applioVoice, applioModel, applioPitch } = req.body;
    
    const selectedVoice = voice || 'Orus';
    const sections = totalSections || 3;
    const section = currentSection || 1;
    const selectedStyle = scriptStyle || 'professional'; // Default al estilo profesional
    const numImages = imageCount || 5; // Default a 5 im√°genes si no se especifica
    const additionalInstructions = promptModifier || ''; // Instrucciones adicionales para im√°genes
    const selectedImageModel = imageModel || 'gemini2';
    const selectedLlmModel = llmModel || 'gemini-2.5-pro';
    let shouldSkipImages = skipImages === true;
    let shouldUseGoogleImages = googleImages === true;
    
    console.log(`üéØ Solicitud recibida: ${shouldUseGoogleImages ? 'ENLACES GOOGLE' : shouldSkipImages ? 'SIN IM√ÅGENES' : numImages + ' im√°genes'} para la secci√≥n ${section}`);
    
    if (!topic) {
      return res.status(400).json({ error: 'Tema requerido' });
    }

    // Crear estructura de carpetas
    const folderStructure = createProjectStructure(topic, section, folderName);
    console.log(`üìÅ Estructura de carpetas creada: ${folderStructure.sectionDir}`);

    // Crear clave √∫nica para la conversaci√≥n (proyecto)
    // Usar siempre el tema como clave de conversaci√≥n para mantener continuidad
    // incluso si cambia el nombre de la carpeta
    const projectKey = createSafeFolderName(topic);
    const conversation = getOrCreateConversation(projectKey);
    
    console.log(`üí¨ Usando conversaci√≥n: ${projectKey} (basada en tema: "${topic}")`);
    console.log(`üìù Historial actual: ${conversation.history.length} mensajes`);

    // Paso 1: Generar gui√≥n usando conversaci√≥n continua
    console.log(`üìù Generando gui√≥n de YouTube - Secci√≥n ${section}/${sections} para el tema: ${topic}...`);
    console.log(`üé≠ Usando estilo: ${selectedStyle === 'comedy' ? 'C√≥mico/Sarc√°stico' : 'Profesional'}`);
    
    let promptContent;
    let chapterStructure = null;
    
    if (section === 1) {
      // Primera secci√≥n: Generar estructura completa de cap√≠tulos primero
      conversation.topic = topic;
      conversation.totalSections = sections;
      conversation.currentSection = 1;
      conversation.history = []; // Limpiar historial para nueva conversaci√≥n

      console.log(`üìã PASO 1: Generando estructura de ${sections} cap√≠tulos para el tema: ${topic}...`);
      
      // Generar estructura de cap√≠tulos
      let chapterPrompt;
      
      // Detectar si se est√° usando un estilo personalizado
      if (selectedStyle && selectedStyle.startsWith('custom_') && customStyleInstructions) {
        // Prompt especializado para estilos personalizados
        chapterPrompt = `Eres un experto en crear estructuras narrativas personalizadas.

TEMA SOLICITADO: "${topic}"
TOTAL DE CAP√çTULOS: ${sections}
ESTILO PERSONALIZADO: ${customStyleInstructions}

Tu tarea es crear una ESTRUCTURA NARRATIVA que respete completamente el estilo personalizado definido.

INSTRUCCIONES ESPEC√çFICAS PARA ESTE ESTILO:
- Analiza cuidadosamente las instrucciones del estilo personalizado
- Crea t√≠tulos que reflejen EXACTAMENTE lo que pide el estilo
- Si el estilo menciona "situaciones cotidianas", crea cap√≠tulos sobre actividades diarias del personaje
- Si el estilo habla de "progresi√≥n del d√≠a", organiza los cap√≠tulos cronol√≥gicamente  
- Si pide "t√©cnicas de hipnotizaci√≥n", enf√≥cate en momentos relajantes del personaje
- IGNORA formatos educativos gen√©ricos, sigue SOLO el estilo personalizado

PARA "${topic}" CON ESTE ESTILO ESPEC√çFICO:
Genera t√≠tulos que narren momentos, actividades y situaciones del personaje, no informaci√≥n educativa sobre la serie.

FORMATO DE RESPUESTA OBLIGATORIO:
Debes responder √öNICAMENTE con los t√≠tulos separados por "||CAPITULO||"

VERIFICACI√ìN: Tu respuesta debe tener exactamente ${sections - 1} delimitadores "||CAPITULO||" para generar ${sections} t√≠tulos.

RESPONDE SOLO CON LOS T√çTULOS SEPARADOS POR "||CAPITULO||", NADA M√ÅS.`;
      } else {
        // Prompt est√°ndar para estilos no personalizados  
        chapterPrompt = `Eres un experto en narrativa para YouTube especializado en contenido educativo y entretenimiento.

TEMA SOLICITADO: "${topic}"
TOTAL DE CAP√çTULOS: ${sections}

Tu tarea es crear una ESTRUCTURA NARRATIVA completa dividiendo el tema en ${sections} cap√≠tulos/secciones coherentes y bien organizadas.

INSTRUCCIONES:
- Crea EXACTAMENTE ${sections} t√≠tulos de cap√≠tulos
- Cada cap√≠tulo debe tener un t√≠tulo descriptivo y atractivo
- Los cap√≠tulos deben seguir un hilo narrativo l√≥gico
- Progresi√≥n natural del tema de inicio a conclusi√≥n
- T√≠tulos que generen curiosidad y mantengan el inter√©s

FORMATO DE RESPUESTA OBLIGATORIO:
Debes responder √öNICAMENTE con los t√≠tulos separados por "||CAPITULO||"

EJEMPLO PARA 3 CAP√çTULOS:
Cap√≠tulo 1: El Origen de la Leyenda||CAPITULO||Cap√≠tulo 2: Los Secretos Revelados||CAPITULO||Cap√≠tulo 3: El Legado Eterno

VERIFICACI√ìN: Tu respuesta debe tener exactamente ${sections - 1} delimitadores "||CAPITULO||" para generar ${sections} t√≠tulos.

RESPONDE SOLO CON LOS T√çTULOS SEPARADOS POR "||CAPITULO||", NADA M√ÅS.`;
      }

      console.log(`üîÑ Enviando prompt de cap√≠tulos al modelo ${selectedLlmModel}...`);
      
      try {
        const chapterResponse = await generateUniversalContent(
          selectedLlmModel,
          chapterPrompt,
          "Eres un experto en estructura narrativa. Tu √öNICA tarea es crear t√≠tulos de cap√≠tulos separados por '||CAPITULO||'. NUNCA generes texto adicional fuera de los t√≠tulos."
        );

        console.log(`‚úÖ Respuesta de cap√≠tulos recibida exitosamente`);

        const chaptersText = chapterResponse.text || '';
        console.log(`üìù Respuesta de estructura: ${chaptersText ? chaptersText.substring(0, 200) + '...' : 'RESPUESTA VAC√çA'}`);
        
        const chapterTitles = chaptersText.split('||CAPITULO||').filter(title => title.trim()).slice(0, sections);
        console.log(`üìö Cap√≠tulos generados: ${chapterTitles.length} de ${sections} solicitados`);
        console.log(`üìñ T√≠tulos: ${chapterTitles.join(', ')}`);
        
        // üìã MOSTRAR ESTRUCTURA COMPLETA DE CAP√çTULOS
        console.log('\n' + '='.repeat(60));
        console.log('üìñ ESTRUCTURA COMPLETA DE CAP√çTULOS GENERADA');
        console.log('='.repeat(60));
        console.log(`üéØ Tema: "${topic}"`);
        console.log(`üìä Total de cap√≠tulos: ${sections}`);
        console.log(`üß† Modelo LLM usado: ${selectedLlmModel}`);
        console.log('‚îÄ'.repeat(60));
        
        if (chapterTitles.length > 0) {
          chapterTitles.forEach((title, index) => {
            const chapterNumber = index + 1;
            const cleanTitle = title.trim();
            console.log(`üìö Cap√≠tulo ${chapterNumber}: ${cleanTitle}`);
          });
        } else {
          console.log('‚ö†Ô∏è No se generaron t√≠tulos de cap√≠tulos');
        }
        
        console.log('='.repeat(60) + '\n');
        
        // Guardar estructura en la conversaci√≥n
        conversation.chapterStructure = chapterTitles;
        chapterStructure = chapterTitles;
        
      } catch (chapterError) {
        console.error('‚ùå ERROR generando estructura de cap√≠tulos:', chapterError);
        console.log('‚ö†Ô∏è Continuando sin estructura de cap√≠tulos...');
        chapterStructure = [];
        conversation.chapterStructure = [];
      }

      console.log(`üìù PASO 2: Generando contenido del Cap√≠tulo 1: ${chapterStructure[0] || 'Sin t√≠tulo'}...`);
      
      // Ahora generar el contenido de la primera secci√≥n con contexto de estructura
      promptContent = generateScriptPrompt(selectedStyle, topic, sections, section, customStyleInstructions, chapterStructure, null);

      // Limpiar historial y agregar mensaje inicial
      conversation.history = [
        { role: 'user', parts: [{ text: promptContent }] }
      ];
      
    } else {
      // Secciones posteriores: Usar estructura existente
      chapterStructure = conversation.chapterStructure || [];
      console.log(`üìñ Usando estructura existente: ${chapterStructure.length} cap√≠tulos`);
      console.log(`üìù Generando Cap√≠tulo ${section}: ${chapterStructure[section - 1] || 'Sin t√≠tulo'}...`);
      
      // ÔøΩ EXTRAER CONTEXTO DE CAP√çTULOS ANTERIORES
      console.log(`üîó Extrayendo contexto de ${section - 1} cap√≠tulos anteriores...`);
      const previousChapterContent = [];
      
      // Obtener el contenido de las respuestas anteriores del asistente
      conversation.history.forEach((message, index) => {
        if (message.role === 'model' && message.parts && message.parts[0] && message.parts[0].text) {
          const content = message.parts[0].text.trim();
          if (content.length > 50) { // Solo incluir respuestas con contenido sustancial
            previousChapterContent.push(content);
          }
        }
      });
      
      console.log(`üìö Cap√≠tulos anteriores encontrados: ${previousChapterContent.length}`);
      if (previousChapterContent.length > 0) {
        console.log(`üìñ √öltimo cap√≠tulo preview: ${previousChapterContent[previousChapterContent.length - 1].substring(0, 100)}...`);
      }
      
      // üìã MOSTRAR PROGRESO DE CAP√çTULOS
      console.log('\n' + '‚îÄ'.repeat(50));
      console.log(`üìö CAP√çTULO ${section} DE ${sections}`);
      console.log('‚îÄ'.repeat(50));
      console.log(`üéØ Tema: "${topic}"`);
      console.log(`üìñ Cap√≠tulo actual: ${chapterStructure[section - 1] || 'Sin t√≠tulo'}`);
      console.log(`üß† Modelo LLM: ${selectedLlmModel}`);
      
      // Mostrar contexto de todos los cap√≠tulos
      console.log('\nüìã Estructura completa:');
      chapterStructure.forEach((title, index) => {
        const chapterNumber = index + 1;
        const isCurrentChapter = chapterNumber === section;
        const statusIcon = chapterNumber < section ? '‚úÖ' : isCurrentChapter ? 'üîÑ' : '‚è≥';
        const cleanTitle = title.trim();
        console.log(`${statusIcon} Cap√≠tulo ${chapterNumber}: ${cleanTitle}`);
      });
      console.log('‚îÄ'.repeat(50) + '\n');
      
      promptContent = generateScriptPrompt(selectedStyle, topic, sections, section, customStyleInstructions, chapterStructure, previousChapterContent);

      // Agregar nueva pregunta al historial
      conversation.history.push({ role: 'user', parts: [{ text: promptContent }] });
    }
    
    // Actualizar secci√≥n actual
    conversation.currentSection = section;

    // Generar respuesta usando el historial de conversaci√≥n
    let systemInstruction;
    if (selectedStyle === 'comedy') {
      systemInstruction = "Eres un escritor de guiones c√≥micos para YouTube con tono sarc√°stico y humor negro. IMPORTANTE: Responde √öNICAMENTE con el texto del gui√≥n, sin explicaciones, comentarios, etiquetas o texto adicional. El texto debe estar listo para TTS. Incluye groser√≠as, humor absurdo y m√∫ltiples voces entre corchetes. ESTRUCTURA OBLIGATORIA: Exactamente 3 p√°rrafos detallados, m√°ximo 300 palabras total, m√≠nimo 200 palabras. Solo el gui√≥n puro.";
    } else if (selectedStyle && selectedStyle.startsWith('custom_') && customStyleInstructions) {
      systemInstruction = `Eres un escritor de guiones para YouTube especializado en el estilo personalizado que el usuario ha definido. IMPORTANTE: Responde √öNICAMENTE con el texto del gui√≥n siguiendo exactamente estas instrucciones de estilo: ${customStyleInstructions}. Sin explicaciones, comentarios, etiquetas o texto adicional. El texto debe estar listo para TTS aplicando fielmente el estilo especificado. ESTRUCTURA OBLIGATORIA: Exactamente 3 p√°rrafos detallados, m√°ximo 250 palabras total, m√≠nimo 200 palabras por secci√≥n. Solo el gui√≥n puro.`;
    } else {
      systemInstruction = "Eres un escritor profesional de guiones para YouTube. IMPORTANTE: Responde √öNICAMENTE con el texto del gui√≥n, sin explicaciones, comentarios, etiquetas o texto adicional. El texto debe estar listo para TTS. No incluyas pensamientos, notas o aclaraciones. ESTRUCTURA OBLIGATORIA: Exactamente 3 p√°rrafos detallados, m√°ximo 300 palabras total, m√≠nimo 200 palabras. Solo el gui√≥n puro.";
    }

    const scriptResponse = await generateUniversalContent(
      selectedLlmModel,
      conversation.history,
      systemInstruction
    );

    console.log(`üîç scriptResponse:`, typeof scriptResponse, scriptResponse);
    const script = scriptResponse.text || scriptResponse.message?.content || scriptResponse;
    console.log(`üîç script extra√≠do:`, typeof script);
    console.log(`üîç script preview:`, script && typeof script === 'string' && script.length > 0 ? script.substring(0, 100) + '...' : 'VAC√çO O INV√ÅLIDO');
    
    // Validar que tenemos contenido v√°lido
    if (!script || typeof script !== 'string' || script.trim().length === 0) {
      throw new Error(`No se pudo extraer contenido v√°lido de la respuesta. Response: ${JSON.stringify(scriptResponse)}`);
    }
    
    // Limpiar el script de cualquier texto adicional no deseado
    const cleanScript = cleanScriptText(script);
    
    // Calcular tokens de entrada y salida
    const inputTokens = estimateTokens(promptContent + (systemInstruction || ''));
    const outputTokens = estimateTokens(cleanScript);
    const totalTokens = inputTokens + outputTokens;
    
    console.log(`üìä TOKENS - Entrada: ${inputTokens}, Salida: ${outputTokens}, Total: ${totalTokens}`);
    
    // Agregar respuesta al historial
    conversation.history.push({ role: 'model', parts: [{ text: cleanScript }] });
    
    // Optimizar historial manteniendo continuidad narrativa
    optimizeConversationHistory(conversation);
    
    // OPTIMIZACI√ìN: Mantener solo los √∫ltimos 4 mensajes (2 intercambios: pregunta+respuesta anteriores)
    // Esto ahorra tokens manteniendo solo el contexto del cap√≠tulo anterior
    const historialAntes = conversation.history.length;
    if (conversation.history.length > 10) { // Activar optimizaci√≥n m√°s tarde
      conversation.history = conversation.history.slice(-8); // Mantener m√°s contexto para continuidad
      console.log(`ÔøΩ OPTIMIZACI√ìN - Historial reducido de ${historialAntes} a ${conversation.history.length} mensajes`);
      console.log(`üí∞ AHORRO DE TOKENS - Eliminados ${historialAntes - conversation.history.length} mensajes antiguos`);
    }
    
    console.log(`‚úÖ Gui√≥n de la secci√≥n ${section} generado usando conversaci√≥n continua`);
    console.log(`üíæ Historial actualizado: ${conversation.history.length} mensajes`);
    
    // Mostrar informaci√≥n de ahorro de tokens
    if (historialAntes > 4) {
      const tokensActuales = conversation.history.reduce((total, msg) => {
        return total + estimateTokens(msg.parts[0].text);
      }, 0);
      console.log(`üìä M√âTRICAS - Tokens actuales en historial: ~${tokensActuales} (optimizado vs ~${tokensActuales * (historialAntes / 4)} sin optimizaci√≥n)`);
    }

    // Guardar el gui√≥n como archivo de texto en la carpeta de la secci√≥n
    try {
      const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
      const scriptFilePath = path.join(folderStructure.sectionDir, scriptFileName);
      
      const scriptContent = `GUI√ìN DE LA SECCI√ìN ${section}
===============================
Tema: ${topic}
Secci√≥n: ${section} de ${sections}
Fecha de generaci√≥n: ${new Date().toLocaleString()}
${folderName ? `Nombre del proyecto: ${folderName}` : ''}

CONTENIDO DEL GUI√ìN:
${cleanScript}

===============================
Generado autom√°ticamente por el sistema de creaci√≥n de contenido
`;
      
      fs.writeFileSync(scriptFilePath, scriptContent, 'utf8');
      console.log(`üìù Gui√≥n guardado autom√°ticamente en: ${scriptFilePath}`);
    } catch (saveError) {
      console.error('‚ùå Error guardando archivo de gui√≥n:', saveError);
      // No detener el proceso por este error, solo registrarlo
    }

    // Verificar si se deben omitir las im√°genes o usar Bing Images
    if (shouldSkipImages || shouldUseGoogleImages) {
      const modeDescription = shouldUseGoogleImages ? 'Descargando im√°genes espec√≠ficas de Bing' : 'Omitiendo generaci√≥n de im√°genes, pero generando prompts para mostrar';
      console.log(`üö´ ${modeDescription}`);
      console.log(`üîç DEBUG SKIP - shouldSkipImages: ${shouldSkipImages}`);
      console.log(`üîç DEBUG BING - shouldUseGoogleImages: ${shouldUseGoogleImages}`);
      console.log(`üîç DEBUG SKIP - numImages: ${numImages}`);
      
      let enhancedPrompts = [];
      let downloadedImages = [];
      let imageKeywords = []; // Declarar aqu√≠ para uso posterior
      
      if (shouldUseGoogleImages) {
        console.log(`üîç Generando palabras clave espec√≠ficas y descargando ${numImages} im√°genes de Bing...`);
        
        try {
          // Generar palabras clave espec√≠ficas usando el LLM
          console.log(`üß† Analizando gui√≥n para generar palabras clave espec√≠ficas...`);
          imageKeywords = await generateImageKeywords(cleanScript, topic, numImages);
          
          console.log(`üéØ Palabras clave generadas para ${numImages} im√°genes:`, imageKeywords);
          
          // Descargar im√°genes usando las palabras clave espec√≠ficas
          downloadedImages = await searchAndDownloadBingImages(imageKeywords, folderStructure.sectionDir);
          
          if (downloadedImages.length > 0) {
            console.log(`‚úÖ ${downloadedImages.length} im√°genes descargadas de Bing exitosamente con keywords espec√≠ficas`);
            
            // Guardar keywords en archivo para cargarlas posteriormente
            try {
              const keywordsToSave = downloadedImages.map(img => img.keywords || '').filter(k => k.trim());
              if (keywordsToSave.length > 0) {
                const keywordsFilePath = path.join(folderStructure.sectionDir, `${folderStructure.folderName}_seccion_${section}_keywords.txt`);
                fs.writeFileSync(keywordsFilePath, keywordsToSave.join('\n'), 'utf8');
                console.log(`üíæ Keywords guardadas en: ${keywordsFilePath}`);
              }
            } catch (keywordSaveError) {
              console.warn(`‚ö†Ô∏è Error guardando keywords: ${keywordSaveError.message}`);
            }
            
            // Crear "prompts" mostrando las palabras clave espec√≠ficas que se usaron
            enhancedPrompts = downloadedImages.map((img, index) => 
              `Imagen ${index + 1}: ${img.keywords || img.caption || img.filename}`
            );
            
            console.log(`üìã Prompts generados con keywords:`, enhancedPrompts);
          } else {
            console.log(`‚ö†Ô∏è No se pudieron descargar im√°genes de Bing, generando prompts como fallback`);
            // Fallback: mostrar las keywords que se intentaron usar
            enhancedPrompts = imageKeywords.map((keyword, index) => 
              `Keywords intentadas ${index + 1}: ${keyword}`
            );
          }
        } catch (error) {
          console.error(`‚ùå Error descargando im√°genes de Bing:`, error.message);
          enhancedPrompts = [`Error generando keywords o descargando im√°genes: ${error.message}`];
        }
      } else {
        console.log(`üé® Generando prompts para secuencia de ${numImages} im√°genes (solo texto)...`);
        const promptsResponse = await generateUniversalContent(
          selectedLlmModel,
          `Bas√°ndote en este gui√≥n de la secci√≥n ${section} sobre "${topic}": "${cleanScript}", crea EXACTAMENTE ${numImages} prompts detallados para generar una SECUENCIA de ${numImages} im√°genes que ilustren visualmente el contenido del gui√≥n en orden cronol√≥gico.

          IMPORTANTE: Debes crear EXACTAMENTE ${numImages} prompts, ni m√°s ni menos.

          ENFOQUE:
          - Las im√°genes deben seguir la narrativa del gui√≥n paso a paso
          - Cada imagen debe representar una parte espec√≠fica del gui√≥n en orden
          - Enf√≥cate en elementos del lore interno del juego mencionados en el gui√≥n
          - Ilustra lugares, personajes, eventos y elementos espec√≠ficos del gui√≥n
          - Mant√©n consistencia visual entre las ${numImages} im√°genes

          INSTRUCCIONES CR√çTICAS PARA EL FORMATO:
          - DEBES dividir el gui√≥n en EXACTAMENTE ${numImages} partes cronol√≥gicas
          - DEBES crear un prompt independiente para cada parte
          - DEBES separar cada prompt con "||PROMPT||" (sin espacios adicionales)
          - DEBES asegurarte de que haya exactamente ${numImages} prompts en tu respuesta
          - Las im√°genes deben contar la historia del gui√≥n de forma visual secuencial
          - Incluye detalles espec√≠ficos mencionados en el texto del gui√≥n

          REQUISITOS OBLIGATORIOS para cada prompt:
          - Formato: Aspecto 16:9 (widescreen)
          
          FORMATO DE RESPUESTA OBLIGATORIO:
          DEBES presentar EXACTAMENTE ${numImages} prompts separados por "||PROMPT||" (sin espacios antes o despu√©s del delimitador).
          
          ESTRUCTURA REQUERIDA:
          Prompt 1 aqu√≠||PROMPT||Prompt 2 aqu√≠||PROMPT||Prompt 3 aqu√≠||PROMPT||... hasta el Prompt ${numImages}
          
          EJEMPLO PARA 3 PROMPTS (adaptar a ${numImages}):
          Un bosque oscuro con √°rboles ancianos||PROMPT||Una batalla √©pica entre guerreros||PROMPT||Un castillo en ruinas bajo la luna
          
          VERIFICACI√ìN FINAL: Tu respuesta debe contener exactamente ${numImages - 1} ocurrencias del delimitador "||PROMPT||" para generar ${numImages} prompts.`,
          `Eres un experto en arte conceptual y narrativa visual. Tu √öNICA tarea es crear prompts separados por "||PROMPT||". 

REGLAS CR√çTICAS:
1. SIEMPRE usa el delimitador exacto "||PROMPT||" (sin espacios adicionales)
2. NUNCA generes texto adicional fuera de los prompts
3. CUENTA cuidadosamente para generar el n√∫mero exacto solicitado
4. DIVIDE el contenido equitativamente entre todos los prompts
5. Cada prompt debe ser independiente y descriptivo

Si te piden N prompts, tu respuesta debe tener exactamente (N-1) delimitadores "||PROMPT||".`
        );

        const promptsText = promptsResponse.text || '';
        console.log(`üìù DEBUG SKIP - Respuesta del modelo: ${promptsText ? promptsText.substring(0, 200) + '...' : 'RESPUESTA VAC√çA'}`);
        console.log(`üîç DEBUG SKIP - Buscando delimitadores "||PROMPT||" en la respuesta...`);
        
        const imagePrompts = promptsText.split('||PROMPT||').filter(p => p.trim()).slice(0, numImages);
        console.log(`üîç DEBUG SKIP - Delimitadores encontrados: ${promptsText.split('||PROMPT||').length - 1}`);
        console.log(`üîç DEBUG SKIP - Prompts despu√©s del filtro: ${imagePrompts.length}`);
        console.log(`üî¢ DEBUG SKIP - Se solicitaron ${numImages} prompts, se generaron ${imagePrompts.length} prompts v√°lidos`);
        console.log(`üé® DEBUG SKIP - Primeros 3 prompts:`, imagePrompts.slice(0, 3));
        
        // Aplicar instrucciones adicionales a los prompts si existen
        enhancedPrompts = imagePrompts;
        if (additionalInstructions && additionalInstructions.trim()) {
          console.log(`‚úÖ DEBUG SKIP - Aplicando instrucciones adicionales a prompts: "${additionalInstructions}"`);
          enhancedPrompts = imagePrompts.map((prompt, index) => {
            const enhanced = `${prompt.trim()}. ${additionalInstructions.trim()}`;
            console.log(`üé® DEBUG SKIP - Prompt ${index + 1} mejorado: ${enhanced.substring(0, 100)}...`);
            return enhanced;
          });
        } else {
          console.log(`‚ùå DEBUG SKIP - No hay instrucciones adicionales para aplicar a prompts`);
        }
      }

      // Guardar los prompts como archivo de texto en la carpeta de la secci√≥n
      try {
        const promptsFileName = `${folderStructure.safeTopicName}_seccion_${section}_prompts_imagenes.txt`;
        const promptsFilePath = path.join(folderStructure.sectionDir, promptsFileName);
        
        const promptsContent = `PROMPTS DE IM√ÅGENES - SECCI√ìN ${section}
===============================
Tema: ${topic}
Secci√≥n: ${section} de ${sections}
Cantidad de prompts: ${enhancedPrompts.length}
Fecha de generaci√≥n: ${new Date().toLocaleString()}
${folderName ? `Nombre del proyecto: ${folderName}` : ''}
${additionalInstructions ? `Instrucciones adicionales aplicadas: ${additionalInstructions}` : 'Sin instrucciones adicionales'}

PROMPTS GENERADOS:
${enhancedPrompts.map((prompt, index) => `
${index + 1}. ${prompt.trim()}
`).join('')}

===============================
NOTA: Estos prompts fueron generados para ilustrar visualmente 
el contenido del gui√≥n pero no se generaron im√°genes porque 
la opci√≥n "Omitir generaci√≥n de im√°genes" estaba activada.

Puedes usar estos prompts en cualquier generador de im√°genes 
como Midjourney, DALL-E, Stable Diffusion, etc.
===============================
Generado autom√°ticamente por el sistema de creaci√≥n de contenido
`;
        
        fs.writeFileSync(promptsFilePath, promptsContent, 'utf8');
        console.log(`üìù Prompts de im√°genes guardados autom√°ticamente en: ${promptsFilePath}`);
        
        // Crear informaci√≥n sobre el archivo de prompts guardado
        const promptsFileRelativePath = path.relative('./public', promptsFilePath).replace(/\\/g, '/');
        
        console.log(`‚úÖ Archivo de prompts creado: ${promptsFileRelativePath}`);
      } catch (saveError) {
        console.error('‚ùå Error guardando archivo de prompts:', saveError);
        // No detener el proceso por este error, solo registrarlo
      }
      
      // Crear informaci√≥n sobre el archivo de gui√≥n guardado
      const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
      const scriptFilePath = path.relative('./public', path.join(folderStructure.sectionDir, scriptFileName)).replace(/\\/g, '/');

      // Crear informaci√≥n sobre el archivo de prompts guardado
      const promptsFileName = `${folderStructure.safeTopicName}_seccion_${section}_prompts_imagenes.txt`;
      const promptsFilePath = path.relative('./public', path.join(folderStructure.sectionDir, promptsFileName)).replace(/\\/g, '/');

      console.log(`üîç DEBUG SKIP - Enviando respuesta con imagePrompts:`, !!enhancedPrompts);
      console.log(`üîç DEBUG SKIP - imagePrompts.length:`, enhancedPrompts.length);
      console.log(`üîç DEBUG SKIP - imagesSkipped:`, shouldSkipImages && !shouldUseGoogleImages);
      console.log(`üîç DEBUG BING - bingImagesMode:`, shouldUseGoogleImages);
      console.log(`üîç DEBUG BING - downloadedImages.length:`, downloadedImages.length);

      // Construir respuesta seg√∫n el modo
      const response = { 
        script: cleanScript,
        scriptFile: {
          path: scriptFilePath,
          filename: scriptFileName,
          saved: true
        },
        promptsFile: {
          path: promptsFilePath,
          filename: promptsFileName,
          saved: true
        },
        voice: selectedVoice,
        currentSection: section,
        totalSections: sections,
        topic: topic,
        isComplete: section >= sections,
        projectFolder: folderStructure.safeTopicName,
        sectionFolder: `seccion_${section}`,
        folderPath: path.relative('./public', folderStructure.sectionDir).replace(/\\/g, '/'),
        chapterStructure: chapterStructure,
        tokenUsage: {
          inputTokens: inputTokens,
          outputTokens: outputTokens,
          totalTokens: totalTokens,
          model: selectedLlmModel
        }
      };

      // Agregar datos espec√≠ficos seg√∫n el modo
      if (shouldUseGoogleImages && downloadedImages.length > 0) {
        // Modo Bing Images: filtrar solo im√°genes exitosas que realmente existen
        const existingImages = downloadedImages.filter(img => {
          // Si la imagen fue marcada como fallida, no incluirla
          if (img.failed) {
            console.log(`‚ö†Ô∏è Imagen marcada como fallida, excluyendo: ${img.filename} (${img.keywords})`);
            return false;
          }
          
          const imagePath = path.join('./public', 'outputs', folderStructure.safeTopicName, `seccion_${section}`, img.filename);
          const exists = fs.existsSync(imagePath);
          if (!exists) {
            console.log(`‚ö†Ô∏è Archivo no encontrado, excluyendo de respuesta: ${img.filename}`);
          }
          return exists;
        });
        
        // Crear arrays de keywords solo para im√°genes exitosas para mantener correspondencia
        const successfulKeywords = existingImages.map(img => img.keywords);
        
        response.downloadedImages = existingImages.map(img => ({
          url: `/outputs/${folderStructure.safeTopicName}/seccion_${section}/${img.filename}`,
          caption: `Imagen de Bing: ${img.filename.replace(/\.[^/.]+$/, '')}`,
          filename: img.filename,
          path: img.path
        }));
        response.bingImagesMode = true;
        response.imagesDownloaded = existingImages.length;
        response.mode = 'bing_images';
        console.log(`‚úÖ Respuesta configurada para modo Bing con ${existingImages.length} im√°genes (${downloadedImages.length} descargadas, ${existingImages.length} existentes)`);
        
        // Usar keywords directamente de las im√°genes exitosas (ya filtradas)
        response.imageKeywords = successfulKeywords;
        console.log(`üéØ Keywords incluidas en respuesta (solo existentes):`, successfulKeywords);
        console.log(`üñºÔ∏è URLs de im√°genes:`, response.downloadedImages.map(img => img.url));
      } else if (shouldUseGoogleImages) {
        // Fallback si no se descargaron im√°genes de Bing
        response.imagePrompts = enhancedPrompts;
        response.bingImagesMode = true;
        response.bingImagesFailed = true;
        response.mode = 'bing_fallback';
        // Incluir las keywords para el bot√≥n de refresh
        if (imageKeywords && imageKeywords.length > 0) {
          response.imageKeywords = imageKeywords;
          console.log(`üéØ Keywords incluidas en respuesta fallback:`, imageKeywords);
        }
        console.log(`‚ö†Ô∏è Modo Bing fall√≥, usando prompts como fallback`);
      } else {
        // Modo skip images normal
        response.imagePrompts = enhancedPrompts;
        response.imagesSkipped = shouldSkipImages;
        response.mode = 'skip_images';
        console.log(`üìù Modo skip images con ${enhancedPrompts.length} prompts`);
      }

      res.json(response);

      console.log(`üö® RESPUESTA FINAL ENVIADA AL FRONTEND:`);
      console.log(`üö® response.downloadedImages:`, response.downloadedImages);
      console.log(`üö® response.bingImagesMode:`, response.bingImagesMode);
      console.log(`üö® response.mode:`, response.mode);
      console.log(`üö® Respuesta completa:`, JSON.stringify(response, null, 2));

      // Guardar estado del proyecto autom√°ticamente
      try {
        const projectData = {
          topic: topic,
          folderName: folderName,
          totalSections: sections,
          currentSection: section,
          voice: selectedVoice,
          imageModel: selectedImageModel,
          llmModel: selectedLlmModel,
          scriptStyle: scriptStyle,
          customStyleInstructions: customStyleInstructions,
          promptModifier: promptModifier,
          imageCount: imageCount,
          skipImages: shouldSkipImages,
          googleImages: shouldUseGoogleImages,
          applioVoice: applioVoice,
          applioModel: applioModel || 'fr-FR-RemyMultilingualNeural',
          applioPitch: applioPitch || 0,
          chapterStructure: chapterStructure
        };
        
        const savedState = saveProjectState(projectData);
        
        if (savedState) {
          // Actualizar secci√≥n completada
          const sectionData = {
            script: cleanScript,
            images: [], // Sin im√°genes en este modo
            imagesSkipped: shouldSkipImages && !shouldUseGoogleImages,
            googleImagesMode: shouldUseGoogleImages,
            imagePrompts: enhancedPrompts,
            scriptFile: {
              path: scriptFilePath,
              filename: scriptFileName,
              saved: true
            },
            promptsFile: {
              path: promptsFilePath,
              filename: promptsFileName,
              saved: true
            }
          };
          
          updateCompletedSection(projectData, section, sectionData);
          console.log(`üíæ Estado del proyecto guardado autom√°ticamente`);
        }
      } catch (saveError) {
        console.error('‚ö†Ô∏è Error guardando estado del proyecto:', saveError);
        // No detener el proceso por este error
      }
      return;
    }

    // Paso 2: Crear prompts para im√°genes secuenciales basadas en el gui√≥n
    console.log(`üé® Generando prompts para secuencia de ${numImages} im√°genes...`);
    const promptsResponse = await ai.models.generateContent({
      model: `models/${selectedLlmModel}`,
      contents: `Bas√°ndote en este gui√≥n de la secci√≥n ${section} sobre "${topic}" ": "${cleanScript}", crea EXACTAMENTE ${numImages} prompts detallados para generar una SECUENCIA de ${numImages} im√°genes que ilustren visualmente el contenido del gui√≥n en orden cronol√≥gico.

      IMPORTANTE: Debes crear EXACTAMENTE ${numImages} prompts, ni m√°s ni menos.

      ENFOQUE:
      - Las im√°genes deben seguir la narrativa del gui√≥n paso a paso
      - Cada imagen debe representar una parte espec√≠fica del gui√≥n en orden
      - Enf√≥cate en elementos del lore interno del juego mencionados en el gui√≥n
      - Ilustra lugares, personajes, eventos y elementos espec√≠ficos del gui√≥n
      - Mant√©n consistencia visual entre las ${numImages} im√°genes

      INSTRUCCIONES CR√çTICAS PARA EL FORMATO:
      - DEBES dividir el gui√≥n en EXACTAMENTE ${numImages} partes cronol√≥gicas
      - DEBES crear un prompt independiente para cada parte
      - DEBES separar cada prompt con "||PROMPT||" (sin espacios adicionales)
      - DEBES asegurarte de que haya exactamente ${numImages} prompts en tu respuesta
      - Las im√°genes deben contar la historia del gui√≥n de forma visual secuencial
      - Incluye detalles espec√≠ficos mencionados en el texto del gui√≥n

      REQUISITOS OBLIGATORIOS para cada prompt:
      - Formato: Aspecto 16:9 (widescreen)
      
      FORMATO DE RESPUESTA OBLIGATORIO:
      DEBES presentar EXACTAMENTE ${numImages} prompts separados por "||PROMPT||" (sin espacios antes o despu√©s del delimitador).
      
      ESTRUCTURA REQUERIDA:
      Prompt 1 aqu√≠||PROMPT||Prompt 2 aqu√≠||PROMPT||Prompt 3 aqu√≠||PROMPT||... hasta el Prompt ${numImages}
      
      EJEMPLO PARA 3 PROMPTS (adaptar a ${numImages}):
      Un bosque oscuro con √°rboles ancianos||PROMPT||Una batalla √©pica entre guerreros||PROMPT||Un castillo en ruinas bajo la luna
      
      VERIFICACI√ìN FINAL: Tu respuesta debe contener exactamente ${numImages - 1} ocurrencias del delimitador "||PROMPT||" para generar ${numImages} prompts.`,
      config: {
        systemInstruction: `Eres un experto en arte conceptual y narrativa visual. Tu √öNICA tarea es crear prompts separados por "||PROMPT||". 

REGLAS CR√çTICAS:
1. SIEMPRE usa el delimitador exacto "||PROMPT||" (sin espacios adicionales)
2. NUNCA generes texto adicional fuera de los prompts
3. CUENTA cuidadosamente para generar el n√∫mero exacto solicitado
4. DIVIDE el contenido equitativamente entre todos los prompts
5. Cada prompt debe ser independiente y descriptivo

Si te piden N prompts, tu respuesta debe tener exactamente (N-1) delimitadores "||PROMPT||".`,
      },
    });

    const promptsText = promptsResponse.text || '';
    console.log(`üìù Respuesta del modelo: ${promptsText ? promptsText.substring(0, 200) + '...' : 'RESPUESTA VAC√çA'}`);
    console.log(`üîç Buscando delimitadores "||PROMPT||" en la respuesta...`);
    
    const imagePrompts = promptsText.split('||PROMPT||').filter(p => p.trim()).slice(0, numImages);
    console.log(`üîç Delimitadores encontrados: ${promptsText.split('||PROMPT||').length - 1}`);
    console.log(`üîç Prompts despu√©s del filtro: ${imagePrompts.length}`);
    console.log(`üî¢ Se solicitaron ${numImages} im√°genes, se encontraron ${imagePrompts.length} prompts v√°lidos`);
    
    console.log(`üé® ${imagePrompts.length} prompts secuenciales generados para la secci√≥n ${section}`);

    // Paso 3: Generar las im√°genes secuenciales y guardarlas
    console.log(`üñºÔ∏è Generando secuencia de ${numImages} im√°genes...`);
    const imagePromises = imagePrompts.map(async (prompt, index) => {
      try {
        console.log(`üñºÔ∏è Generando imagen ${index + 1}/${numImages}...`);
        console.log(`üìã Prompt base para imagen ${index + 1}: ${prompt.trim().substring(0, 100)}...`);
        
        // Construir el prompt completo con estilo y agregar instrucciones adicionales al final
        let enhancedPrompt = `${prompt.trim()}.`;

        // Agregar instrucciones adicionales del usuario AL FINAL del prompt si existen
        if (additionalInstructions && additionalInstructions.trim()) {
          enhancedPrompt += `. ${additionalInstructions.trim()}`;
          console.log(`‚úÖ Instrucciones adicionales aplicadas al final de imagen ${index + 1}:`, additionalInstructions);
        } else {
          console.log(`‚ùå No hay instrucciones adicionales para imagen ${index + 1} (valor: "${additionalInstructions}")`);
        }
        
        console.log(`üìù Prompt completo para imagen ${index + 1}: ${enhancedPrompt}`);
        console.log(`ü§ñ Usando modelo: ${selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash (nativo)' : 'Imagen 4.0'}`);

        const imageResponse = await generateImageWithModel(ai, enhancedPrompt, selectedImageModel);

        if (imageResponse.generatedImages && imageResponse.generatedImages.length > 0) {
          const results = [];
          
          // Procesar las im√°genes generadas
          for (let varIndex = 0; varIndex < imageResponse.generatedImages.length; varIndex++) {
            const generatedImage = imageResponse.generatedImages[varIndex];
            const imageData = generatedImage.image.imageBytes;
            
            // Guardar imagen con nombre √∫nico
            const imageFileName = `${folderStructure.safeTopicName}_seccion_${section}_imagen_${index + 1}_${Date.now()}.png`;
            const imageFilePath = path.join(folderStructure.sectionDir, imageFileName);
            const imageBuffer = Buffer.from(imageData, 'base64');
            
            fs.writeFileSync(imageFilePath, imageBuffer);
            console.log(`üíæ Imagen ${index + 1} guardada en: ${imageFilePath}`);
            console.log(`ü§ñ Generada con: ${selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'}`);
            
            // Retornar ruta relativa para acceso web
            const relativePath = path.relative('./public', imageFilePath).replace(/\\/g, '/');
            
            results.push({ 
              index: index,
              originalPromptIndex: index,
              variationIndex: varIndex,
              image: imageData,
              imagePath: relativePath,
              prompt: enhancedPrompt,
              model: selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'
            });
          }
          
          return results;
        }
        return null;
      } catch (error) {
        console.error(`‚ùå Error generando imagen ${index + 1}:`, error);
        return null;
      }
    });

    const imageResults = await Promise.all(imagePromises);
    // Aplanar el array ya que cada prompt ahora devuelve un array de 3 im√°genes
    const allImages = imageResults.filter(result => result !== null).flat();

    if (allImages.length === 0) {
      return res.status(500).json({ error: 'No se pudo generar ninguna imagen' });
    }

    console.log(`‚úÖ ${allImages.length} im√°genes generadas (${imagePrompts.length} prompts √ó 3 variaciones cada uno) para la secci√≥n ${section}`);

    // Crear informaci√≥n sobre el archivo de gui√≥n guardado
    const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
    const scriptFilePath = path.relative('./public', path.join(folderStructure.sectionDir, scriptFileName)).replace(/\\/g, '/');

    res.json({ 
      images: allImages,
      script: cleanScript,
      scriptFile: {
        path: scriptFilePath,
        filename: scriptFileName,
        saved: true
      },
      imagePrompts: imagePrompts,
      voice: selectedVoice,
      sequenceType: 'chronological',
      currentSection: section,
      totalSections: sections,
      topic: topic,
      isComplete: section >= sections,
      projectFolder: folderStructure.safeTopicName,
      sectionFolder: `seccion_${section}`,
      folderPath: path.relative('./public', folderStructure.sectionDir).replace(/\\/g, '/'),
      chapterStructure: chapterStructure
    });

    // Guardar estado del proyecto autom√°ticamente
    try {
      const projectData = {
        topic: topic,
        folderName: folderName,
        totalSections: sections,
        currentSection: section,
        voice: selectedVoice,
        imageModel: selectedImageModel,
        llmModel: selectedLlmModel,
        scriptStyle: scriptStyle,
        customStyleInstructions: customStyleInstructions,
        promptModifier: promptModifier,
        imageCount: imageCount,
        skipImages: shouldSkipImages,
        googleImages: shouldUseGoogleImages,
        chapterStructure: chapterStructure
      };
      
      const savedState = saveProjectState(projectData);
      
      if (savedState) {
        // Actualizar secci√≥n completada
        const sectionData = {
          script: cleanScript,
          images: allImages,
          imagesSkipped: false,
          googleImagesMode: false,
          imagePrompts: imagePrompts,
          scriptFile: {
            path: scriptFilePath,
            filename: scriptFileName,
            saved: true
          }
        };
        
        updateCompletedSection(projectData, section, sectionData);
        console.log(`üíæ Estado del proyecto guardado autom√°ticamente`);
      }
    } catch (saveError) {
      console.error('‚ö†Ô∏è Error guardando estado del proyecto:', saveError);
      // No detener el proceso por este error
    }
  } catch (error) {
    console.error('‚ùå Error:', error);
    res.status(500).json({ error: 'Error generando contenido' });
  }
});

// RUTA COMENTADA - Ahora usamos el cliente Applio directo en Node.js
/*
// Nueva ruta simple para generar audio TTS (compatible con applio_tts)
app.post('/applio_tts', async (req, res) => {
  try {
    const { text, sectionDir } = req.body;
    
    if (!text || !text.trim()) {
      return res.status(400).json({ error: 'Texto requerido para generar audio' });
    }

    console.log(`üéµ Intentando TTS para texto: ${text.substring(0, 100)}...`);
    
    // Intentar primero con servidor Applio externo si est√° disponible
    const APPLIO_URL = process.env.APPLIO_SERVER_URL || "http://localhost:5004";
    
    try {
      console.log(`üîó Intentando conexi√≥n con servidor Applio en ${APPLIO_URL}...`);
      const applioResponse = await fetch(`${APPLIO_URL}/applio_tts`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text }),
        timeout: 5000 // 5 segundos timeout
      });
      
      if (applioResponse.ok) {
        console.log(`‚úÖ Servidor Applio respondi√≥ exitosamente`);
        // Reenviar la respuesta del servidor Applio
        const audioBuffer = await applioResponse.buffer();
        res.setHeader('Content-Type', 'audio/wav');
        res.setHeader('Content-Length', audioBuffer.length);
        return res.send(audioBuffer);
      }
    } catch (applioError) {
      console.log(`‚ö†Ô∏è Servidor Applio no disponible: ${applioError.message}`);
      console.log(`üîÑ Intentando con Gemini TTS como fallback...`);
    }
    
    // Fallback a Gemini TTS
    const response = await ai.models.generateContent({
      model: "gemini-2.5-pro-preview-tts",
      contents: [{ 
        parts: [{ 
          text: `Narra el siguiente texto de manera natural y clara: ${text}`
        }] 
      }],
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { 
              voiceName: 'Orus' 
            }
          }
        }
      }
    });

    const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    if (!audioData) {
      throw new Error('No se pudo generar el audio con Gemini TTS');
    }

    const audioBuffer = Buffer.from(audioData, 'base64');
    
    // Configurar headers para audio streaming
    res.setHeader('Content-Type', 'audio/wav');
    res.setHeader('Content-Length', audioBuffer.length);
    
    // Enviar el audio directamente como stream
    res.send(audioBuffer);
    
  } catch (error) {
    console.error('‚ùå Error en TTS:', error);
    
    // Mensaje m√°s espec√≠fico basado en el tipo de error
    let errorMessage = 'Error generando audio TTS';
    if (error.status === 429) {
      errorMessage = 'Cuota de TTS excedida. Intenta nuevamente en unos minutos o configura servidor Applio.';
    }
    
    res.status(500).json({ error: errorMessage });
  }
});
*/

// Nueva ruta para generar solo el audio del gui√≥n
app.post('/generate-audio', async (req, res) => {
  try {
    const { script, voice, topic, folderName, currentSection, narrationStyle } = req.body;
    
    if (!topic || !currentSection) {
      return res.status(400).json({ error: 'Tema y secci√≥n requeridos para organizar archivos' });
    }

    const selectedVoice = voice || 'Orus';
    const section = currentSection || 1;
    const customNarrationStyle = narrationStyle || null;
    
    // Si no se proporciona script, intentar leerlo del archivo guardado
    let scriptContent = script;
    if (!scriptContent) {
      console.log(`üîç Script no proporcionado, intentando leer archivo de secci√≥n ${section}...`);
      
      try {
        const folderStructure = createProjectStructure(topic, section, folderName);
        const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
        const scriptFilePath = path.join(folderStructure.sectionDir, scriptFileName);
        
        if (fs.existsSync(scriptFilePath)) {
          scriptContent = fs.readFileSync(scriptFilePath, 'utf8');
          console.log(`‚úÖ Script le√≠do desde archivo: ${scriptFilePath}`);
        } else {
          return res.status(400).json({ error: `No se encontr√≥ el gui√≥n para la secci√≥n ${section}. Archivo esperado: ${scriptFilePath}` });
        }
      } catch (readError) {
        console.error('‚ùå Error leyendo archivo de script:', readError);
        return res.status(400).json({ error: 'No se pudo leer el gui√≥n de la secci√≥n. Aseg√∫rate de que el gui√≥n se haya generado primero.' });
      }
    }
    
    if (!scriptContent || scriptContent.trim() === '') {
      return res.status(400).json({ error: 'Gui√≥n vac√≠o o no v√°lido' });
    }
    
    // Crear estructura de carpetas para el audio
    const folderStructure = createProjectStructure(topic, section, folderName);
    
    console.log(`üéµ Generando audio del gui√≥n con voz ${selectedVoice}...`);
    if (customNarrationStyle) {
      console.log(`üé≠ Estilo de narraci√≥n personalizado recibido: "${customNarrationStyle}"`);
    }
    
    try {
      const audioFilePath = await generateStoryAudio(scriptContent, selectedVoice, folderStructure.sectionDir, topic, section, customNarrationStyle);
      
      res.json({ 
        success: true,
        audio: audioFilePath,
        voice: selectedVoice,
        projectFolder: folderStructure.safeTopicName,
        sectionFolder: `seccion_${section}`
      });
    } catch (audioError) {
      console.error('‚ùå Error espec√≠fico en generaci√≥n de audio:', audioError.message);
      
      // Responder con informaci√≥n m√°s espec√≠fica sobre el error
      res.status(500).json({ 
        error: 'Error generando audio',
        details: audioError.message,
        suggestion: 'El servicio de Text-to-Speech puede estar temporalmente no disponible. Intenta nuevamente en unos momentos.'
      });
    }
  } catch (error) {
    console.error('‚ùå Error general en endpoint de audio:', error);
    res.status(500).json({ error: 'Error procesando solicitud de audio' });
  }
});

// Nueva ruta para regenerar una imagen espec√≠fica
app.post('/regenerate-image', async (req, res) => {
  try {
    const { prompt, imageIndex, topic, folderName, currentSection, imageModel } = req.body;
    
    if (!prompt || typeof imageIndex !== 'number') {
      return res.status(400).json({ error: 'Prompt e √≠ndice de imagen requeridos' });
    }

    if (!topic || !currentSection) {
      return res.status(400).json({ error: 'Tema y secci√≥n requeridos para organizar archivos' });
    }

    const selectedImageModel = 'gemini2'; // TEMPORAL: Forzar Gemini 2.0 para depuraci√≥n
    console.log(`üîÑ Regenerando imagen ${imageIndex + 1} con nuevo prompt...`);
    console.log(`ü§ñ Forzando uso de Gemini 2.0 Flash para depuraci√≥n...`);
    console.log(`üîç Modelo recibido del frontend: ${imageModel}`);
    console.log(`üîç Modelo que se usar√°: ${selectedImageModel}`);
    
    // Crear estructura de carpetas
    const folderStructure = createProjectStructure(topic, currentSection, folderName);
    
    try {
      console.log(`üîç DEBUG REGENERACION - Iniciando proceso de regeneraci√≥n...`);
      console.log(`üîç DEBUG REGENERACION - Prompt recibido: ${prompt.substring(0, 50)}...`);
      
      // Agregar especificaciones de estilo oscuro 2D al prompt
      const enhancedPrompt = `${prompt.trim()}. `;
      console.log(`üîç DEBUG REGENERACION - Enhanced prompt: ${enhancedPrompt.substring(0, 50)}...`);
      console.log(`üîç DEBUG REGENERACION - Llamando a generateImageWithModel con modelo: ${selectedImageModel}`);

      const imageResponse = await generateImageWithModel(ai, enhancedPrompt, selectedImageModel);
      console.log(`üîç DEBUG REGENERACION - Respuesta recibida:`, !!imageResponse);

      if (imageResponse.generatedImages && imageResponse.generatedImages.length > 0) {
        const regeneratedImages = [];
        
        // Procesar las im√°genes generadas
        for (let varIndex = 0; varIndex < imageResponse.generatedImages.length; varIndex++) {
          const generatedImage = imageResponse.generatedImages[varIndex];
          const imageData = generatedImage.image.imageBytes;
          
          // Guardar imagen regenerada con un nombre √∫nico
          const timestamp = Date.now();
          const imageFileName = `${folderStructure.safeTopicName}_seccion_${currentSection}_imagen_${imageIndex + 1}_regenerated_${timestamp}.png`;
          const imageFilePath = path.join(folderStructure.sectionDir, imageFileName);
          const imageBuffer = Buffer.from(imageData, 'base64');
          
          fs.writeFileSync(imageFilePath, imageBuffer);
          console.log(`üíæ Imagen regenerada ${imageIndex + 1} guardada en: ${imageFilePath}`);
          console.log(`ü§ñ Regenerada con: ${selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'}`);
          
          // Retornar ruta relativa para acceso web
          const relativePath = path.relative('./public', imageFilePath).replace(/\\/g, '/');
          
          regeneratedImages.push({
            image: imageData,
            imagePath: relativePath,
            variationIndex: varIndex,
            model: selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'
          });
        }
        
        res.json({ 
          success: true,
          images: regeneratedImages,
          prompt: enhancedPrompt,
          imageIndex: imageIndex,
          model: selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'
        });
        return;
      }
      
      res.status(500).json({ error: 'No se pudo regenerar la imagen' });
      
    } catch (error) {
      console.error('‚ùå Error regenerando imagen:', error.message);
      res.status(500).json({ 
        error: 'Error regenerando imagen',
        details: error.message
      });
    }
  } catch (error) {
    console.error('‚ùå Error general en endpoint de regenerar imagen:', error);
    res.status(500).json({ error: 'Error procesando solicitud de regeneraci√≥n' });
  }
});

// Nueva ruta para generar audio de secci√≥n espec√≠fica usando cliente Applio Node.js
app.post('/generate-section-audio', async (req, res) => {
  try {
    const { script, topic, folderName, currentSection, voice, applioVoice, applioModel, applioPitch } = req.body;
    
    if (!script || !topic || !currentSection) {
      return res.status(400).json({ 
        error: 'Script, tema y n√∫mero de secci√≥n son requeridos' 
      });
    }

    const section = parseInt(currentSection);
    const selectedApplioVoice = applioVoice || "logs\\VOCES\\RemyOriginal.pth";
    const selectedApplioModel = applioModel || "fr-FR-RemyMultilingualNeural";
    const selectedPitch = parseInt(applioPitch) || 0;
    
    // Crear estructura de carpetas
    const folderStructure = createProjectStructure(topic, section, folderName);
    
    console.log(`üéµ Generando audio con Applio Node.js para secci√≥n ${section}...`);
    console.log(`üé§ Voz de Applio seleccionada: ${selectedApplioVoice}`);
    console.log(`üéõÔ∏è Modelo TTS seleccionado: ${selectedApplioModel}`);
    console.log(`üéµ Pitch seleccionado: ${selectedPitch}`);
    
    try {
      // Verificar conexi√≥n con Applio primero
      const isConnected = await applioClient.checkConnection();
      if (!isConnected) {
        throw new Error('Applio no est√° disponible en el puerto 6969');
      }
      
      // Crear nombre del archivo
      const safeTopicName = createSafeFolderName(topic);
      const fileName = `${safeTopicName}_seccion_${section}_applio_${Date.now()}.wav`;
      const filePath = path.join(folderStructure.sectionDir, fileName);
      
      console.log(`üìÅ Guardando audio en: ${filePath}`);
      
      // Generar audio con Applio
      const result = await applioClient.textToSpeech(script, filePath, {
        model: selectedApplioModel,
        speed: 0,
        pitch: selectedPitch,
        voicePath: selectedApplioVoice
      });
      
      if (!result.success) {
        throw new Error('Applio no gener√≥ el audio correctamente');
      }
      
      console.log(`‚úÖ Audio Applio generado exitosamente: ${filePath}`);
      console.log(`üìä Tama√±o del archivo: ${(result.size / 1024).toFixed(1)} KB`);
      
      // Retornar la ruta relativa para acceso web
      const relativePath = path.relative('./public', filePath).replace(/\\/g, '/');
      
      res.json({ 
        success: true,
        audioFile: relativePath,
        method: 'Applio Node.js',
        section: section,
        size: result.size,
        message: `Audio generado con Applio para la secci√≥n ${section}`
      });
      
    } catch (applioError) {
      console.error('‚ùå Error con cliente Applio Node.js:', applioError);
      
      if (applioError.message.includes('6969') || applioError.message.includes('Timeout')) {
        res.status(503).json({ 
          error: 'Applio no disponible',
          details: 'Aseg√∫rate de que Applio est√© corriendo en el puerto 6969',
          suggestion: 'Abre la interfaz de Applio y verifica que est√© en el puerto 6969'
        });
      } else {
        res.status(500).json({ 
          error: 'Error generando audio con Applio',
          details: applioError.message
        });
      }
    }
    
  } catch (error) {
    console.error('‚ùå Error general:', error);
    res.status(500).json({ error: 'Error procesando solicitud' });
  }
});

// Ruta para subir archivo para transcripci√≥n
app.post('/upload-audio', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No se recibi√≥ ning√∫n archivo' });
    }

    console.log(`üìÅ Archivo subido: ${req.file.filename}`);
    res.json({ 
      success: true, 
      filePath: req.file.path,
      originalName: req.file.originalname 
    });
    
  } catch (error) {
    console.error('‚ùå Error subiendo archivo:', error);
    res.status(500).json({ error: 'Error subiendo archivo: ' + error.message });
  }
});

// Ruta para obtener pistas de audio de un archivo
app.post('/get-audio-tracks', async (req, res) => {
  try {
    const { filePath } = req.body;
    
    if (!filePath) {
      return res.status(400).json({ error: 'Ruta del archivo requerida' });
    }

    console.log(`üéµ Obteniendo pistas de audio de: ${filePath}`);
    const tracks = await getAudioTracks(filePath);
    
    res.json({ tracks });
  } catch (error) {
    console.error('‚ùå Error obteniendo pistas de audio:', error);
    res.status(500).json({ error: 'Error obteniendo pistas de audio: ' + error.message });
  }
});

// Ruta para transcribir audio/video con Whisper LOCAL
app.post('/transcribe-audio-local', async (req, res) => {
  try {
    const { filePath, audioTrackIndex, modelSize = 'medium', language } = req.body;
    
    if (!filePath) {
      return res.status(400).json({ error: 'Ruta del archivo requerida' });
    }

    console.log(`üé§ Iniciando transcripci√≥n LOCAL de: ${filePath}`);
    console.log(`üîß Modelo: ${modelSize} | Idioma: ${language || 'auto-detectar'}`);
    if (audioTrackIndex !== undefined) {
      console.log(`üì° Usando pista de audio: ${audioTrackIndex}`);
    }

    // Importar din√°micamente el m√≥dulo local de Python
    const { spawn } = await import('child_process');
    
    // Crear script Python temporal para la transcripci√≥n
    const pythonScript = `
# -*- coding: utf-8 -*-
import sys
import json
import os
import subprocess
import tempfile
import shutil
from pathlib import Path

# Configurar codificaci√≥n UTF-8 para Windows
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

sys.path.append('${process.cwd().replace(/\\/g, '/')}')

from whisper_local import whisper_local

def extract_audio_from_mp4(input_path, output_path, track_index=None):
    """Extrae audio de MP4 usando FFmpeg"""
    try:
        cmd = ['ffmpeg', '-y', '-i', input_path]
        
        if track_index is not None:
            cmd.extend(['-map', f'0:a:{track_index}'])
        else:
            cmd.extend(['-map', '0:a:0'])  # Primera pista de audio por defecto
        
        cmd.extend(['-acodec', 'libmp3lame', '-ab', '192k', output_path])
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"Error FFmpeg: {result.stderr}")
            return False
        
        return True
        
    except Exception as e:
        print(f"Error extrayendo audio: {e}")
        return False

def main():
    file_path = r'${filePath}'
    audio_track_index = ${audioTrackIndex || 'None'}
    model_size = '${modelSize}'
    language = ${language ? `'${language}'` : 'None'}
    
    temp_audio_file = None
    
    try:
        # Verificar que el archivo existe
        if not os.path.exists(file_path):
            raise Exception(f"Archivo no encontrado: {file_path}")
        
        # Determinar archivo de audio a procesar
        if file_path.lower().endswith('.mp4'):
            # Extraer audio de MP4
            temp_audio_file = tempfile.mktemp(suffix='.mp3')
            print(f"Extrayendo audio de MP4 a: {temp_audio_file}")
            
            if not extract_audio_from_mp4(file_path, temp_audio_file, audio_track_index):
                raise Exception("Error extrayendo audio del MP4")
            
            audio_file = temp_audio_file
        else:
            # Usar archivo de audio directamente
            audio_file = file_path
        
        # Cargar modelo si no est√° cargado
        if not whisper_local.is_loaded or whisper_local.model_size != model_size:
            print(f"Cargando modelo {model_size}...")
            if not whisper_local.load_model(model_size):
                raise Exception(f"No se pudo cargar el modelo {model_size}")
        
        # Transcribir
        print(f"Transcribiendo archivo: {os.path.basename(audio_file)}")
        result = whisper_local.transcribe_audio(audio_file, language)
        
        if result['success']:
            print(json.dumps({
                'success': True,
                'transcript': result['transcript'],
                'language': result['language'],
                'duration': result['duration'],
                'model_info': result['model_info'],
                'stats': result['stats']
            }, ensure_ascii=False))
        else:
            print(json.dumps({
                'success': False,
                'error': result['error']
            }, ensure_ascii=False))
            
    except Exception as e:
        print(json.dumps({
            'success': False,
            'error': str(e)
        }, ensure_ascii=False))
    
    finally:
        # Limpiar archivo temporal de audio si se cre√≥
        if temp_audio_file and os.path.exists(temp_audio_file):
            try:
                os.unlink(temp_audio_file)
                print(f"Archivo temporal de audio eliminado: {temp_audio_file}")
            except:
                pass

if __name__ == '__main__':
    main()
`;

    // Escribir script temporal
    const tempScriptPath = path.join(process.cwd(), 'temp', `transcribe_${Date.now()}.py`);
    fs.mkdirSync(path.dirname(tempScriptPath), { recursive: true });
    fs.writeFileSync(tempScriptPath, pythonScript);

    // Ejecutar transcripci√≥n
    const pythonProcess = spawn('python', [tempScriptPath], {
      cwd: process.cwd(),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: { 
        ...process.env, 
        PYTHONIOENCODING: 'utf-8',
        PYTHONUTF8: '1'
      }
    });

    let stdout = '';
    let stderr = '';

    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });

    pythonProcess.stderr.on('data', (data) => {
      stderr += data.toString();
    });

    pythonProcess.on('close', (code) => {
      // Limpiar script temporal
      try {
        fs.unlinkSync(tempScriptPath);
      } catch (e) {
        console.warn('No se pudo eliminar script temporal:', e.message);
      }

      // Limpiar archivo de audio temporal
      try {
        if (fs.existsSync(filePath)) {
          fs.unlinkSync(filePath);
          console.log(`üóëÔ∏è Archivo temporal eliminado: ${filePath}`);
        }
      } catch (cleanupError) {
        console.warn('‚ö†Ô∏è No se pudo eliminar archivo temporal:', cleanupError.message);
      }

      if (code !== 0) {
        console.error('‚ùå Error en transcripci√≥n local:', stderr);
        return res.status(500).json({ 
          error: 'Error en transcripci√≥n local: ' + stderr,
          stdout: stdout 
        });
      }

      try {
        // Buscar la √∫ltima l√≠nea que sea JSON v√°lido
        const lines = stdout.trim().split('\n');
        let result = null;
        
        for (let i = lines.length - 1; i >= 0; i--) {
          try {
            result = JSON.parse(lines[i]);
            break;
          } catch (e) {
            continue;
          }
        }

        if (!result) {
          throw new Error('No se pudo parsear el resultado');
        }

        if (result.success) {
          console.log(`‚úÖ Transcripci√≥n LOCAL completada. Caracteres: ${result.transcript.length}`);
          console.log(`üìä Velocidad: ${result.stats.processing_speed.toFixed(1)}x tiempo real`);
          console.log(`üåç Idioma: ${result.language}`);
          
          res.json({
            transcript: result.transcript,
            language: result.language,
            duration: result.duration,
            model_info: result.model_info,
            stats: result.stats,
            method: 'local'
          });
        } else {
          throw new Error(result.error);
        }

      } catch (parseError) {
        console.error('‚ùå Error parseando resultado:', parseError);
        console.log('Raw stdout:', stdout);
        res.status(500).json({ 
          error: 'Error parseando resultado de transcripci√≥n',
          stdout: stdout,
          stderr: stderr 
        });
      }
    });

    pythonProcess.on('error', (error) => {
      console.error('‚ùå Error ejecutando Python:', error);
      res.status(500).json({ error: 'Error ejecutando transcripci√≥n local: ' + error.message });
    });
    
  } catch (error) {
    console.error('‚ùå Error en transcripci√≥n local:', error);
    res.status(500).json({ error: 'Error en transcripci√≥n local: ' + error.message });
  }
});

// Ruta para obtener las voces disponibles de Applio
app.get('/api/applio-voices', (req, res) => {
  try {
    console.log('üé§ Solicitando lista de voces de Applio...');
    const voices = getAvailableVoices();
    
    res.json({
      success: true,
      voices: voices,
      count: voices.length
    });
    
    console.log(`‚úÖ Enviadas ${voices.length} voces al cliente`);
  } catch (error) {
    console.error('‚ùå Error obteniendo voces:', error);
    res.status(500).json({
      success: false,
      error: 'Error al obtener las voces disponibles',
      voices: [{
        name: 'RemyOriginal (Default)',
        path: 'logs\\VOCES\\RemyOriginal.pth',
        displayName: 'RemyOriginal'
      }]
    });
  }
});

// Ruta para obtener informaci√≥n del modelo local
app.get('/whisper-local-info', async (req, res) => {
  try {
    const { spawn } = await import('child_process');
    
    const pythonScript = `
import sys
import json
sys.path.append('${process.cwd().replace(/\\/g, '/')}')

from whisper_local import whisper_local

try:
    info = whisper_local.get_model_info()
    print(json.dumps(info))
except Exception as e:
    print(json.dumps({'error': str(e)}))
`;

    const tempScriptPath = path.join(process.cwd(), 'temp', `info_${Date.now()}.py`);
    fs.mkdirSync(path.dirname(tempScriptPath), { recursive: true });
    fs.writeFileSync(tempScriptPath, pythonScript);

    const pythonProcess = spawn('python', [tempScriptPath], {
      env: { 
        ...process.env, 
        PYTHONIOENCODING: 'utf-8',
        PYTHONUTF8: '1'
      }
    });
    let stdout = '';

    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });

    pythonProcess.on('close', (code) => {
      try {
        fs.unlinkSync(tempScriptPath);
      } catch (e) {}

      try {
        const result = JSON.parse(stdout.trim());
        res.json(result);
      } catch (error) {
        res.status(500).json({ error: 'Error obteniendo informaci√≥n del modelo' });
      }
    });

  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Ruta para transcribir audio/video
app.post('/transcribe-audio', async (req, res) => {
  try {
    const { filePath, audioTrackIndex } = req.body;
    
    if (!filePath) {
      return res.status(400).json({ error: 'Ruta del archivo requerida' });
    }

    console.log(`üé§ Iniciando transcripci√≥n de: ${filePath}`);
    if (audioTrackIndex !== undefined) {
      console.log(`üì° Usando pista de audio: ${audioTrackIndex}`);
    }

    const transcript = await transcribeAudio({
      filePath,
      audioTrackIndex,
      onUploadProgress: (percent) => {
        // Aqu√≠ podr√≠as implementar WebSockets para progreso en tiempo real si quisieras
        console.log(`üìä Progreso de transcripci√≥n: ${percent}%`);
      }
    });

    console.log(`‚úÖ Transcripci√≥n completada. Caracteres: ${transcript.length}`);
    
    // Limpiar archivo temporal despu√©s de la transcripci√≥n
    try {
      if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
        console.log(`üóëÔ∏è Archivo temporal eliminado: ${filePath}`);
      }
    } catch (cleanupError) {
      console.warn('‚ö†Ô∏è No se pudo eliminar archivo temporal:', cleanupError.message);
    }
    
    res.json({ transcript });
    
  } catch (error) {
    console.error('‚ùå Error transcribiendo audio:', error);
    res.status(500).json({ error: 'Error transcribiendo audio: ' + error.message });
  }
});

// Endpoint para generar t√≠tulos, descripci√≥n y etiquetas para YouTube
app.post('/generate-youtube-metadata', async (req, res) => {
  try {
    const { topic, allSections, folderName, thumbnailStyle } = req.body;

    if (!topic || !allSections || allSections.length === 0) {
      return res.status(400).json({ error: 'Tema y secciones requeridos' });
    }

    console.log(`üé¨ Generando metadata de YouTube para: ${topic}`);
    console.log(`üìù N√∫mero de secciones: ${allSections.length}`);
    console.log(`üñºÔ∏è Estilo de miniatura: ${thumbnailStyle || 'default'}`);

    // Combinar todas las secciones en un resumen
    const fullScript = allSections.join('\n\n--- SECCI√ìN ---\n\n');

    // Obtener instrucciones de estilo de miniatura
    const thumbnailInstructions = getThumbnailStyleInstructions(thumbnailStyle || 'default');
    
    console.log(`üé® thumbnailStyle recibido:`, thumbnailStyle);
    console.log(`üìù thumbnailInstructions generadas:`, thumbnailInstructions);

    const prompt = `
Bas√°ndote en el siguiente tema y gui√≥n completo del video, genera metadata optimizada para YouTube:

**TEMA:** ${topic}

**GUI√ìN COMPLETO:**
${fullScript}

Por favor genera:

1. **10 T√çTULOS CLICKBAIT** (cada uno en una l√≠nea, numerados):
   - Usa palabras que generen curiosidad como "QUE PASA CUANDO", "POR QUE", "HICE ESTO Y PASO ESTO", "NO VAS A CREER", "ESTO CAMBI√ì TODO"
   - Que sean pol√©micos pero relacionados al contenido
   - maximo 15 palabras, minimo 10.

2. **DESCRIPCI√ìN PARA VIDEO** (optimizada para SEO):
   - Entre 150-300 palabras
   - Incluye palabras clave relevantes del tema
   - Menciona el contenido principal del video
   - Incluye call-to-action para suscribirse
   - Formato atractivo con emojis

3. **25 ETIQUETAS** (separadas por comas):
   - Palabras clave relacionadas al tema
   - Tags populares del nicho correspondiente
   - T√©rminos de b√∫squeda relevantes
   - Sin espacios en tags compuestos (usar guiones o camelCase)

4. **5 PROMPTS PARA MINIATURAS DE YOUTUBE** (cada uno en una l√≠nea, numerados):
   
   FORMATO OBLIGATORIO - DEBES SEGUIR ESTA ESTRUCTURA EXACTA PARA CADA UNO DE LOS 5 PROMPTS:
   
   "Miniatura de YouTube 16:9 mostrando [descripci√≥n visual muy detallada del contenido relacionado al tema, m√≠nimo 15 palabras] con texto superpuesto '[frase clickbait espec√≠fica relacionada al contenido]' con el texto aplicando el siguiente estilo: ${thumbnailInstructions}"
   
   REGLAS ESTRICTAS - NO GENERAR PROMPTS CORTOS O INCOMPLETOS:
   - CADA prompt debe tener m√≠nimo 25 palabras de descripci√≥n visual
   - CADA prompt debe incluir una frase clickbait espec√≠fica entre comillas
   - CADA prompt debe terminar con la frase completa del estilo
   - NO generar prompts como "el texto con contorno negro" - ESO EST√Å PROHIBIDO
   - TODOS los prompts deben seguir el formato completo
   
   EJEMPLO DE FORMATO CORRECTO (SEGUIR EXACTAMENTE ESTA ESTRUCTURA):
   1. Miniatura de YouTube 16:9 mostrando a Link adulto con expresi√≥n de shock mirando directamente a la c√°mara mientras sostiene la Master Sword brillante, con el Castillo de Hyrule destruido de fondo y llamas rojas. El rostro de Link debe mostrar sorpresa extrema con ojos muy abiertos con texto superpuesto "¬°ZELDA EST√Å MUERTA!" con el texto aplicando el siguiente estilo: ${thumbnailInstructions}

REGLAS ESTRICTAS:
- EXACTAMENTE 5 prompts numerados del 1 al 5
- Cada prompt debe incluir la frase completa del estilo al final
- NO hacer referencias a estilos anteriores
- Descripci√≥n visual espec√≠fica y detallada en cada uno
IMPORTANTE: 
- Genera EXACTAMENTE 5 prompts completos, numerados del 1 al 5
- Cada prompt debe ser una oraci√≥n completa y detallada (m√≠nimo 25 palabras)
- SIEMPRE incluye la frase completa del estilo al final de cada prompt
- NO usar "aplicando el estilo especificado anteriormente" NUNCA
- NO generar prompts cortos como "el texto con contorno negro" - ESTO EST√Å PROHIBIDO
- VERIFICA que cada prompt tenga: descripci√≥n visual + frase clickbait + estilo completo
- Si un prompt sale corto, reescr√≠belo completo


Formato de respuesta:
**T√çTULOS CLICKBAIT:**
1. [t√≠tulo]
2. [t√≠tulo]
...

**DESCRIPCI√ìN:**
[descripci√≥n completa]

**ETIQUETAS:**
tag1, tag2, tag3, ...

**PROMPTS PARA MINIATURAS:**
1. [prompt completo para miniatura]
2. [prompt completo para miniatura]  
3. [prompt completo para miniatura]
4. [prompt completo para miniatura]
5. [prompt completo para miniatura]
    `;

    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-exp",
      contents: [{
        role: "user",
        parts: [{ text: prompt }]
      }]
    });

    const responseText = response.text;

    // Validar que los prompts de miniatura no est√©n incompletos
    const thumbnailSection = responseText.match(/\*\*PROMPTS PARA MINIATURAS:\*\*([\s\S]*?)(?=\n\n|$)/);
    if (thumbnailSection) {
      const thumbnailPrompts = thumbnailSection[1].trim().split('\n').filter(line => line.trim());
      
      // Verificar prompts incompletos
      const incompletePrompts = thumbnailPrompts.filter(prompt => {
        const cleanPrompt = prompt.replace(/^\d+\.\s*/, '').trim();
        return cleanPrompt.length < 50 || 
               cleanPrompt.includes('el texto con contorno negro y muy brillante el texto') ||
               !cleanPrompt.includes('con el texto aplicando el siguiente estilo:');
      });
      
      if (incompletePrompts.length > 0) {
        console.log(`‚ö†Ô∏è Detectados ${incompletePrompts.length} prompts incompletos, regenerando...`);
        console.log('Prompts problem√°ticos:', incompletePrompts);
        
        // Regenerar solo la secci√≥n de prompts
        const regeneratePrompt = `
Genera EXACTAMENTE 5 prompts completos para miniaturas de YouTube sobre: ${topic}

FORMATO OBLIGATORIO para cada prompt:
"Miniatura de YouTube 16:9 mostrando [descripci√≥n visual muy detallada, m√≠nimo 20 palabras] con texto superpuesto '[frase clickbait espec√≠fica]' con el texto aplicando el siguiente estilo: ${thumbnailInstructions}"

REGLAS ESTRICTAS:
- Cada prompt debe tener m√≠nimo 30 palabras
- NUNCA generar "el texto con contorno negro y muy brillante el texto"
- TODOS deben incluir la frase completa del estilo al final
- Numerar del 1 al 5

1. [prompt completo]
2. [prompt completo]
3. [prompt completo]
4. [prompt completo]
5. [prompt completo]
        `;
        
        const regenerateResponse = await ai.models.generateContent({
          model: "gemini-2.0-flash-exp",
          contents: [{
            role: "user",
            parts: [{ text: regeneratePrompt }]
          }]
        });
        
        // Reemplazar la secci√≥n de prompts en la respuesta original
        const newThumbnailPrompts = regenerateResponse.text.trim();
        const updatedResponse = responseText.replace(
          /(\*\*PROMPTS PARA MINIATURAS:\*\*)([\s\S]*?)(?=\n\n|$)/,
          `$1\n${newThumbnailPrompts}`
        );
        
        console.log(`‚úÖ Prompts regenerados exitosamente`);
        
        // Guardar los metadatos en archivo con los prompts corregidos
        try {
          const safeFolderName = folderName && folderName.trim() 
            ? createSafeFolderName(folderName.trim())
            : createSafeFolderName(topic);
            
          const outputsDir = path.join('./public/outputs');
          const projectDir = path.join(outputsDir, safeFolderName);
          
          if (!fs.existsSync(outputsDir)) {
            fs.mkdirSync(outputsDir, { recursive: true });
          }
          if (!fs.existsSync(projectDir)) {
            fs.mkdirSync(projectDir, { recursive: true });
          }
          
          const metadataFileName = `${safeFolderName}_metadata_youtube.txt`;
          const metadataFilePath = path.join(projectDir, metadataFileName);
          
          const metadataContent = `METADATA DE YOUTUBE
===============================
Tema: ${topic}
N√∫mero de secciones: ${allSections.length}
${folderName ? `Nombre del proyecto: ${folderName}` : ''}
Fecha de generaci√≥n: ${new Date().toLocaleString()}

CONTENIDO DE METADATA:
${updatedResponse}

===============================
Generado autom√°ticamente por el sistema de creaci√≥n de contenido
`;
          
          fs.writeFileSync(metadataFilePath, metadataContent, 'utf8');
          console.log(`üíæ Metadata de YouTube guardada (con prompts corregidos): ${metadataFilePath}`);
          
        } catch (saveError) {
          console.error('‚ùå Error guardando archivo de metadata:', saveError);
        }
        
        return res.json({ 
          success: true, 
          metadata: updatedResponse,
          message: 'Metadata generada exitosamente (con prompts corregidos)' 
        });
      }
    }

    console.log(`‚úÖ Metadata de YouTube generada exitosamente`);
    
    // Guardar los metadatos en archivo
    try {
      // Usar el mismo sistema que las secciones para determinar el nombre de carpeta
      const safeFolderName = folderName && folderName.trim() 
        ? createSafeFolderName(folderName.trim())
        : createSafeFolderName(topic);
        
      const outputsDir = path.join('./public/outputs');
      const projectDir = path.join(outputsDir, safeFolderName);
      
      // Crear carpetas si no existen
      if (!fs.existsSync(outputsDir)) {
        fs.mkdirSync(outputsDir, { recursive: true });
      }
      if (!fs.existsSync(projectDir)) {
        fs.mkdirSync(projectDir, { recursive: true });
      }
      
      // Guardar en la misma carpeta donde est√°n las secciones del gui√≥n
      const metadataFileName = `${safeFolderName}_metadata_youtube.txt`;
      const metadataFilePath = path.join(projectDir, metadataFileName);
      
      const metadataContent = `METADATA DE YOUTUBE
===============================
Tema: ${topic}
N√∫mero de secciones: ${allSections.length}
${folderName ? `Nombre del proyecto: ${folderName}` : ''}
Fecha de generaci√≥n: ${new Date().toLocaleString()}

CONTENIDO DE METADATA:
${responseText}

===============================
Generado autom√°ticamente por el sistema de creaci√≥n de contenido
`;
      
      fs.writeFileSync(metadataFilePath, metadataContent, 'utf8');
      console.log(`üíæ Metadata de YouTube guardada en la carpeta del proyecto: ${metadataFilePath}`);
      
    } catch (saveError) {
      console.error('‚ùå Error guardando archivo de metadata:', saveError);
      // No detener el proceso por este error, solo registrarlo
    }
    
    res.json({
      success: true,
      metadata: responseText,
      topic: topic,
      sectionsCount: allSections.length
    });

  } catch (error) {
    console.error('‚ùå Error generando metadata de YouTube:', error);
    res.status(500).json({ 
      success: false, 
      error: 'Error generando metadata de YouTube: ' + error.message 
    });
  }
});

// ================================
// RUTAS PARA SISTEMA DE PROYECTOS
// ================================

// Ruta para obtener lista de proyectos disponibles
app.get('/api/projects', (req, res) => {
  try {
    console.log('üì° API /api/projects llamada');
    const projects = getAvailableProjects();
    console.log('üìä Proyectos encontrados:', projects.length);
    res.json({ success: true, projects });
  } catch (error) {
    console.error('‚ùå Error obteniendo proyectos:', error);
    res.status(500).json({ success: false, error: 'Error obteniendo proyectos: ' + error.message });
  }
});

// Ruta para cargar un proyecto espec√≠fico
app.get('/api/projects/:folderName', (req, res) => {
  try {
    const { folderName } = req.params;
    const projectState = loadProjectState(folderName);
    
    if (!projectState) {
      return res.status(404).json({ success: false, error: 'Proyecto no encontrado' });
    }
    
    res.json({ success: true, project: projectState });
  } catch (error) {
    console.error('‚ùå Error cargando proyecto:', error);
    res.status(500).json({ success: false, error: 'Error cargando proyecto' });
  }
});

// Endpoint para obtener im√°genes de una secci√≥n espec√≠fica
app.get('/api/project-images/:folderName/:sectionNumber', (req, res) => {
  try {
    const { folderName, sectionNumber } = req.params;
    const projectDir = path.join('./public/outputs', folderName);
    const sectionDir = path.join(projectDir, `seccion_${sectionNumber}`);
    
    console.log(`üñºÔ∏è Buscando im√°genes en: ${sectionDir}`);
    
    if (!fs.existsSync(sectionDir)) {
      console.log(`üìÅ Directorio de secci√≥n no encontrado: ${sectionDir}`);
      return res.json({ success: true, images: [], keywords: [], prompts: [] });
    }
    
    // Buscar archivos de imagen
    const imageExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'];
    const files = fs.readdirSync(sectionDir);
    const imageFiles = files.filter(file => 
      imageExtensions.includes(path.extname(file).toLowerCase())
    );
    
    console.log(`üñºÔ∏è Archivos de imagen encontrados: ${imageFiles.length}`);
    
    // Crear URLs para las im√°genes
    const images = imageFiles.map(filename => ({
      url: `/outputs/${folderName}/seccion_${sectionNumber}/${filename}`,
      filename: filename,
      caption: `Imagen: ${filename}`,
      path: path.join(sectionDir, filename)
    }));
    
    // Buscar archivo de keywords
    let keywords = [];
    const keywordsFile = path.join(sectionDir, `${folderName}_seccion_${sectionNumber}_keywords.txt`);
    if (fs.existsSync(keywordsFile)) {
      try {
        const keywordsContent = fs.readFileSync(keywordsFile, 'utf8');
        keywords = keywordsContent.split('\n').filter(line => line.trim());
        console.log(`üìã Keywords cargadas desde archivo keywords: ${keywords.length}`);
      } catch (error) {
        console.warn(`‚ö†Ô∏è Error leyendo keywords: ${error.message}`);
      }
    } else {
      // Intentar extraer keywords del archivo de prompts como fallback
      const promptsFile = path.join(sectionDir, `${folderName}_seccion_${sectionNumber}_prompts_imagenes.txt`);
      if (fs.existsSync(promptsFile)) {
        try {
          const promptsContent = fs.readFileSync(promptsFile, 'utf8');
          const lines = promptsContent.split('\n');
          
          // Buscar l√≠neas que contengan "Imagen X: [keyword]"
          const keywordLines = lines.filter(line => {
            return line.match(/^\d+\.\s*Imagen\s+\d+:\s*(.+)$/);
          });
          
          keywords = keywordLines.map(line => {
            const match = line.match(/^\d+\.\s*Imagen\s+\d+:\s*(.+)$/);
            return match ? match[1].trim() : '';
          }).filter(keyword => keyword);
          
          console.log(`üìã Keywords extra√≠das desde archivo de prompts: ${keywords.length}`);
        } catch (error) {
          console.warn(`‚ö†Ô∏è Error extrayendo keywords desde prompts: ${error.message}`);
        }
      }
    }
    
    // Buscar archivo de prompts
    let prompts = [];
    const promptsFile = path.join(sectionDir, `${folderName}_seccion_${sectionNumber}_prompts_imagenes.txt`);
    if (fs.existsSync(promptsFile)) {
      try {
        const promptsContent = fs.readFileSync(promptsFile, 'utf8');
        prompts = promptsContent.split('\n').filter(line => line.trim());
        console.log(`üé® Prompts cargados: ${prompts.length}`);
      } catch (error) {
        console.warn(`‚ö†Ô∏è Error leyendo prompts: ${error.message}`);
      }
    }
    
    console.log(`‚úÖ Respondiendo con ${images.length} im√°genes, ${keywords.length} keywords, ${prompts.length} prompts`);
    
    res.json({ 
      success: true, 
      images: images,
      keywords: keywords,
      prompts: prompts,
      sectionNumber: parseInt(sectionNumber)
    });
    
  } catch (error) {
    console.error('‚ùå Error obteniendo im√°genes del proyecto:', error);
    res.status(500).json({ success: false, error: 'Error obteniendo im√°genes del proyecto' });
  }
});

// Ruta para eliminar un proyecto
app.delete('/api/projects/:folderName', (req, res) => {
  try {
    const { folderName } = req.params;
    const projectDir = path.join('./public/outputs', folderName);
    
    if (fs.existsSync(projectDir)) {
      fs.rmSync(projectDir, { recursive: true, force: true });
      console.log(`üóëÔ∏è Proyecto eliminado: ${folderName}`);
      res.json({ success: true, message: 'Proyecto eliminado exitosamente' });
    } else {
      res.status(404).json({ success: false, error: 'Proyecto no encontrado' });
    }
  } catch (error) {
    console.error('‚ùå Error eliminando proyecto:', error);
    res.status(500).json({ success: false, error: 'Error eliminando proyecto' });
  }
});

// Ruta para duplicar un proyecto
app.post('/api/projects/:folderName/duplicate', (req, res) => {
  try {
    const { folderName } = req.params;
    const { newName } = req.body;
    
    const sourceDir = path.join('./public/outputs', folderName);
    const newFolderName = createSafeFolderName(newName);
    const targetDir = path.join('./public/outputs', newFolderName);
    
    if (!fs.existsSync(sourceDir)) {
      return res.status(404).json({ success: false, error: 'Proyecto fuente no encontrado' });
    }
    
    if (fs.existsSync(targetDir)) {
      return res.status(400).json({ success: false, error: 'Ya existe un proyecto con ese nombre' });
    }
    
    // Copiar directorio completo
    fs.cpSync(sourceDir, targetDir, { recursive: true });
    
    // Actualizar el archivo de estado del proyecto duplicado
    const projectStateFile = path.join(targetDir, 'project_state.json');
    if (fs.existsSync(projectStateFile)) {
      const projectState = JSON.parse(fs.readFileSync(projectStateFile, 'utf8'));
      projectState.originalFolderName = newName;
      projectState.folderName = newFolderName;
      projectState.createdAt = new Date().toISOString();
      projectState.lastModified = new Date().toISOString();
      
      fs.writeFileSync(projectStateFile, JSON.stringify(projectState, null, 2), 'utf8');
    }
    
    console.log(`üìã Proyecto duplicado: ${folderName} -> ${newFolderName}`);
    res.json({ 
      success: true, 
      message: 'Proyecto duplicado exitosamente',
      newFolderName: newFolderName
    });
  } catch (error) {
    console.error('‚ùå Error duplicando proyecto:', error);
    res.status(500).json({ success: false, error: 'Error duplicando proyecto' });
  }
});

// Ruta para refrescar una imagen espec√≠fica
app.post('/api/refresh-image', async (req, res) => {
  console.log('üéØ ENDPOINT /api/refresh-image llamado con body:', req.body);
  try {
    const { folderName, imageIndex, sectionNum, keywords, currentImages } = req.body;
    
    console.log('üìã Par√°metros recibidos:', { folderName, imageIndex, sectionNum, keywords: keywords.substring(0, 50) + '...' });
    
    if (!folderName || imageIndex === undefined || !sectionNum || !keywords) {
      console.log('‚ùå Faltan par√°metros requeridos');
      return res.status(400).json({ error: 'Faltan par√°metros requeridos' });
    }

    // Convertir espacios a underscores para coincidir con la estructura de carpetas
    const normalizedFolderName = folderName.replace(/ /g, '_');
    console.log(`üîÑ Carpeta normalizada: "${folderName}" ‚Üí "${normalizedFolderName}"`);
    
    const imagesDir = path.join('./public/outputs', normalizedFolderName, `seccion_${sectionNum}`);
    console.log('üìÅ Directorio de im√°genes:', imagesDir);
    
    if (!fs.existsSync(imagesDir)) {
      console.log('‚ùå Carpeta no encontrada:', imagesDir);
      return res.status(404).json({ error: 'Carpeta no encontrada' });
    }

    console.log(`üîÑ Refrescando imagen en posici√≥n visual ${imageIndex} con keywords: ${keywords}`);
    
    // Si tenemos el array de im√°genes actuales del frontend, usarlo
    let targetFilename = null;
    
    if (currentImages && currentImages[imageIndex]) {
      // Extraer el nombre del archivo de la URL
      const imageUrl = currentImages[imageIndex].url || currentImages[imageIndex];
      targetFilename = imageUrl.split('/').pop().split('?')[0]; // Remover query params
      console.log(`üéØ Usando mapeo directo del frontend: posici√≥n ${imageIndex} ‚Üí ${targetFilename}`);
    } else {
      // Fallback: usar orden alfab√©tico (comportamiento anterior)
      const files = fs.readdirSync(imagesDir);
      const imageFiles = files.filter(file => 
        /\.(jpg|jpeg|png|gif|webp)$/i.test(file)
      ).sort();
      
      if (imageIndex >= imageFiles.length) {
        return res.status(400).json({ error: '√çndice de imagen inv√°lido' });
      }
      
      targetFilename = imageFiles[imageIndex];
      console.log(`‚ö†Ô∏è Usando fallback alfab√©tico: posici√≥n ${imageIndex} ‚Üí ${targetFilename}`);
    }

    // Verificar que el archivo existe
    const currentImagePath = path.join(imagesDir, targetFilename);
    if (!fs.existsSync(currentImagePath)) {
      return res.status(404).json({ error: `Archivo no encontrado: ${targetFilename}` });
    }

    // Buscar y descargar una nueva imagen con las mismas keywords
    console.log(`üîÑ Buscando nueva imagen con keywords: ${keywords}`);
    
    // Convertir keywords a string si es un array, o usarlo directamente si es string
    const searchQuery = Array.isArray(keywords) ? keywords.join(' ') : keywords;
    const imageUrls = await searchBingImages(searchQuery, 30); // Buscar 30 im√°genes para m√°s variaci√≥n
    
    if (imageUrls && imageUrls.length > 0) {
      // Obtener URLs de im√°genes existentes para evitar duplicados
      const existingFiles = fs.readdirSync(imagesDir);
      const existingImageUrls = new Set();
      
      // Leer metadata si existe para obtener URLs originales
      const metadataPath = path.join(imagesDir, 'images_metadata.json');
      if (fs.existsSync(metadataPath)) {
        try {
          const metadata = JSON.parse(fs.readFileSync(metadataPath, 'utf8'));
          Object.values(metadata).forEach(img => {
            if (img.originalUrl) existingImageUrls.add(img.originalUrl);
          });
        } catch (error) {
          console.log('‚ö†Ô∏è Error leyendo metadata, continuando sin filtro de duplicados');
        }
      }
      
      // Filtrar URLs que ya tenemos
      const filteredUrls = imageUrls.filter(url => !existingImageUrls.has(url));
      const urlsToUse = filteredUrls.length > 0 ? filteredUrls : imageUrls;
      
      // Seleccionar una imagen aleatoria para obtener variaci√≥n
      const randomIndex = Math.floor(Math.random() * urlsToUse.length);
      const imageUrl = urlsToUse[randomIndex];
      console.log(`üé≤ Seleccionando imagen ${randomIndex + 1} de ${urlsToUse.length} encontradas (${filteredUrls.length > 0 ? 'sin duplicados' : 'total'})`);
      
      // Mantener el mismo nombre base pero con timestamp para evitar cache
      const timestamp = Date.now();
      const extension = imageUrl.split('.').pop()?.split('?')[0] || 'jpg';
      
      // Crear nombre que mantenga la posici√≥n visual
      let newImageName;
      
      // Mejorar extracci√≥n de extensi√≥n para evitar extensiones corruptas
      let validExtension = 'jpg'; // Default seguro
      try {
        const urlParts = imageUrl.split('.');
        if (urlParts.length > 1) {
          const lastPart = urlParts[urlParts.length - 1];
          const cleanExtension = lastPart.split('?')[0].split('/')[0].split('#')[0].toLowerCase();
          // Validar que la extensi√≥n sea v√°lida y no muy larga
          if (/^(jpg|jpeg|png|gif|webp)$/i.test(cleanExtension) && cleanExtension.length <= 5) {
            validExtension = cleanExtension;
          }
        }
      } catch (error) {
        console.log(`‚ö†Ô∏è Error extrayendo extensi√≥n de URL, usando jpg por defecto: ${error.message}`);
      }
      
      if (targetFilename.startsWith('bing_image_')) {
        // Mantener el formato bing_image_X para compatibilidad
        const imageNumber = targetFilename.match(/bing_image_(\d+)/)?.[1] || (imageIndex + 1);
        newImageName = `bing_image_${imageNumber}.jpg`;
      } else {
        // Para archivos con otros formatos, usar formato consistente
        newImageName = `image_${imageIndex}_${timestamp}.${validExtension}`;
      }
      
      const newImagePath = path.join(imagesDir, newImageName);
      
      // Descargar la nueva imagen con reintentos
      let downloadSuccess = false;
      let attemptCount = 0;
      const maxAttempts = Math.min(5, urlsToUse.length); // M√°ximo 5 intentos
      
      // Crear ruta temporal para la nueva imagen
      const tempImagePath = newImagePath.replace('.jpg', '_temp.jpg');
      
      while (!downloadSuccess && attemptCount < maxAttempts) {
        try {
          const attemptIndex = (randomIndex + attemptCount) % urlsToUse.length;
          const attemptUrl = urlsToUse[attemptIndex];
          console.log(`üì• Intento ${attemptCount + 1}/${maxAttempts} descargando desde: ${attemptUrl.substring(0, 80)}...`);
          
          // Descargar en archivo temporal primero
          await downloadImageFromUrl(attemptUrl, tempImagePath);
          downloadSuccess = true;
          console.log(`‚úÖ Descarga exitosa en intento ${attemptCount + 1}`);
        } catch (error) {
          attemptCount++;
          console.log(`‚ùå Fallo en intento ${attemptCount}: ${error.message}`);
          if (attemptCount < maxAttempts) {
            console.log(`üîÑ Reintentando con otra URL...`);
          }
        }
      }
      
      if (!downloadSuccess) {
        // Limpiar archivo temporal si fall√≥ la descarga
        if (fs.existsSync(tempImagePath)) {
          fs.unlinkSync(tempImagePath);
          console.log(`üóëÔ∏è Archivo temporal borrado tras fallo: ${tempImagePath}`);
        }
        console.log(`‚ùå No se pudo descargar ninguna imagen despu√©s de ${maxAttempts} intentos`);
        return res.status(500).json({ error: 'No se pudo descargar una nueva imagen despu√©s de varios intentos' });
      }

      // Solo borrar la imagen anterior DESPU√âS de confirmar que la nueva se descarg√≥ exitosamente
      if (fs.existsSync(currentImagePath)) {
        fs.unlinkSync(currentImagePath);
        console.log(`üóëÔ∏è Imagen anterior borrada: ${currentImagePath}`);
      }
      
      // Mover imagen temporal a ubicaci√≥n final
      fs.renameSync(tempImagePath, newImagePath);
      console.log(`üìÅ Imagen temporal movida a ubicaci√≥n final: ${newImagePath}`);
      
      // Actualizar metadata para rastrear URL original
      const metadataFilePath = path.join(imagesDir, 'images_metadata.json');
      let metadata = {};
      
      if (fs.existsSync(metadataFilePath)) {
        try {
          metadata = JSON.parse(fs.readFileSync(metadataFilePath, 'utf8'));
        } catch (error) {
          console.log('‚ö†Ô∏è Error leyendo metadata existente, creando nuevo');
        }
      }
      
      metadata[newImageName] = {
        originalUrl: imageUrl,
        keywords: searchQuery,
        timestamp: timestamp,
        refreshed: true
      };
      
      try {
        fs.writeFileSync(metadataFilePath, JSON.stringify(metadata, null, 2));
        console.log(`üìù Metadata actualizada para ${newImageName}`);
      } catch (error) {
        console.log('‚ö†Ô∏è Error guardando metadata:', error.message);
      }
      
      console.log(`‚úÖ Nueva imagen descargada: ${newImagePath}`);
      console.log(`üéØ Mapeo mantenido: posici√≥n visual ${imageIndex} ‚Üí ${newImageName}`);
      
      // Devolver la informaci√≥n de la nueva imagen
      res.json({ 
        success: true,
        message: `Imagen ${imageIndex + 1} refrescada exitosamente`,
        newImageUrl: `/outputs/${normalizedFolderName}/seccion_${sectionNum}/${newImageName}`,
        filename: newImageName,
        imageIndex: imageIndex
      });
    } else {
      res.status(404).json({ error: 'No se pudo encontrar una nueva imagen' });
    }

  } catch (error) {
    console.error('‚ùå Error al refrescar imagen:', error);
    res.status(500).json({ error: 'Error interno del servidor' });
  }
});

// ================================
// ENDPOINTS PARA GENERACI√ìN DE VIDEO
// ================================

// Almac√©n de progreso en memoria para cada sesi√≥n de video
const videoProgressStore = new Map();

// Funci√≥n helper para actualizar progreso de video
function updateVideoProgress(sessionId, percent, message) {
  videoProgressStore.set(sessionId, { percent, message, timestamp: Date.now() });
  console.log(`[VIDEO-${sessionId}] ${Math.round(percent)}% - ${message}`);
}

// Endpoint para progreso de video en tiempo real usando Server-Sent Events
app.get('/video-progress/:sessionId', (req, res) => {
  const sessionId = req.params.sessionId;
  
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Headers': 'Cache-Control'
  });

  // Funci√≥n para enviar progreso
  const sendProgress = (data) => {
    res.write(`data: ${JSON.stringify(data)}\n\n`);
  };

  // Enviar progreso inicial
  const initialProgress = videoProgressStore.get(sessionId) || { percent: 0, message: 'Iniciando generaci√≥n de video...' };
  sendProgress(initialProgress);

  // Verificar progreso cada segundo
  const progressInterval = setInterval(() => {
    const progress = videoProgressStore.get(sessionId);
    if (progress) {
      sendProgress(progress);
      
      // Si est√° completo, limpiar despu√©s de un tiempo
      if (progress.percent >= 100) {
        setTimeout(() => {
          videoProgressStore.delete(sessionId);
          clearInterval(progressInterval);
        }, 30000); // Limpiar despu√©s de 30 segundos
      }
    }
  }, 1000);

  // Limpiar al cerrar conexi√≥n
  req.on('close', () => {
    clearInterval(progressInterval);
  });
});

// Endpoint para generar video desde el proyecto
app.post('/generate-project-video', async (req, res) => {
  const sessionId = Date.now().toString(); // ID √∫nico para esta sesi√≥n
  
  try {
    updateVideoProgress(sessionId, 0, 'Iniciando procesamiento de video...');
    
    const { 
      folderName, 
      duration = 3, 
      animationType = 'zoom-out', 
      quality = 'standard' 
    } = req.body;
    
    // Enviar sessionId al cliente para que pueda conectarse al progreso
    res.setHeader('X-Video-Session-ID', sessionId);
    
    if (!folderName) {
      return res.status(400).json({ error: 'Nombre de carpeta requerido' });
    }

    console.log(`üé¨ Iniciando generaci√≥n de video para proyecto: ${folderName}`);
    console.log(`üé¨ Configuraci√≥n: duraci√≥n=${duration}s, animaci√≥n=${animationType}, calidad=${quality}`);

    updateVideoProgress(sessionId, 5, 'Analizando estructura del proyecto...');
    
    // Normalizar nombre de la carpeta
    const normalizedFolderName = folderName.toLowerCase().replace(/\s+/g, '_');
    const projectPath = path.join(process.cwd(), 'public', 'outputs', normalizedFolderName);
    
    if (!fs.existsSync(projectPath)) {
      return res.status(404).json({ error: 'Proyecto no encontrado' });
    }

    // Organizar archivos por secciones
    updateVideoProgress(sessionId, 10, 'Organizando archivos por secciones...');
    const secciones = await organizarArchivosPorSecciones(projectPath);
    
    if (secciones.length === 0) {
      return res.status(404).json({ error: 'No se encontraron secciones con im√°genes' });
    }

    console.log(`üé¨ Encontradas ${secciones.length} secciones para procesar`);
    updateVideoProgress(sessionId, 15, `Encontradas ${secciones.length} secciones para procesar`);
    
    // Generar video
    const outputPath = await procesarVideoCompleto(secciones, normalizedFolderName, duration, animationType, quality, sessionId);
    
    // Verificar que el archivo existe antes de enviarlo
    if (!fs.existsSync(outputPath)) {
      throw new Error('El archivo de video no se gener√≥ correctamente');
    }
    
    console.log('üé¨ Enviando video al cliente');
    updateVideoProgress(sessionId, 100, '¬°Video completado y listo para descarga!');
    
    const filename = `${normalizedFolderName}_video_completo.mp4`;
    
    res.download(outputPath, filename, (err) => {
      if (err) {
        console.error('‚ùå Error enviando video:', err);
      } else {
        console.log('‚úÖ Video enviado exitosamente');
        
        // Limpiar archivo temporal despu√©s de un tiempo
        setTimeout(() => {
          try {
            if (fs.existsSync(outputPath)) {
              fs.unlinkSync(outputPath);
              console.log('üóëÔ∏è Archivo temporal de video limpiado');
            }
          } catch (e) {
            console.log('‚ö†Ô∏è No se pudo limpiar archivo temporal:', e.message);
          }
        }, 60000); // Limpiar despu√©s de 1 minuto
      }
    });

  } catch (error) {
    console.error('‚ùå Error al procesar video:', error);
    updateVideoProgress(sessionId, 0, `Error: ${error.message}`);
    res.status(500).json({ error: 'Error interno del servidor' });
  }
});

// Funci√≥n para organizar archivos por secciones desde el proyecto
async function organizarArchivosPorSecciones(projectPath) {
  const secciones = [];
  
  try {
    const items = fs.readdirSync(projectPath);
    
    // Buscar carpetas de secciones
    for (const item of items) {
      const itemPath = path.join(projectPath, item);
      const stats = fs.statSync(itemPath);
      
      if (stats.isDirectory() && item.startsWith('seccion_')) {
        const numeroSeccion = parseInt(item.replace('seccion_', ''));
        const imagenes = [];
        const audios = [];
        
        // Buscar archivos en la carpeta de secci√≥n
        const sectionFiles = fs.readdirSync(itemPath);
        
        for (const file of sectionFiles) {
          const filePath = path.join(itemPath, file);
          const fileStats = fs.statSync(filePath);
          
          if (fileStats.isFile()) {
            const ext = path.extname(file).toLowerCase();
            
            if (['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'].includes(ext)) {
              imagenes.push({
                path: filePath,
                name: file,
                mtime: fileStats.mtime
              });
            } else if (['.mp3', '.wav', '.m4a', '.aac', '.ogg'].includes(ext)) {
              audios.push({
                path: filePath,
                name: file
              });
            }
          }
        }
        
        if (imagenes.length > 0) {
          // Ordenar im√°genes por nombre para mantener orden consistente
          imagenes.sort((a, b) => a.name.localeCompare(b.name, undefined, { numeric: true }));
          
          secciones.push({
            numero: numeroSeccion,
            nombre: `Secci√≥n ${numeroSeccion}`,
            imagenes: imagenes,
            audios: audios,
            path: itemPath
          });
        }
      }
    }
    
    // Ordenar secciones por n√∫mero
    secciones.sort((a, b) => a.numero - b.numero);
    
    console.log(`üé¨ Secciones encontradas: ${secciones.length}`);
    secciones.forEach(seccion => {
      console.log(`  - ${seccion.nombre}: ${seccion.imagenes.length} im√°genes, ${seccion.audios.length} audios`);
    });
    
    return secciones;
    
  } catch (error) {
    console.error('‚ùå Error organizando archivos:', error);
    return [];
  }
}

// Funci√≥n principal para procesar video completo
async function procesarVideoCompleto(secciones, projectName, duration, animationType, quality, sessionId) {
  const outputDir = path.join(process.cwd(), 'temp');
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }
  
  const finalOutputPath = path.join(outputDir, `${projectName}_video_${Date.now()}.mp4`);
  const videosSeccionesTemp = [];
  
  try {
    // Procesar cada secci√≥n individualmente
    for (let i = 0; i < secciones.length; i++) {
      const seccion = secciones[i];
      const progresoBase = 20 + (i * 60 / secciones.length);
      
      updateVideoProgress(sessionId, progresoBase, `Procesando ${seccion.nombre}...`);
      
      const videoSeccionPath = await procesarSeccionVideo(seccion, duration, animationType, quality, sessionId, progresoBase, secciones.length);
      
      if (videoSeccionPath && fs.existsSync(videoSeccionPath)) {
        videosSeccionesTemp.push(videoSeccionPath);
        console.log(`‚úÖ ${seccion.nombre} procesada: ${videoSeccionPath}`);
      }
    }
    
    if (videosSeccionesTemp.length === 0) {
      throw new Error('No se pudieron procesar las secciones');
    }
    
    // Combinar todas las secciones
    updateVideoProgress(sessionId, 85, 'Combinando todas las secciones...');
    await combinarSeccionesVideo(videosSeccionesTemp, finalOutputPath, sessionId);
    
    // Limpiar videos temporales de secciones
    videosSeccionesTemp.forEach(video => {
      try {
        if (fs.existsSync(video)) {
          fs.unlinkSync(video);
        }
      } catch (e) {
        console.log('‚ö†Ô∏è No se pudo limpiar video temporal:', e.message);
      }
    });
    
    return finalOutputPath;
    
  } catch (error) {
    // Limpiar videos temporales en caso de error
    videosSeccionesTemp.forEach(video => {
      try {
        if (fs.existsSync(video)) {
          fs.unlinkSync(video);
        }
      } catch (e) {
        console.log('‚ö†Ô∏è No se pudo limpiar video temporal:', e.message);
      }
    });
    throw error;
  }
}

// Funci√≥n para procesar una secci√≥n individual
async function procesarSeccionVideo(seccion, duration, animationType, quality, sessionId, progresoBase, totalSecciones) {
  try {
    const outputPath = path.join(process.cwd(), 'temp', `seccion_${seccion.numero}_${Date.now()}.mp4`);
    
    // Validar que la secci√≥n tiene im√°genes
    if (!seccion.imagenes || seccion.imagenes.length === 0) {
      throw new Error(`${seccion.nombre} no tiene im√°genes para procesar`);
    }
    
    // Buscar archivo de audio para esta secci√≥n
    let audioPath = null;
    let finalDuration = duration; // Duraci√≥n por defecto
    
    if (seccion.audios && seccion.audios.length > 0) {
      // Usar el primer archivo de audio encontrado
      audioPath = seccion.audios[0].path;
      if (fs.existsSync(audioPath)) {
        console.log(`üéµ Audio encontrado para ${seccion.nombre}: ${audioPath}`);
        
        // Obtener duraci√≥n del audio usando ffprobe
        try {
          const audioDuration = await getAudioDuration(audioPath);
          if (audioDuration > 0) {
            // Calcular duraci√≥n por imagen bas√°ndose en el audio
            finalDuration = audioDuration / seccion.imagenes.length;
            console.log(`ÔøΩ Duraci√≥n del audio: ${audioDuration} segundos`);
            console.log(`üìê Duraci√≥n calculada por imagen: ${finalDuration.toFixed(2)} segundos`);
          } else {
            console.warn(`‚ö†Ô∏è No se pudo obtener duraci√≥n v√°lida del audio, usando duraci√≥n fija: ${duration}s`);
          }
        } catch (error) {
          console.warn(`‚ö†Ô∏è Error obteniendo duraci√≥n del audio: ${error.message}, usando duraci√≥n fija: ${duration}s`);
        }
      } else {
        console.warn(`‚ö†Ô∏è Archivo de audio no existe: ${audioPath}`);
        audioPath = null;
      }
    } else {
      console.log(`üì¢ No se encontr√≥ audio para ${seccion.nombre}`);
    }
    
    // Validar que todas las im√°genes existen y obtener sus rutas absolutas
    const imagenesValidadas = [];
    for (const imagen of seccion.imagenes) {
      let imagePath = imagen.path;
      
      // Si la ruta no es absoluta, convertirla
      if (!path.isAbsolute(imagePath)) {
        imagePath = path.resolve(imagePath);
      }
      
      if (!fs.existsSync(imagePath)) {
        console.error(`‚ùå Imagen no encontrada: ${imagePath}`);
        throw new Error(`Imagen no encontrada: ${imagePath}`);
      }
      
      // Verificar que es un archivo de imagen v√°lido
      const ext = path.extname(imagePath).toLowerCase();
      if (!['.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp'].includes(ext)) {
        console.error(`‚ùå Formato de imagen no soportado: ${ext}`);
        throw new Error(`Formato de imagen no soportado: ${ext}`);
      }
      
      imagenesValidadas.push(imagePath);
      console.log(`‚úÖ Imagen validada: ${imagePath}`);
    }
    
    console.log(`üé¨ Procesando ${seccion.nombre} con ${imagenesValidadas.length} im√°genes validadas${audioPath ? ' y audio' : ''}`);
    console.log(`‚è±Ô∏è Duraci√≥n por imagen: ${finalDuration.toFixed(2)} segundos`);
    
    // Procesar cada imagen con transiciones usando Canvas
    const transitionTypes = ['zoom-in', 'zoom-out', 'pan-right', 'pan-left', 'fade-in', 'slide-in-left', 'slide-in-right', 'rotate-zoom'];
    const framesPorSegundo = 30;
    
    if (imagenesValidadas.length === 1) {
      // Una sola imagen - generar directamente al archivo final
      const imagePath = imagenesValidadas[0];
      const transitionType = 'zoom-out'; // Usar zoom-out para imagen √∫nica
      
      console.log(`üé¨ Procesando imagen √∫nica con transici√≥n ${transitionType}`);
      
      // Generar video con transici√≥n
      await generateImageVideoWithTransitions(imagePath, outputPath, finalDuration, transitionType, framesPorSegundo);
      
      // Agregar audio si existe
      if (audioPath) {
        const tempVideo = path.join(path.dirname(outputPath), `temp_${path.basename(outputPath)}`);
        fs.renameSync(outputPath, tempVideo);
        
        const ffmpegArgs = ['-i', tempVideo, '-i', audioPath, '-c:v', 'copy', '-c:a', 'aac', '-shortest', outputPath];
        
        await new Promise((resolve, reject) => {
          const ffmpeg = spawn('ffmpeg', ffmpegArgs, { stdio: 'pipe' });
          ffmpeg.on('close', (code) => {
            if (code === 0) {
              // Limpiar archivo temporal
              if (fs.existsSync(tempVideo)) fs.unlinkSync(tempVideo);
              resolve();
            } else {
              reject(new Error(`FFmpeg fall√≥ con c√≥digo ${code}`));
            }
          });
        });
      }
    } else {
      // M√∫ltiples im√°genes - generar videos temporales y concatenar
      const tempVideos = [];
      
      for (let i = 0; i < imagenesValidadas.length; i++) {
        const imagePath = imagenesValidadas[i];
        const transitionType = 'zoom-out'; // Usar siempre zoom-out
        const tempVideoPath = path.join(path.dirname(outputPath), `temp_${i}_${Date.now()}.mp4`);
        
        console.log(`üé¨ Procesando imagen ${i + 1}/${imagenesValidadas.length} con transici√≥n ${transitionType}`);
        
        // Generar video con transici√≥n para esta imagen
        await generateImageVideoWithTransitions(imagePath, tempVideoPath, finalDuration, transitionType, framesPorSegundo);
        tempVideos.push(tempVideoPath);
      }
      
      // Concatenar videos con transiciones de desvanecimiento
      await concatenateVideosWithCrossfade(tempVideos, audioPath, outputPath);
      
      // Limpiar archivos temporales
      tempVideos.forEach(video => {
        if (fs.existsSync(video)) fs.unlinkSync(video);
      });
    }
    
    console.log(`‚úÖ Video de secci√≥n ${seccion.nombre} generado con transiciones: ${outputPath}`);
    return outputPath; // Devolver la ruta del video generado
        
  } catch (error) {
    console.error(`‚ùå Error en procesarSeccionVideo:`, error);
    throw error;
  }
}

// Funci√≥n auxiliar para obtener la duraci√≥n del audio
function getAudioDuration(audioPath) {
  return new Promise((resolve, reject) => {
    const ffprobeProcess = spawn('ffprobe', [
      '-v', 'quiet',
      '-show_entries', 'format=duration',
      '-of', 'csv=p=0',
      audioPath
    ]);
    
    let ffprobeOutput = '';
    
    ffprobeProcess.stdout.on('data', (data) => {
      ffprobeOutput += data.toString();
    });
    
    ffprobeProcess.on('close', (code) => {
      if (code === 0) {
        const duration = parseFloat(ffprobeOutput.trim());
        resolve(duration);
      } else {
        reject(new Error(`ffprobe fall√≥ con c√≥digo ${code}`));
      }
    });
    
    ffprobeProcess.on('error', (err) => {
      reject(err);
    });
  });
}

// Funci√≥n para combinar todas las secciones
async function combinarSeccionesVideo(videosSeccionesTemp, finalOutputPath, sessionId) {
  return new Promise((resolve, reject) => {
    updateVideoProgress(sessionId, 90, 'Concatenando todas las secciones...');
    
    const listFile = path.join(process.cwd(), 'temp', `concat_list_${Date.now()}.txt`);
    const listContent = videosSeccionesTemp.map(video => `file '${video}'`).join('\n');
    
    fs.writeFileSync(listFile, listContent);
    
    const args = [
      '-f', 'concat',
      '-safe', '0',
      '-i', listFile,
      '-c', 'copy',
      '-y',
      finalOutputPath
    ];
    
    const ffmpegProcess = spawn('ffmpeg', args);
    
    let stderrData = '';
    
    ffmpegProcess.stderr.on('data', (data) => {
      stderrData += data.toString();
    });
    
    ffmpegProcess.on('close', (code) => {
      // Limpiar archivo de lista temporal
      try {
        if (fs.existsSync(listFile)) {
          fs.unlinkSync(listFile);
        }
      } catch (e) {
        console.log('‚ö†Ô∏è No se pudo limpiar archivo de lista:', e.message);
      }
      
      if (code === 0) {
        console.log('‚úÖ Video final concatenado exitosamente');
        updateVideoProgress(sessionId, 95, 'Video final generado exitosamente');
        resolve(finalOutputPath);
      } else {
        console.error('‚ùå Error en concatenaci√≥n FFmpeg:', stderrData);
        reject(new Error(`FFmpeg fall√≥ con c√≥digo ${code}`));
      }
    });
    
    ffmpegProcess.on('error', (err) => {
      console.error('‚ùå Error ejecutando FFmpeg:', err);
      reject(err);
    });
  });
}

// ================================
// FUNCIONES DE ANIMACI√ìN AVANZADAS CON TRANSICIONES
// ================================

// Funci√≥n para generar frames animados usando Canvas con transiciones avanzadas
async function generateAnimatedFrames(imagePath, outputPath, duration, animationType, smoothness = 'standard', useGPU = false) {
  // FPS optimizado seg√∫n el nivel de suavidad seleccionado
  let fps = 25;
  
  if (smoothness === 'standard') {
    if (duration > 10) fps = 20;      // 20 FPS para videos de 10-30s
    if (duration > 30) fps = 15;      // 15 FPS para videos de 30-60s
    if (duration > 60) fps = 10;      // 10 FPS para videos de 1-2 minutos  
    if (duration > 120) fps = 8;      // 8 FPS para videos muy largos (>2 min)
  } else if (smoothness === 'smooth') {
    if (duration > 10) fps = 25;      // 25 FPS para videos de 10-30s
    if (duration > 30) fps = 20;      // 20 FPS para videos de 30-60s
    if (duration > 60) fps = 15;      // 15 FPS para videos de 1-2 minutos  
    if (duration > 120) fps = 12;     // 12 FPS para videos muy largos (>2 min)
  } else if (smoothness === 'ultra') {
    if (duration > 10) fps = 30;      // 30 FPS para videos de 10-30s
    if (duration > 30) fps = 25;      // 25 FPS para videos de 30-60s
    if (duration > 60) fps = 20;      // 20 FPS para videos de 1-2 minutos  
    if (duration > 120) fps = 15;     // 15 FPS para videos muy largos (>2 min)
  }
  
  const totalFrames = duration * fps;
  const tempDir = path.join(process.cwd(), 'temp_frames');
  
  console.log(`üé¨ Generando ${totalFrames} frames a ${fps} FPS para duraci√≥n de ${duration}s (calidad: ${smoothness})`);
  
  // Crear directorio temporal para los frames
  if (!fs.existsSync(tempDir)) {
    fs.mkdirSync(tempDir, { recursive: true });
  }
  
  try {
    // Verificar que es un archivo de imagen v√°lido
    const validImageExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'];
    const fileExtension = path.extname(imagePath).toLowerCase();
    
    console.log(`üñºÔ∏è Procesando archivo: ${imagePath}`);
    console.log(`üìÑ Extensi√≥n detectada: "${fileExtension}"`);
    
    if (!validImageExtensions.includes(fileExtension)) {
      throw new Error(`Tipo de imagen no soportado: "${fileExtension}" para archivo ${path.basename(imagePath)}`);
    }
    
    // Verificar que el archivo existe
    if (!fs.existsSync(imagePath)) {
      throw new Error(`Archivo no encontrado: ${imagePath}`);
    }
    
    console.log(`üìÇ Cargando imagen: ${path.basename(imagePath)} (${fileExtension})`);
    
    // Cargar la imagen original
    const image = await loadImage(imagePath);
    
    // Para videos muy largos, usar lotes m√°s grandes para mejor rendimiento
    const batchSize = duration > 60 ? 20 : 50; // Lotes m√°s peque√±os para videos largos
    
    for (let batchStart = 0; batchStart < totalFrames; batchStart += batchSize) {
      const batchEnd = Math.min(batchStart + batchSize, totalFrames);
      
      console.log(`üé• Procesando frames ${batchStart + 1}-${batchEnd} de ${totalFrames}`);
      
      // Generar frames del lote actual
      for (let frame = batchStart; frame < batchEnd; frame++) {
        const progress = frame / (totalFrames - 1); // 0 a 1
        
        // Funci√≥n de easing para suavizar las transiciones (ease-in-out cubic)
        const easeInOutCubic = (t) => {
          return t < 0.5 ? 4 * t * t * t : 1 - Math.pow(-2 * t + 2, 3) / 2;
        };
        
        // Funci√≥n de easing suave (ease-out sine) para movimientos m√°s naturales
        const easeOutSine = (t) => {
          return Math.sin((t * Math.PI) / 2);
        };
        
        // Aplicar easing al progreso para animaciones m√°s fluidas
        const easedProgress = easeInOutCubic(progress);
        
        // Crear canvas de 1920x1080
        const canvas = createCanvas(1920, 1080);
        const ctx = canvas.getContext('2d');
        
        // Fondo negro
        ctx.fillStyle = 'black';
        ctx.fillRect(0, 0, 1920, 1080);
        
        // Calcular aspect ratio de la imagen original y del canvas
        const imageAspectRatio = image.width / image.height;
        const canvasAspectRatio = 1920 / 1080;
        
        // Calcular dimensiones manteniendo aspect ratio
        let baseWidth, baseHeight;
        
        if (imageAspectRatio > canvasAspectRatio) {
          // Imagen m√°s ancha: ajustar por ancho
          baseWidth = 1920;
          baseHeight = 1920 / imageAspectRatio;
        } else {
          // Imagen m√°s alta: ajustar por alto
          baseHeight = 1080;
          baseWidth = 1080 * imageAspectRatio;
        }
        
        // Calcular posici√≥n centrada
        const baseCenterX = (1920 - baseWidth) / 2;
        const baseCenterY = (1080 - baseHeight) / 2;
        
        // Aplicar efectos de animaci√≥n manteniendo aspect ratio
        let drawWidth, drawHeight, drawX, drawY;
        
        switch (animationType) {
          case 'zoom-in':
            // Zoom in: escala de 1.0 a 1.3 con easing suave
            const zoomInScale = 1 + (easedProgress * 0.3);
            drawWidth = baseWidth * zoomInScale;
            drawHeight = baseHeight * zoomInScale;
            drawX = baseCenterX - ((drawWidth - baseWidth) / 2);
            drawY = baseCenterY - ((drawHeight - baseHeight) / 2);
            break;
            
          case 'zoom-out':
            // Zoom out: escala de 1.3 a 1.0 con easing suave
            const zoomOutScale = 1.3 - (easedProgress * 0.3);
            drawWidth = baseWidth * zoomOutScale;
            drawHeight = baseHeight * zoomOutScale;
            drawX = baseCenterX - ((drawWidth - baseWidth) / 2);
            drawY = baseCenterY - ((drawHeight - baseHeight) / 2);
            break;
            
          case 'pan-right':
            // Pan derecha: imagen m√°s grande que se mueve con easing suave
            const panScale = 1.2;
            drawWidth = baseWidth * panScale;
            drawHeight = baseHeight * panScale;
            const panOffsetX = ((drawWidth - baseWidth) / 2) + ((drawWidth - 1920) * easedProgress);
            drawX = baseCenterX - panOffsetX;
            drawY = baseCenterY - ((drawHeight - baseHeight) / 2);
            break;
            
          case 'pan-left':
            // Pan izquierda: imagen m√°s grande que se mueve al rev√©s con easing suave
            const leftPanScale = 1.2;
            drawWidth = baseWidth * leftPanScale;
            drawHeight = baseHeight * leftPanScale;
            const leftPanOffsetX = ((drawWidth - baseWidth) / 2) + ((drawWidth - 1920) * (1 - easedProgress));
            drawX = baseCenterX - leftPanOffsetX;
            drawY = baseCenterY - ((drawHeight - baseHeight) / 2);
            break;
            
          case 'fade-in':
            // Fade in: opacidad de 0 a 1
            drawWidth = baseWidth;
            drawHeight = baseHeight;
            drawX = baseCenterX;
            drawY = baseCenterY;
            ctx.globalAlpha = easedProgress;
            break;
            
          case 'slide-in-left':
            // Deslizar desde la izquierda
            drawWidth = baseWidth;
            drawHeight = baseHeight;
            drawX = baseCenterX - (1920 * (1 - easedProgress));
            drawY = baseCenterY;
            break;
            
          case 'slide-in-right':
            // Deslizar desde la derecha
            drawWidth = baseWidth;
            drawHeight = baseHeight;
            drawX = baseCenterX + (1920 * (1 - easedProgress));
            drawY = baseCenterY;
            break;
            
          case 'rotate-zoom':
            // Rotaci√≥n con zoom
            const rotateZoomScale = 1 + (easedProgress * 0.2);
            const rotation = easedProgress * Math.PI * 2; // Una rotaci√≥n completa
            drawWidth = baseWidth * rotateZoomScale;
            drawHeight = baseHeight * rotateZoomScale;
            
            ctx.save();
            ctx.translate(1920/2, 1080/2);
            ctx.rotate(rotation);
            ctx.translate(-drawWidth/2, -drawHeight/2);
            drawX = 0;
            drawY = 0;
            break;
            
          case 'none':
          default:
            // Sin animaci√≥n: imagen est√°tica centrada manteniendo aspect ratio
            drawWidth = baseWidth;
            drawHeight = baseHeight;
            drawX = baseCenterX;
            drawY = baseCenterY;
        }
        
        // Dibujar la imagen en el canvas manteniendo aspect ratio
        ctx.drawImage(image, drawX, drawY, drawWidth, drawHeight);
        
        // Restaurar contexto si se us√≥ transformaci√≥n
        if (animationType === 'rotate-zoom') {
          ctx.restore();
        }
        
        // Resetear alpha si se us√≥
        if (animationType === 'fade-in') {
          ctx.globalAlpha = 1;
        }
        
        // Guardar el frame como imagen con calidad ajustada seg√∫n duraci√≥n
        const quality = duration > 60 ? 0.7 : 0.85; // Menor calidad para videos largos
        const framePath = path.join(tempDir, `frame_${String(frame).padStart(6, '0')}.jpg`);
        const buffer = canvas.toBuffer('image/jpeg', { quality });
        fs.writeFileSync(framePath, buffer);
      }
      
      // Forzar liberaci√≥n de memoria entre lotes
      if (global.gc) {
        global.gc();
      }
    }
    
    // Convertir frames a video usando FFmpeg con aceleraci√≥n GPU opcional
    await new Promise((resolve, reject) => {
      const videoCodec = useGPU ? 'h264_nvenc' : 'libx264';
      const outputOptions = [
        '-c:v', videoCodec,
        '-pix_fmt', 'yuv420p',
        '-t', duration.toString()
      ];
      
      if (useGPU) {
        // Opciones optimizadas para NVENC
        outputOptions.push(
          '-preset', 'fast',        // Preset r√°pido para NVENC
          '-rc', 'vbr',             // Variable bitrate
          '-cq', '23',              // Calidad constante
          '-b:v', '8M',             // Bitrate target
          '-maxrate', '15M',        // Bitrate m√°ximo
          '-bufsize', '30M'         // Buffer size
        );
      } else {
        // Opciones para CPU
        outputOptions.push('-preset', duration > 60 ? 'ultrafast' : 'fast');
      }
      
      console.log(`üé¨ Convirtiendo frames a video usando ${useGPU ? 'GPU (NVENC)' : 'CPU'}...`);
      
      ffmpeg()
        .input(path.join(tempDir, 'frame_%06d.jpg'))
        .inputOptions(['-framerate', fps.toString()])
        .outputOptions(outputOptions)
        .output(outputPath)
        .on('end', () => {
          console.log(`‚úÖ Video generado exitosamente con ${useGPU ? 'aceleraci√≥n GPU' : 'CPU'}`);
          resolve();
        })
        .on('error', reject)
        .run();
    });
    
    // Limpiar frames temporales
    const files = fs.readdirSync(tempDir);
    for (const file of files) {
      fs.unlinkSync(path.join(tempDir, file));
    }
    
  } catch (error) {
    throw error;
  }
}

// Funci√≥n para generar video de una imagen con transiciones usando Canvas
async function generateImageVideoWithTransitions(imagePath, outputPath, duration, animationType = 'zoom-out', fps = 30) {
  return new Promise(async (resolve, reject) => {
    try {
      console.log(`üé¨ Generando video con transici√≥n ${animationType} para ${path.basename(imagePath)}`);
      
      // Generar video completo con animaci√≥n
      await generateAnimatedFrames(imagePath, outputPath, duration, animationType, 'standard', false);
      
      console.log(`‚úÖ Video con transici√≥n generado: ${path.basename(outputPath)}`);
      resolve(outputPath);
      
    } catch (error) {
      console.error('Error en generateImageVideoWithTransitions:', error);
      reject(error);
    }
  });
}

// Funci√≥n para concatenar videos con transici√≥n crossfade
async function concatenateVideosWithCrossfade(videoPaths, audioPath, outputPath) {
  return new Promise((resolve, reject) => {
    console.log(`üé¨ Concatenando ${videoPaths.length} videos con transici√≥n crossfade...`);
    
    if (videoPaths.length === 0) {
      reject(new Error('No hay videos para concatenar'));
      return;
    }
    
    if (videoPaths.length === 1) {
      // Si solo hay un video, no necesitamos crossfade
      const command = ffmpeg(videoPaths[0]);
      if (audioPath) {
        command.input(audioPath);
      }
      command
        .outputOptions(['-c:v libx264', '-crf 23', '-preset medium'])
        .output(outputPath)
        .on('end', () => {
          console.log('‚úÖ Video √∫nico procesado correctamente');
          resolve(outputPath);
        })
        .on('error', (err) => {
          console.error('Error procesando video √∫nico:', err);
          reject(err);
        })
        .run();
      return;
    }
    
    // Para m√∫ltiples videos, creamos filtros de crossfade
    const command = ffmpeg();
    
    // Agregar todos los videos como inputs
    videoPaths.forEach(videoPath => {
      command.input(videoPath);
    });
    
    // Agregar audio si existe
    if (audioPath) {
      command.input(audioPath);
    }
    
    // Construir el filtro complejo para crossfade
    const filterComplex = [];
    const crossfadeDuration = 0.5; // 0.5 segundos de crossfade
    
    // Para m√∫ltiples videos, usaremos un enfoque m√°s simple: concatenar con fade
    // Primero, creamos un filtro que ajusta cada video para que tenga fade out al final
    for (let i = 0; i < videoPaths.length; i++) {
      if (i === 0) {
        // Primer video: solo fade out al final
        filterComplex.push(`[${i}:v]fade=t=out:st=9.5:d=0.5[v${i}]`);
      } else if (i === videoPaths.length - 1) {
        // √öltimo video: solo fade in al inicio
        filterComplex.push(`[${i}:v]fade=t=in:st=0:d=0.5[v${i}]`);
      } else {
        // Videos del medio: fade in y fade out
        filterComplex.push(`[${i}:v]fade=t=in:st=0:d=0.5,fade=t=out:st=9.5:d=0.5[v${i}]`);
      }
    }
    
    // Ahora concatenamos todos los videos con fade
    const inputLabels = videoPaths.map((_, i) => `[v${i}]`).join('');
    filterComplex.push(`${inputLabels}concat=n=${videoPaths.length}:v=1:a=0[outv]`);
    
    const outputOptions = [
      '-filter_complex', filterComplex.join(';'),
      '-map', '[outv]',
      '-c:v', 'libx264',
      '-crf', '23',
      '-preset', 'medium',
      '-pix_fmt', 'yuv420p'
    ];
    
    // Si hay audio, mapearlo tambi√©n
    if (audioPath) {
      outputOptions.push('-map', `${videoPaths.length}:a`);
      outputOptions.push('-c:a', 'aac');
      outputOptions.push('-b:a', '128k');
    }
    
    command
      .outputOptions(outputOptions)
      .output(outputPath)
      .on('start', (commandLine) => {
        console.log('üé¨ Comando FFmpeg para crossfade:', commandLine);
      })
      .on('progress', (progress) => {
        if (progress.percent) {
          console.log(`‚è≥ Progreso crossfade: ${Math.round(progress.percent)}%`);
        }
      })
      .on('end', () => {
        console.log('‚úÖ Videos concatenados con crossfade exitosamente');
        resolve(outputPath);
      })
      .on('error', (err) => {
        console.error('‚ùå Error en concatenaci√≥n con crossfade:', err);
        reject(err);
      })
      .run();
  });
}

app.listen(PORT, () => {
  console.log(`üöÄ Servidor corriendo en http://localhost:${PORT}`);
});
