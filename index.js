import 'dotenv/config';
import express from 'express';
import cors from 'cors';
import bodyParser from 'body-parser';
import { GoogleGenAI, Modality } from "@google/genai";
import wav from 'wav';
import fs from 'fs';
import path from 'path';
import fetch from 'node-fetch';
import ApplioClient from "./applio-client.js";
import { transcribeAudio, getAudioTracks } from "./transcriber.js";
import multer from 'multer';

const app = express();
const PORT = 3000;

// Configurar cliente Applio
const applioClient = new ApplioClient();

app.use(cors());
app.use(bodyParser.json());
app.use(express.static('public')); // Servir HTML y assets

// Configurar multer para subida de archivos
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    const tempDir = './temp';
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    cb(null, tempDir);
  },
  filename: function (req, file, cb) {
    cb(null, Date.now() + '_' + file.originalname);
  }
});

const upload = multer({ 
  storage: storage,
  limits: {
    fileSize: 5 * 1024 * 1024 * 1024 // 5GB m√°ximo para videos grandes
  },
  fileFilter: function (req, file, cb) {
    const allowedTypes = ['audio/mp3', 'audio/wav', 'audio/mpeg', 'audio/m4a', 'video/mp4'];
    const allowedExtensions = ['.mp3', '.wav', '.m4a', '.mp4'];
    
    const isValidType = allowedTypes.includes(file.mimetype) || 
                       allowedExtensions.some(ext => file.originalname.toLowerCase().endsWith(ext));
    
    if (isValidType) {
      cb(null, true);
    } else {
      cb(new Error('Formato de archivo no soportado'));
    }
  }
});

const ai = new GoogleGenAI({
  apiKey: process.env.GOOGLE_API_KEY,
});

// Almac√©n de conversaciones en memoria (historial por proyecto)
const conversationStore = new Map();

// Funci√≥n para obtener o crear una conversaci√≥n
function getOrCreateConversation(projectKey) {
  if (!conversationStore.has(projectKey)) {
    conversationStore.set(projectKey, {
      history: [],
      topic: '',
      totalSections: 0,
      currentSection: 0,
      createdAt: Date.now()
    });
  }
  return conversationStore.get(projectKey);
}

// Funci√≥n para limpiar conversaciones antiguas (m√°s de 24 horas)
function cleanOldConversations() {
  const now = Date.now();
  const oneDayInMs = 24 * 60 * 60 * 1000;
  
  for (const [key, conversation] of conversationStore.entries()) {
    if (now - conversation.createdAt > oneDayInMs) {
      conversationStore.delete(key);
    }
  }
}

// Limpiar conversaciones antiguas cada hora
setInterval(cleanOldConversations, 60 * 60 * 1000);

// Funci√≥n para crear nombre de carpeta seguro basado en el tema
function createSafeFolderName(topic) {
  return topic
    .toLowerCase()
    .replace(/[^a-z0-9\s]/g, '') // Remover caracteres especiales
    .replace(/\s+/g, '_') // Reemplazar espacios con guiones bajos
    .substring(0, 50); // Limitar longitud
}

// Funci√≥n para limpiar el texto del gui√≥n de contenido no deseado
function cleanScriptText(text) {
  let cleanText = text.trim();
  
  // Remover patrones comunes de texto no deseado
  const unwantedPatterns = [
    /^Secci√≥n \d+:/gi,
    /^Gui√≥n:/gi,
    /^Texto del gui√≥n:/gi,
    /^Contenido:/gi,
    /^\*\*Secci√≥n \d+\*\*/gi,
    /^\# Secci√≥n \d+/gi,
    /^---+/g,
    /^\*\*Gui√≥n para TTS:\*\*/gi,
    /^\*\*Respuesta:\*\*/gi,
    /^Aqu√≠ est√° el gui√≥n:/gi,
    /^El gui√≥n para la secci√≥n \d+ es:/gi,
  ];
  
  // Aplicar limpieza de patrones
  unwantedPatterns.forEach(pattern => {
    cleanText = cleanText.replace(pattern, '').trim();
  });
  
  // Remover l√≠neas que parezcan comentarios o explicaciones
  const lines = cleanText.split('\n');
  const filteredLines = lines.filter(line => {
    const trimmedLine = line.trim();
    // Filtrar l√≠neas que parezcan comentarios o explicaciones
    return !trimmedLine.startsWith('*') && 
           !trimmedLine.startsWith('#') && 
           !trimmedLine.startsWith('//') &&
           !trimmedLine.startsWith('Nota:') &&
           !trimmedLine.startsWith('Aclaraci√≥n:') &&
           trimmedLine.length > 0;
  });
  
  return filteredLines.join('\n').trim();
}

// Funci√≥n para crear estructura de carpetas
function createProjectStructure(topic, section, customFolderName = null) {
  // Usar nombre personalizado si se proporciona, sino usar el tema
  const folderName = customFolderName && customFolderName.trim() 
    ? createSafeFolderName(customFolderName.trim())
    : createSafeFolderName(topic);
    
  const outputsDir = path.join('./public/outputs');
  const projectDir = path.join(outputsDir, folderName);
  const sectionDir = path.join(projectDir, `seccion_${section}`);
  
  // Crear todas las carpetas necesarias
  if (!fs.existsSync(outputsDir)) {
    fs.mkdirSync(outputsDir, { recursive: true });
  }
  if (!fs.existsSync(projectDir)) {
    fs.mkdirSync(projectDir, { recursive: true });
  }
  if (!fs.existsSync(sectionDir)) {
    fs.mkdirSync(sectionDir, { recursive: true });
  }
  
  return {
    outputsDir,
    projectDir,
    sectionDir,
    safeTopicName: folderName
  };
}

// Funci√≥n para guardar archivo de audio WAV
async function saveWaveFile(filename, pcmData, channels = 1, rate = 24000, sampleWidth = 2) {
  return new Promise((resolve, reject) => {
    const writer = new wav.FileWriter(filename, {
      channels,
      sampleRate: rate,
      bitDepth: sampleWidth * 8,
    });

    writer.on('finish', resolve);
    writer.on('error', reject);

    writer.write(pcmData);
    writer.end();
  });
}

// Funci√≥n para determinar el tono de narraci√≥n basado en el tema
function getNarrationTone(topic) {
  // Tono fijo: c√°lido y amigable para todos los temas
  return " ";
}

// Funci√≥n para generar audio del gui√≥n
async function generateStoryAudio(script, voiceName = 'Orus', sectionDir, topic, section, customNarrationStyle = null) {
  try {
    console.log(`üéµ Generando narraci√≥n del gui√≥n con voz: ${voiceName}...`);
    console.log(`üìù Script a narrar (primeros 100 caracteres): ${script.substring(0, 100)}...`);
    console.log(`üìè Longitud del script: ${script.length} caracteres`);
    
    // Verificar si el script es demasiado largo
    if (script.length > 5000) {
      console.log(`‚ö†Ô∏è Script muy largo (${script.length} caracteres), truncando a 5000...`);
      script = script.substring(0, 5000) + "...";
    }
    
    // Usar estilo de narraci√≥n personalizado si se proporciona, sino usar el tono por defecto
    let narrationTone;
    if (customNarrationStyle && customNarrationStyle.trim()) {
      narrationTone = `${customNarrationStyle.trim()}: `;
      console.log(`üé≠ Estilo de narraci√≥n personalizado: ${narrationTone}`);
    } else {
      narrationTone = getNarrationTone(topic);
      console.log(`üé≠ Tono de narraci√≥n por defecto: ${narrationTone}`);
    }
    
    // Intentar con configuraci√≥n m√°s simple
    const response = await ai.models.generateContent({
      model: "gemini-2.5-flash-preview-tts",
      contents: [{ 
        parts: [{ 
          text: `Narra el siguiente gui√≥n ${narrationTone}:

${script}`
        }] 
      }],
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { 
              voiceName: voiceName 
            }
          }
        }
      }
    });

    console.log(`üîç Respuesta recibida:`, {
      candidates: response.candidates?.length || 0,
      hasContent: !!response.candidates?.[0]?.content,
      hasParts: !!response.candidates?.[0]?.content?.parts,
      partsLength: response.candidates?.[0]?.content?.parts?.length || 0
    });

    const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    if (!audioData) {
      console.log(`‚ùå Estructura de respuesta completa:`, JSON.stringify(response, null, 2));
      throw new Error('No se gener√≥ audio - revisa los logs para m√°s detalles');
    }

    console.log(`‚úÖ Audio data recibido, tama√±o: ${audioData.length} caracteres`);

    const audioBuffer = Buffer.from(audioData, 'base64');
    const safeTopicName = createSafeFolderName(topic);
    const fileName = `${safeTopicName}_seccion_${section}_${Date.now()}.wav`;
    const filePath = path.join(sectionDir, fileName);
    
    await saveWaveFile(filePath, audioBuffer);
    console.log(`‚úÖ Audio generado exitosamente con voz ${voiceName} en: ${filePath}`);
    
    // Retornar la ruta relativa para acceso web
    const relativePath = path.relative('./public', filePath).replace(/\\/g, '/');
    return relativePath;
  } catch (error) {
    console.error('‚ùå Error generando audio:', error.message);
    console.error('‚ùå Error completo:', error);
    
    // Si es un error de API, intentar diagnosticar
    if (error.message && error.message.includes('API')) {
      console.error('‚ùå Posible problema con la API de Gemini TTS');
    }
    
    // Crear un archivo de texto como fallback
    console.log('üìù Generando archivo de texto como alternativa...');
    const safeTopicName = createSafeFolderName(topic);
    const textFileName = `${safeTopicName}_seccion_${section}_guion_audio_fallback.txt`;
    const textFilePath = path.join(sectionDir, textFileName);
    
    const textContent = `GUI√ìN PARA AUDIO - SECCI√ìN ${section}
===============================
Tema: ${topic}
Voz solicitada: ${voiceName}
Fecha: ${new Date().toLocaleString()}
Estado: Audio no disponible (usando texto como fallback)

CONTENIDO DEL GUI√ìN:
${script}

===============================
NOTA: Este archivo se gener√≥ porque el servicio de Text-to-Speech 
no est√° disponible temporalmente. El contenido del gui√≥n se ha 
guardado para referencia futura.
`;
    
    try {
      fs.writeFileSync(textFilePath, textContent, 'utf8');
      const textRelativePath = path.relative('./public', textFilePath).replace(/\\/g, '/');
      console.log(`üìù Archivo de texto fallback generado: ${textRelativePath}`);
    } catch (writeError) {
      console.error('‚ùå Error creando archivo de texto:', writeError);
    }
    
    throw new Error(`Error al generar audio: ${error.message}. El servicio TTS puede estar temporalmente no disponible.`);
  }
}

// Funci√≥n para generar im√°genes con diferentes modelos
async function generateImageWithModel(ai, prompt, modelType) {
  console.log(`üîç DEBUG - generateImageWithModel llamada con modelType: "${modelType}"`);
  console.log(`üîç DEBUG - Tipo de modelType: ${typeof modelType}`);
  console.log(`üîç DEBUG - ¬øEs igual a 'gemini2'?: ${modelType === 'gemini2'}`);
  
  if (modelType === 'gemini2') {
    console.log(`ü§ñ Usando Gemini 2.0 Flash nativo...`);
    // Usar Gemini 2.0 nativo con responseModalities
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-preview-image-generation",
      contents: prompt,
      config: {
        responseModalities: [Modality.TEXT, Modality.IMAGE],
      },
    });

    const images = [];
    for (const part of response.candidates[0].content.parts) {
      if (part.inlineData && part.inlineData.mimeType?.includes('image')) {
        images.push({
          image: {
            imageBytes: part.inlineData.data
          }
        });
      }
    }
    
    return {
      generatedImages: images
    };
  } else {
    console.log(`ü§ñ Usando Imagen 4.0 tradicional...`);
    // Usar Imagen 4.0 (m√©todo tradicional)
    return await ai.models.generateImages({
      model: 'imagen-4.0-generate-preview-06-06',
      prompt: prompt,
      config: {
        numberOfImages: 1,
        aspectRatio: "16:9",
      },
    });
  }
}

// Funci√≥n para generar prompts seg√∫n el estilo seleccionado
function generateScriptPrompt(style, topic, sections, section, customStyleInstructions = null) {
  console.log(`üé® DEBUG BACKEND - generateScriptPrompt llamada:`);
  console.log(`üé® DEBUG BACKEND - style: "${style}"`);
  console.log(`üé® DEBUG BACKEND - customStyleInstructions: "${customStyleInstructions}"`);
  console.log(`üé® DEBUG BACKEND - style.startsWith('custom_'): ${style && style.startsWith('custom_')}`);
  
  if (style === 'comedy') {
    console.log(`üé® DEBUG BACKEND - Usando estilo comedy`);
    return generateComedyPrompt(topic, sections, section);
  } else if (style && style.startsWith('custom_') && customStyleInstructions) {
    console.log(`üé® DEBUG BACKEND - Usando estilo personalizado: ${style}`);
    return generateCustomPrompt(topic, sections, section, customStyleInstructions);
  } else {
    console.log(`üé® DEBUG BACKEND - Usando estilo profesional (default)`);
    return generateProfessionalPrompt(topic, sections, section);
  }
}

// Funci√≥n para generar prompt con estilo personalizado
function generateCustomPrompt(topic, sections, section, customInstructions) {
  const currentSection = section;
  const totalSections = sections;
  
  if (currentSection === 1) {
    // Primera secci√≥n
    return `${customInstructions}

TEMA SOLICITADO: "${topic}"
TOTAL DE SECCIONES: ${sections}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} secciones sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO LA SECCI√ìN 1 DE ${sections}.

INSTRUCCIONES GENERALES:
- Crea contenido basado exactamente en lo que el usuario ha pedido en el tema
- Si es sobre lore de videojuegos, enf√≥cate en la historia interna del juego
- Si es sobre desarrollo/creaci√≥n de videojuegos, enf√≥cate en los aspectos reales de producci√≥n
- Si es sobre historia de la industria, enf√≥cate en hechos hist√≥ricos y datos
- Adapta tu estilo narrativo al tipo de contenido solicitado
- APLICA ESTRICTAMENTE el estilo personalizado especificado arriba
- NO REPITAS IDEAS, SI ES NECESARIO SALTE UN POCO DEL TEMA PARA EXPLORAR NUEVAS PERSPECTIVAS, PUEDES EXPLORAR CURIOSIDADES TAMBIEN, EASTER EGGS, ETC.

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n el estilo personalizado establecido arriba
- Establece las bases del tema para las siguientes secciones

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n 1:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n
- APLICA FIELMENTE el estilo personalizado: ${customInstructions}

IMPORTANTE: 
- Esta es la PRIMERA secci√≥n, establece los fundamentos del tema, da una bienvenida al canal
- NO incluyas despedida ya que habr√° m√°s secciones
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    // Secciones posteriores
    return `Ahora dame la secci√≥n ${currentSection} de ${totalSections} del mismo tema.

MANT√âN EXACTAMENTE EL MISMO ESTILO PERSONALIZADO: ${customInstructions}

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN ${currentSection}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n continuidad narrativa con las secciones anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo y enfoque que estableciste en las secciones anteriores
- APLICA ESTRICTAMENTE el estilo personalizado: ${customInstructions}

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n ${currentSection}:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${currentSection === totalSections ? `IMPORTANTE: Como esta es la √öLTIMA secci√≥n (${currentSection}/${totalSections}), DEBES incluir una despedida profesional al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida: "Y as√≠ concluye este episodio sobre [tema]... Si este contenido te ha resultado interesante, d√©janos un like y suscr√≠bete al canal para m√°s contenido. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos..."` : 'NO incluyas despedida ya que esta no es la √∫ltima secci√≥n.'}

üéØ RECORDATORIO CR√çTICO: Debes seguir fielmente este estilo: ${customInstructions}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
}

// Funci√≥n para generar prompt estilo profesional (original)
function generateProfessionalPrompt(topic, sections, section) {
  if (section === 1) {
    return `Eres un escritor profesional especializado en guiones para YouTube del canal que el usuario indique, si no indica entonces es para "Cr√≥nicas del Gaming".

TEMA SOLICITADO: "${topic}"
TOTAL DE SECCIONES: ${sections}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} secciones sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO LA SECCI√ìN 1 DE ${sections}.

INSTRUCCIONES GENERALES:
- Crea contenido basado exactamente en lo que el usuario ha pedido en el tema
- Si es sobre lore de videojuegos, enf√≥cate en la historia interna del juego
- Si es sobre desarrollo/creaci√≥n de videojuegos, enf√≥cate en los aspectos reales de producci√≥n
- Si es sobre historia de la industria, enf√≥cate en hechos hist√≥ricos y datos
- Adapta tu estilo narrativo al tipo de contenido solicitado

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n un tono profesional y enganchante
- Establece las bases del tema para las siguientes secciones

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n 1:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

IMPORTANTE: 
- Esta es la PRIMERA secci√≥n, establece los fundamentos del tema
- NO incluyas despedida ya que habr√° m√°s secciones
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    return `Ahora dame la secci√≥n ${section} de ${sections} del mismo tema.

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN ${section}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n continuidad narrativa con las secciones anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo y enfoque que estableciste en las secciones anteriores

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n ${section}:", "Gui√≥n:", etc.
- NO incluyas notas, aclaraciones o pensamientos
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${section === sections ? `IMPORTANTE: Como esta es la √öLTIMA secci√≥n (${section}/${sections}), DEBES incluir una despedida profesional al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida: "Y as√≠ concluye este episodio sobre [tema]... Si este contenido te ha resultado interesante, d√©janos un like y suscr√≠bete a al canal para m√°s contenido. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos..."` : 'NO incluyas despedida ya que esta no es la √∫ltima secci√≥n.'}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
}

// Funci√≥n para generar prompt estilo c√≥mico/sarc√°stico
function generateComedyPrompt(topic, sections, section) {
  if (section === 1) {
    return `Eres un escritor de guiones para gameplays del canal de YouTube Cr√≥nicas del Gaming.

Tu tarea es construir guiones con un tono sarc√°stico, ir√≥nico, con humor negro, muchas groser√≠as y un chingo de humor absurdo.

TEMA SOLICITADO: "${topic}"
TOTAL DE SECCIONES: ${sections}

Vamos a crear un gui√≥n de YouTube dividido en ${sections} secciones sobre el tema que el usuario ha solicitado.

POR FAVOR, DAME SOLO LA SECCI√ìN 1 DE ${sections}.

üé≠ FORMATO DEL GUION:

El guion debe leerse como una actuaci√≥n, adem√°s de una narraci√≥n cronol√≥gica.

Usa m√∫ltiples voces indicadas con corchetes, por ejemplo:
[voz de narrador serio], [voz sarc√°stica], [grito desesperado], [voz de ni√±a loca], [voz de viejita], etc.

Las escenas deben sentirse teatrales, exageradas, bizarras y alucinantes.
en algunas ocasiones interpreta lo que los personajes en el guion podrian decir o pensar.

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN 1:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n un tono sarc√°stico, ir√≥nico y absurdo y muy √°cido.
- Establece las bases del tema para las siguientes secciones

PALABRAS Y EXPRESIONES A USAR:
Usas algunas veces palabras como: pinche, wey, pendejo, cabr√≥n, verga, chinga tu madre, me vale verga, come verga, hijo de la verga.

RESTRICCIONES:
- No se permite usar la palabra "show"
- No se permiten chistes sobre pol√≠ticos ni ex parejas

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n 1:", "Gui√≥n:", etc.
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

IMPORTANTE: 
- Esta es la PRIMERA secci√≥n, establece los fundamentos del tema
- NO incluyas despedida ya que habr√° m√°s secciones
- Basa tu contenido completamente en lo que el usuario solicita en el tema
- RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, NADA M√ÅS`;
  } else {
    return `Ahora dame la secci√≥n ${section} de ${sections} del mismo tema.

Mant√©n el mismo estilo sarc√°stico, ir√≥nico, con humor negro y groser√≠as.

ESTRUCTURA REQUERIDA PARA LA SECCI√ìN ${section}:
- Exactamente 3 p√°rrafos detallados
- M√°ximo 300 palabras en total para esta secci√≥n
- M√≠nimo 250 palabras por secci√≥n
- Mant√©n continuidad narrativa con las secciones anteriores
- Progresa de manera l√≥gica en el desarrollo del tema
- Sigue el mismo estilo c√≥mico y absurdo que estableciste

üé≠ FORMATO DEL GUION:
- Usa m√∫ltiples voces indicadas con corchetes al menos 4 en cada p√°rrafo
- Usa onomatopeyas y efectos sonoros rid√≠culos
- Las escenas deben sentirse teatrales y exageradas

PALABRAS Y EXPRESIONES A USAR:
Usa muchas palabras como: pinche, wey, pendejo, cabr√≥n, verga, chinga tu madre, me vale verga, come verga.

FORMATO DE RESPUESTA OBLIGATORIO:
- Responde √öNICAMENTE con el texto del gui√≥n
- NO incluyas explicaciones, comentarios, ni texto adicional
- NO incluyas etiquetas como "Secci√≥n ${section}:", "Gui√≥n:", etc.
- El texto debe estar listo para ser usado directamente en TTS
- Comienza directamente con el contenido del gui√≥n

${section === sections ? `IMPORTANTE: Como esta es la √öLTIMA secci√≥n (${section}/${sections}), DEBES incluir una despedida c√≥mica al final que invite a:
- Comentar sus opiniones sobre el tema presentado
- Suscribirse al canal para m√°s contenido  
- Dar like si disfrutaron el contenido
- Sugerir futuros temas que les gustar√≠a ver

Ejemplo de despedida c√≥mica: "Y as√≠ concluye este pinche episodio sobre [tema]... Si te cagaste de risa, d√©janos un like y suscr√≠bete al canal para m√°s contenido cabr√≥n. Comp√°rtenos en los comentarios qu√© otros temas te gustar√≠a que cubramos, wey..."` : 'NO incluyas despedida ya que esta no es la √∫ltima secci√≥n.'}

RECUERDA: RESPONDE SOLO CON EL TEXTO DEL GUI√ìN, SIN COMENTARIOS NI EXPLICACIONES ADICIONALES.`;
  }
}

app.post('/generate', async (req, res) => {
  try {
    const { topic, folderName, voice, totalSections, currentSection, previousSections, imageCount, promptModifier, imageModel, skipImages, scriptStyle, customStyleInstructions } = req.body;
    
    console.log(`üîç DEBUG REQUEST - Datos recibidos en /generate:`);
    console.log(`üîç DEBUG REQUEST - topic: "${topic}"`);
    console.log(`üîç DEBUG REQUEST - scriptStyle: "${scriptStyle}"`);
    console.log(`üîç DEBUG REQUEST - customStyleInstructions: "${customStyleInstructions || 'N/A'}"`);
    console.log(`üîç DEBUG REQUEST - skipImages: ${skipImages} (tipo: ${typeof skipImages})`);
    console.log(`üîç DEBUG REQUEST - imageCount: ${imageCount}`);
    console.log(`üîç DEBUG REQUEST - Cuerpo completo:`, req.body);
    
    const selectedVoice = voice || 'Orus';
    const sections = totalSections || 3;
    const section = currentSection || 1;
    const selectedStyle = scriptStyle || 'professional'; // Default al estilo profesional
    const numImages = imageCount || 5; // Default a 5 im√°genes si no se especifica
    const additionalInstructions = promptModifier || ''; // Instrucciones adicionales para im√°genes
    const selectedImageModel = imageModel || 'gemini2'; // Default a gemini2 si no se especifica
    const shouldSkipImages = skipImages === true; // Verificar expl√≠citamente si es true
    
    console.log(`üéØ Solicitud recibida: ${shouldSkipImages ? 'SIN IM√ÅGENES' : numImages + ' im√°genes'} para la secci√≥n ${section}`);
    console.log(`üìÅ Nombre de carpeta personalizado: ${folderName || 'auto-generado'}`);
    console.log(`ÔøΩ Estilo de gui√≥n seleccionado: ${selectedStyle}`);
    console.log(`ÔøΩüé® Instrucciones adicionales recibidas:`, additionalInstructions);
    console.log(`üìä Tipo de dato additionalInstructions:`, typeof additionalInstructions);
    console.log(`ü§ñ Modelo de imagen seleccionado: ${selectedImageModel}`);
    console.log(`üìè Longitud additionalInstructions:`, additionalInstructions ? additionalInstructions.length : 0);
    console.log(`‚úÖ ¬øHay instrucciones adicionales?:`, !!additionalInstructions);
    console.log(`üö´ ¬øOmitir im√°genes?:`, shouldSkipImages);
    console.log(`üîç DEBUG - skipImages original: ${skipImages}, shouldSkipImages procesado: ${shouldSkipImages}`);
    
    if (!topic) {
      return res.status(400).json({ error: 'Tema requerido' });
    }

    // Crear estructura de carpetas
    const folderStructure = createProjectStructure(topic, section, folderName);
    console.log(`üìÅ Estructura de carpetas creada: ${folderStructure.sectionDir}`);

    // Crear clave √∫nica para la conversaci√≥n (proyecto)
    const projectKey = folderName ? createSafeFolderName(folderName) : createSafeFolderName(topic);
    const conversation = getOrCreateConversation(projectKey);
    
    console.log(`üí¨ Usando conversaci√≥n: ${projectKey}`);
    console.log(`üìù Historial actual: ${conversation.history.length} mensajes`);

    // Paso 1: Generar gui√≥n usando conversaci√≥n continua
    console.log(`üìù Generando gui√≥n de YouTube - Secci√≥n ${section}/${sections} para el tema: ${topic}...`);
    console.log(`üé≠ Usando estilo: ${selectedStyle === 'comedy' ? 'C√≥mico/Sarc√°stico' : 'Profesional'}`);
    
    let promptContent;
    
    if (section === 1) {
      // Primera secci√≥n: Configurar la conversaci√≥n inicial
      conversation.topic = topic;
      conversation.totalSections = sections;
      conversation.currentSection = 1;
      conversation.history = []; // Limpiar historial para nueva conversaci√≥n

      promptContent = generateScriptPrompt(selectedStyle, topic, sections, section, customStyleInstructions);

      // Limpiar historial y agregar mensaje inicial
      conversation.history = [
        { role: 'user', parts: [{ text: promptContent }] }
      ];
      
    } else {
      // Secciones posteriores: Continuar la conversaci√≥n
      promptContent = generateScriptPrompt(selectedStyle, topic, sections, section, customStyleInstructions);

      // Agregar nueva pregunta al historial
      conversation.history.push({ role: 'user', parts: [{ text: promptContent }] });
    }
    
    // Actualizar secci√≥n actual
    conversation.currentSection = section;

    // Generar respuesta usando el historial de conversaci√≥n
    let systemInstruction;
    if (selectedStyle === 'comedy') {
      systemInstruction = "Eres un escritor de guiones c√≥micos para YouTube con tono sarc√°stico y humor negro. IMPORTANTE: Responde √öNICAMENTE con el texto del gui√≥n, sin explicaciones, comentarios, etiquetas o texto adicional. El texto debe estar listo para TTS. Incluye groser√≠as, humor absurdo y m√∫ltiples voces entre corchetes. ESTRUCTURA OBLIGATORIA: Exactamente 3 p√°rrafos detallados, m√°ximo 300 palabras total, m√≠nimo 200 palabras. Solo el gui√≥n puro.";
    } else if (selectedStyle && selectedStyle.startsWith('custom_') && customStyleInstructions) {
      systemInstruction = `Eres un escritor de guiones para YouTube especializado en el estilo personalizado que el usuario ha definido. IMPORTANTE: Responde √öNICAMENTE con el texto del gui√≥n siguiendo exactamente estas instrucciones de estilo: ${customStyleInstructions}. Sin explicaciones, comentarios, etiquetas o texto adicional. El texto debe estar listo para TTS aplicando fielmente el estilo especificado. ESTRUCTURA OBLIGATORIA: Exactamente 3 p√°rrafos detallados, m√°ximo 250 palabras total, m√≠nimo 200 palabras por secci√≥n. Solo el gui√≥n puro.`;
    } else {
      systemInstruction = "Eres un escritor profesional de guiones para YouTube. IMPORTANTE: Responde √öNICAMENTE con el texto del gui√≥n, sin explicaciones, comentarios, etiquetas o texto adicional. El texto debe estar listo para TTS. No incluyas pensamientos, notas o aclaraciones. ESTRUCTURA OBLIGATORIA: Exactamente 3 p√°rrafos detallados, m√°ximo 300 palabras total, m√≠nimo 200 palabras. Solo el gui√≥n puro.";
    }

    const scriptResponse = await ai.models.generateContent({
      model: "models/gemini-2.5-pro",
      contents: conversation.history,
      config: {
        systemInstruction: systemInstruction,
      },
    });

    const script = scriptResponse.text;
    
    // Limpiar el script de cualquier texto adicional no deseado
    const cleanScript = cleanScriptText(script);
    
    // Agregar respuesta al historial
    conversation.history.push({ role: 'model', parts: [{ text: cleanScript }] });
    
    console.log(`‚úÖ Gui√≥n de la secci√≥n ${section} generado usando conversaci√≥n continua`);
    console.log(`üíæ Historial actualizado: ${conversation.history.length} mensajes`);

    // Guardar el gui√≥n como archivo de texto en la carpeta de la secci√≥n
    try {
      const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
      const scriptFilePath = path.join(folderStructure.sectionDir, scriptFileName);
      
      const scriptContent = `GUI√ìN DE LA SECCI√ìN ${section}
===============================
Tema: ${topic}
Secci√≥n: ${section} de ${sections}
Fecha de generaci√≥n: ${new Date().toLocaleString()}
${folderName ? `Nombre del proyecto: ${folderName}` : ''}

CONTENIDO DEL GUI√ìN:
${cleanScript}

===============================
Generado autom√°ticamente por el sistema de creaci√≥n de contenido
`;
      
      fs.writeFileSync(scriptFilePath, scriptContent, 'utf8');
      console.log(`üìù Gui√≥n guardado autom√°ticamente en: ${scriptFilePath}`);
    } catch (saveError) {
      console.error('‚ùå Error guardando archivo de gui√≥n:', saveError);
      // No detener el proceso por este error, solo registrarlo
    }

    // Verificar si se deben omitir las im√°genes
    if (shouldSkipImages) {
      console.log(`üö´ Omitiendo generaci√≥n de im√°genes, pero generando prompts para mostrar`);
      console.log(`üîç DEBUG SKIP - shouldSkipImages: ${shouldSkipImages}`);
      console.log(`üîç DEBUG SKIP - numImages: ${numImages}`);
      
      // Generar prompts para mostrar al usuario aunque no se generen im√°genes
      console.log(`üé® Generando prompts para secuencia de ${numImages} im√°genes (solo texto)...`);
      const promptsResponse = await ai.models.generateContent({
        model: "models/gemini-2.5-pro",
        contents: `Bas√°ndote en este gui√≥n de la secci√≥n ${section} sobre "${topic}": "${cleanScript}", crea EXACTAMENTE ${numImages} prompts detallados para generar una SECUENCIA de ${numImages} im√°genes que ilustren visualmente el contenido del gui√≥n en orden cronol√≥gico.

        IMPORTANTE: Debes crear EXACTAMENTE ${numImages} prompts, ni m√°s ni menos.

        ENFOQUE:
        - Las im√°genes deben seguir la narrativa del gui√≥n paso a paso
        - Cada imagen debe representar una parte espec√≠fica del gui√≥n en orden
        - Enf√≥cate en elementos del lore interno del juego mencionados en el gui√≥n
        - Ilustra lugares, personajes, eventos y elementos espec√≠ficos del gui√≥n
        - Mant√©n consistencia visual entre las ${numImages} im√°genes

        INSTRUCCIONES CR√çTICAS PARA EL FORMATO:
        - DEBES dividir el gui√≥n en EXACTAMENTE ${numImages} partes cronol√≥gicas
        - DEBES crear un prompt independiente para cada parte
        - DEBES separar cada prompt con "||PROMPT||" (sin espacios adicionales)
        - DEBES asegurarte de que haya exactamente ${numImages} prompts en tu respuesta
        - Las im√°genes deben contar la historia del gui√≥n de forma visual secuencial
        - Incluye detalles espec√≠ficos mencionados en el texto del gui√≥n

        REQUISITOS OBLIGATORIOS para cada prompt:
        - Formato: Aspecto 16:9 (widescreen)
        
        FORMATO DE RESPUESTA OBLIGATORIO:
        DEBES presentar EXACTAMENTE ${numImages} prompts separados por "||PROMPT||" (sin espacios antes o despu√©s del delimitador).
        
        ESTRUCTURA REQUERIDA:
        Prompt 1 aqu√≠||PROMPT||Prompt 2 aqu√≠||PROMPT||Prompt 3 aqu√≠||PROMPT||... hasta el Prompt ${numImages}
        
        EJEMPLO PARA 3 PROMPTS (adaptar a ${numImages}):
        Un bosque oscuro con √°rboles ancianos||PROMPT||Una batalla √©pica entre guerreros||PROMPT||Un castillo en ruinas bajo la luna
        
        VERIFICACI√ìN FINAL: Tu respuesta debe contener exactamente ${numImages - 1} ocurrencias del delimitador "||PROMPT||" para generar ${numImages} prompts.`,
        config: {
          systemInstruction: `Eres un experto en arte conceptual y narrativa visual. Tu √öNICA tarea es crear prompts separados por "||PROMPT||". 

REGLAS CR√çTICAS:
1. SIEMPRE usa el delimitador exacto "||PROMPT||" (sin espacios adicionales)
2. NUNCA generes texto adicional fuera de los prompts
3. CUENTA cuidadosamente para generar el n√∫mero exacto solicitado
4. DIVIDE el contenido equitativamente entre todos los prompts
5. Cada prompt debe ser independiente y descriptivo

Si te piden N prompts, tu respuesta debe tener exactamente (N-1) delimitadores "||PROMPT||".`,
        },
      });

      const promptsText = promptsResponse.text || '';
      console.log(`üìù DEBUG SKIP - Respuesta del modelo: ${promptsText ? promptsText.substring(0, 200) + '...' : 'RESPUESTA VAC√çA'}`);
      console.log(`üîç DEBUG SKIP - Buscando delimitadores "||PROMPT||" en la respuesta...`);
      
      const imagePrompts = promptsText.split('||PROMPT||').filter(p => p.trim()).slice(0, numImages);
      console.log(`üîç DEBUG SKIP - Delimitadores encontrados: ${promptsText.split('||PROMPT||').length - 1}`);
      console.log(`üîç DEBUG SKIP - Prompts despu√©s del filtro: ${imagePrompts.length}`);
      console.log(`üî¢ DEBUG SKIP - Se solicitaron ${numImages} prompts, se generaron ${imagePrompts.length} prompts v√°lidos`);
      console.log(`üé® DEBUG SKIP - Primeros 3 prompts:`, imagePrompts.slice(0, 3));
      
      // Aplicar instrucciones adicionales a los prompts si existen
      let enhancedPrompts = imagePrompts;
      if (additionalInstructions && additionalInstructions.trim()) {
        console.log(`‚úÖ DEBUG SKIP - Aplicando instrucciones adicionales a prompts: "${additionalInstructions}"`);
        enhancedPrompts = imagePrompts.map((prompt, index) => {
          const enhanced = `${prompt.trim()}. ${additionalInstructions.trim()}`;
          console.log(`üé® DEBUG SKIP - Prompt ${index + 1} mejorado: ${enhanced.substring(0, 100)}...`);
          return enhanced;
        });
      } else {
        console.log(`‚ùå DEBUG SKIP - No hay instrucciones adicionales para aplicar a prompts`);
      }
      
      // Guardar los prompts como archivo de texto en la carpeta de la secci√≥n
      try {
        const promptsFileName = `${folderStructure.safeTopicName}_seccion_${section}_prompts_imagenes.txt`;
        const promptsFilePath = path.join(folderStructure.sectionDir, promptsFileName);
        
        const promptsContent = `PROMPTS DE IM√ÅGENES - SECCI√ìN ${section}
===============================
Tema: ${topic}
Secci√≥n: ${section} de ${sections}
Cantidad de prompts: ${enhancedPrompts.length}
Fecha de generaci√≥n: ${new Date().toLocaleString()}
${folderName ? `Nombre del proyecto: ${folderName}` : ''}
${additionalInstructions ? `Instrucciones adicionales aplicadas: ${additionalInstructions}` : 'Sin instrucciones adicionales'}

PROMPTS GENERADOS:
${enhancedPrompts.map((prompt, index) => `
${index + 1}. ${prompt.trim()}
`).join('')}

===============================
NOTA: Estos prompts fueron generados para ilustrar visualmente 
el contenido del gui√≥n pero no se generaron im√°genes porque 
la opci√≥n "Omitir generaci√≥n de im√°genes" estaba activada.

Puedes usar estos prompts en cualquier generador de im√°genes 
como Midjourney, DALL-E, Stable Diffusion, etc.
===============================
Generado autom√°ticamente por el sistema de creaci√≥n de contenido
`;
        
        fs.writeFileSync(promptsFilePath, promptsContent, 'utf8');
        console.log(`üìù Prompts de im√°genes guardados autom√°ticamente en: ${promptsFilePath}`);
        
        // Crear informaci√≥n sobre el archivo de prompts guardado
        const promptsFileRelativePath = path.relative('./public', promptsFilePath).replace(/\\/g, '/');
        
        console.log(`‚úÖ Archivo de prompts creado: ${promptsFileRelativePath}`);
      } catch (saveError) {
        console.error('‚ùå Error guardando archivo de prompts:', saveError);
        // No detener el proceso por este error, solo registrarlo
      }
      
      // Crear informaci√≥n sobre el archivo de gui√≥n guardado
      const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
      const scriptFilePath = path.relative('./public', path.join(folderStructure.sectionDir, scriptFileName)).replace(/\\/g, '/');

      // Crear informaci√≥n sobre el archivo de prompts guardado
      const promptsFileName = `${folderStructure.safeTopicName}_seccion_${section}_prompts_imagenes.txt`;
      const promptsFilePath = path.relative('./public', path.join(folderStructure.sectionDir, promptsFileName)).replace(/\\/g, '/');

      console.log(`üîç DEBUG SKIP - Enviando respuesta con imagePrompts:`, !!enhancedPrompts);
      console.log(`üîç DEBUG SKIP - imagePrompts.length:`, enhancedPrompts.length);
      console.log(`üîç DEBUG SKIP - imagesSkipped:`, true);

      res.json({ 
        script: cleanScript,
        scriptFile: {
          path: scriptFilePath,
          filename: scriptFileName,
          saved: true
        },
        promptsFile: {
          path: promptsFilePath,
          filename: promptsFileName,
          saved: true
        },
        imagePrompts: enhancedPrompts,
        voice: selectedVoice,
        currentSection: section,
        totalSections: sections,
        topic: topic,
        isComplete: section >= sections,
        projectFolder: folderStructure.safeTopicName,
        sectionFolder: `seccion_${section}`,
        folderPath: path.relative('./public', folderStructure.sectionDir).replace(/\\/g, '/'),
        imagesSkipped: true
      });
      return;
    }

    // Paso 2: Crear prompts para im√°genes secuenciales basadas en el gui√≥n
    console.log(`üé® Generando prompts para secuencia de ${numImages} im√°genes...`);
    const promptsResponse = await ai.models.generateContent({
      model: "models/gemini-2.5-pro",
      contents: `Bas√°ndote en este gui√≥n de la secci√≥n ${section} sobre "${topic}" ": "${cleanScript}", crea EXACTAMENTE ${numImages} prompts detallados para generar una SECUENCIA de ${numImages} im√°genes que ilustren visualmente el contenido del gui√≥n en orden cronol√≥gico.

      IMPORTANTE: Debes crear EXACTAMENTE ${numImages} prompts, ni m√°s ni menos.

      ENFOQUE:
      - Las im√°genes deben seguir la narrativa del gui√≥n paso a paso
      - Cada imagen debe representar una parte espec√≠fica del gui√≥n en orden
      - Enf√≥cate en elementos del lore interno del juego mencionados en el gui√≥n
      - Ilustra lugares, personajes, eventos y elementos espec√≠ficos del gui√≥n
      - Mant√©n consistencia visual entre las ${numImages} im√°genes

      INSTRUCCIONES CR√çTICAS PARA EL FORMATO:
      - DEBES dividir el gui√≥n en EXACTAMENTE ${numImages} partes cronol√≥gicas
      - DEBES crear un prompt independiente para cada parte
      - DEBES separar cada prompt con "||PROMPT||" (sin espacios adicionales)
      - DEBES asegurarte de que haya exactamente ${numImages} prompts en tu respuesta
      - Las im√°genes deben contar la historia del gui√≥n de forma visual secuencial
      - Incluye detalles espec√≠ficos mencionados en el texto del gui√≥n

      REQUISITOS OBLIGATORIOS para cada prompt:
      - Formato: Aspecto 16:9 (widescreen)
      
      FORMATO DE RESPUESTA OBLIGATORIO:
      DEBES presentar EXACTAMENTE ${numImages} prompts separados por "||PROMPT||" (sin espacios antes o despu√©s del delimitador).
      
      ESTRUCTURA REQUERIDA:
      Prompt 1 aqu√≠||PROMPT||Prompt 2 aqu√≠||PROMPT||Prompt 3 aqu√≠||PROMPT||... hasta el Prompt ${numImages}
      
      EJEMPLO PARA 3 PROMPTS (adaptar a ${numImages}):
      Un bosque oscuro con √°rboles ancianos||PROMPT||Una batalla √©pica entre guerreros||PROMPT||Un castillo en ruinas bajo la luna
      
      VERIFICACI√ìN FINAL: Tu respuesta debe contener exactamente ${numImages - 1} ocurrencias del delimitador "||PROMPT||" para generar ${numImages} prompts.`,
      config: {
        systemInstruction: `Eres un experto en arte conceptual y narrativa visual. Tu √öNICA tarea es crear prompts separados por "||PROMPT||". 

REGLAS CR√çTICAS:
1. SIEMPRE usa el delimitador exacto "||PROMPT||" (sin espacios adicionales)
2. NUNCA generes texto adicional fuera de los prompts
3. CUENTA cuidadosamente para generar el n√∫mero exacto solicitado
4. DIVIDE el contenido equitativamente entre todos los prompts
5. Cada prompt debe ser independiente y descriptivo

Si te piden N prompts, tu respuesta debe tener exactamente (N-1) delimitadores "||PROMPT||".`,
      },
    });

    const promptsText = promptsResponse.text || '';
    console.log(`üìù Respuesta del modelo: ${promptsText ? promptsText.substring(0, 200) + '...' : 'RESPUESTA VAC√çA'}`);
    console.log(`üîç Buscando delimitadores "||PROMPT||" en la respuesta...`);
    
    const imagePrompts = promptsText.split('||PROMPT||').filter(p => p.trim()).slice(0, numImages);
    console.log(`üîç Delimitadores encontrados: ${promptsText.split('||PROMPT||').length - 1}`);
    console.log(`üîç Prompts despu√©s del filtro: ${imagePrompts.length}`);
    console.log(`üî¢ Se solicitaron ${numImages} im√°genes, se encontraron ${imagePrompts.length} prompts v√°lidos`);
    
    console.log(`üé® ${imagePrompts.length} prompts secuenciales generados para la secci√≥n ${section}`);

    // Paso 3: Generar las im√°genes secuenciales y guardarlas
    console.log(`üñºÔ∏è Generando secuencia de ${numImages} im√°genes...`);
    const imagePromises = imagePrompts.map(async (prompt, index) => {
      try {
        console.log(`üñºÔ∏è Generando imagen ${index + 1}/${numImages}...`);
        console.log(`üìã Prompt base para imagen ${index + 1}: ${prompt.trim().substring(0, 100)}...`);
        
        // Construir el prompt completo con estilo y agregar instrucciones adicionales al final
        let enhancedPrompt = `${prompt.trim()}.`;

        // Agregar instrucciones adicionales del usuario AL FINAL del prompt si existen
        if (additionalInstructions && additionalInstructions.trim()) {
          enhancedPrompt += `. ${additionalInstructions.trim()}`;
          console.log(`‚úÖ Instrucciones adicionales aplicadas al final de imagen ${index + 1}:`, additionalInstructions);
        } else {
          console.log(`‚ùå No hay instrucciones adicionales para imagen ${index + 1} (valor: "${additionalInstructions}")`);
        }
        
        console.log(`üìù Prompt completo para imagen ${index + 1}: ${enhancedPrompt}`);
        console.log(`ü§ñ Usando modelo: ${selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash (nativo)' : 'Imagen 4.0'}`);

        const imageResponse = await generateImageWithModel(ai, enhancedPrompt, selectedImageModel);

        if (imageResponse.generatedImages && imageResponse.generatedImages.length > 0) {
          const results = [];
          
          // Procesar las im√°genes generadas
          for (let varIndex = 0; varIndex < imageResponse.generatedImages.length; varIndex++) {
            const generatedImage = imageResponse.generatedImages[varIndex];
            const imageData = generatedImage.image.imageBytes;
            
            // Guardar imagen con nombre √∫nico
            const imageFileName = `${folderStructure.safeTopicName}_seccion_${section}_imagen_${index + 1}_${Date.now()}.png`;
            const imageFilePath = path.join(folderStructure.sectionDir, imageFileName);
            const imageBuffer = Buffer.from(imageData, 'base64');
            
            fs.writeFileSync(imageFilePath, imageBuffer);
            console.log(`üíæ Imagen ${index + 1} guardada en: ${imageFilePath}`);
            console.log(`ü§ñ Generada con: ${selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'}`);
            
            // Retornar ruta relativa para acceso web
            const relativePath = path.relative('./public', imageFilePath).replace(/\\/g, '/');
            
            results.push({ 
              index: index,
              originalPromptIndex: index,
              variationIndex: varIndex,
              image: imageData,
              imagePath: relativePath,
              prompt: enhancedPrompt,
              model: selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'
            });
          }
          
          return results;
        }
        return null;
      } catch (error) {
        console.error(`‚ùå Error generando imagen ${index + 1}:`, error);
        return null;
      }
    });

    const imageResults = await Promise.all(imagePromises);
    // Aplanar el array ya que cada prompt ahora devuelve un array de 3 im√°genes
    const allImages = imageResults.filter(result => result !== null).flat();

    if (allImages.length === 0) {
      return res.status(500).json({ error: 'No se pudo generar ninguna imagen' });
    }

    console.log(`‚úÖ ${allImages.length} im√°genes generadas (${imagePrompts.length} prompts √ó 3 variaciones cada uno) para la secci√≥n ${section}`);

    // Crear informaci√≥n sobre el archivo de gui√≥n guardado
    const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
    const scriptFilePath = path.relative('./public', path.join(folderStructure.sectionDir, scriptFileName)).replace(/\\/g, '/');

    res.json({ 
      images: allImages,
      script: cleanScript,
      scriptFile: {
        path: scriptFilePath,
        filename: scriptFileName,
        saved: true
      },
      imagePrompts: imagePrompts,
      voice: selectedVoice,
      sequenceType: 'chronological',
      currentSection: section,
      totalSections: sections,
      topic: topic,
      isComplete: section >= sections,
      projectFolder: folderStructure.safeTopicName,
      sectionFolder: `seccion_${section}`,
      folderPath: path.relative('./public', folderStructure.sectionDir).replace(/\\/g, '/')
    });
  } catch (error) {
    console.error('‚ùå Error:', error);
    res.status(500).json({ error: 'Error generando contenido' });
  }
});

// RUTA COMENTADA - Ahora usamos el cliente Applio directo en Node.js
/*
// Nueva ruta simple para generar audio TTS (compatible con applio_tts)
app.post('/applio_tts', async (req, res) => {
  try {
    const { text, sectionDir } = req.body;
    
    if (!text || !text.trim()) {
      return res.status(400).json({ error: 'Texto requerido para generar audio' });
    }

    console.log(`üéµ Intentando TTS para texto: ${text.substring(0, 100)}...`);
    
    // Intentar primero con servidor Applio externo si est√° disponible
    const APPLIO_URL = process.env.APPLIO_SERVER_URL || "http://localhost:5004";
    
    try {
      console.log(`üîó Intentando conexi√≥n con servidor Applio en ${APPLIO_URL}...`);
      const applioResponse = await fetch(`${APPLIO_URL}/applio_tts`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text }),
        timeout: 5000 // 5 segundos timeout
      });
      
      if (applioResponse.ok) {
        console.log(`‚úÖ Servidor Applio respondi√≥ exitosamente`);
        // Reenviar la respuesta del servidor Applio
        const audioBuffer = await applioResponse.buffer();
        res.setHeader('Content-Type', 'audio/wav');
        res.setHeader('Content-Length', audioBuffer.length);
        return res.send(audioBuffer);
      }
    } catch (applioError) {
      console.log(`‚ö†Ô∏è Servidor Applio no disponible: ${applioError.message}`);
      console.log(`üîÑ Intentando con Gemini TTS como fallback...`);
    }
    
    // Fallback a Gemini TTS
    const response = await ai.models.generateContent({
      model: "gemini-2.5-pro-preview-tts",
      contents: [{ 
        parts: [{ 
          text: `Narra el siguiente texto de manera natural y clara: ${text}`
        }] 
      }],
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { 
              voiceName: 'Orus' 
            }
          }
        }
      }
    });

    const audioData = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    if (!audioData) {
      throw new Error('No se pudo generar el audio con Gemini TTS');
    }

    const audioBuffer = Buffer.from(audioData, 'base64');
    
    // Configurar headers para audio streaming
    res.setHeader('Content-Type', 'audio/wav');
    res.setHeader('Content-Length', audioBuffer.length);
    
    // Enviar el audio directamente como stream
    res.send(audioBuffer);
    
  } catch (error) {
    console.error('‚ùå Error en TTS:', error);
    
    // Mensaje m√°s espec√≠fico basado en el tipo de error
    let errorMessage = 'Error generando audio TTS';
    if (error.status === 429) {
      errorMessage = 'Cuota de TTS excedida. Intenta nuevamente en unos minutos o configura servidor Applio.';
    }
    
    res.status(500).json({ error: errorMessage });
  }
});
*/

// Nueva ruta para generar solo el audio del gui√≥n
app.post('/generate-audio', async (req, res) => {
  try {
    const { script, voice, topic, folderName, currentSection, narrationStyle } = req.body;
    
    if (!topic || !currentSection) {
      return res.status(400).json({ error: 'Tema y secci√≥n requeridos para organizar archivos' });
    }

    const selectedVoice = voice || 'Orus';
    const section = currentSection || 1;
    const customNarrationStyle = narrationStyle || null;
    
    // Si no se proporciona script, intentar leerlo del archivo guardado
    let scriptContent = script;
    if (!scriptContent) {
      console.log(`üîç Script no proporcionado, intentando leer archivo de secci√≥n ${section}...`);
      
      try {
        const folderStructure = createProjectStructure(topic, section, folderName);
        const scriptFileName = `${folderStructure.safeTopicName}_seccion_${section}_guion.txt`;
        const scriptFilePath = path.join(folderStructure.sectionDir, scriptFileName);
        
        if (fs.existsSync(scriptFilePath)) {
          scriptContent = fs.readFileSync(scriptFilePath, 'utf8');
          console.log(`‚úÖ Script le√≠do desde archivo: ${scriptFilePath}`);
        } else {
          return res.status(400).json({ error: `No se encontr√≥ el gui√≥n para la secci√≥n ${section}. Archivo esperado: ${scriptFilePath}` });
        }
      } catch (readError) {
        console.error('‚ùå Error leyendo archivo de script:', readError);
        return res.status(400).json({ error: 'No se pudo leer el gui√≥n de la secci√≥n. Aseg√∫rate de que el gui√≥n se haya generado primero.' });
      }
    }
    
    if (!scriptContent || scriptContent.trim() === '') {
      return res.status(400).json({ error: 'Gui√≥n vac√≠o o no v√°lido' });
    }
    
    // Crear estructura de carpetas para el audio
    const folderStructure = createProjectStructure(topic, section, folderName);
    
    console.log(`üéµ Generando audio del gui√≥n con voz ${selectedVoice}...`);
    if (customNarrationStyle) {
      console.log(`üé≠ Estilo de narraci√≥n personalizado recibido: "${customNarrationStyle}"`);
    }
    
    try {
      const audioFilePath = await generateStoryAudio(scriptContent, selectedVoice, folderStructure.sectionDir, topic, section, customNarrationStyle);
      
      res.json({ 
        success: true,
        audio: audioFilePath,
        voice: selectedVoice,
        projectFolder: folderStructure.safeTopicName,
        sectionFolder: `seccion_${section}`
      });
    } catch (audioError) {
      console.error('‚ùå Error espec√≠fico en generaci√≥n de audio:', audioError.message);
      
      // Responder con informaci√≥n m√°s espec√≠fica sobre el error
      res.status(500).json({ 
        error: 'Error generando audio',
        details: audioError.message,
        suggestion: 'El servicio de Text-to-Speech puede estar temporalmente no disponible. Intenta nuevamente en unos momentos.'
      });
    }
  } catch (error) {
    console.error('‚ùå Error general en endpoint de audio:', error);
    res.status(500).json({ error: 'Error procesando solicitud de audio' });
  }
});

// Nueva ruta para regenerar una imagen espec√≠fica
app.post('/regenerate-image', async (req, res) => {
  try {
    const { prompt, imageIndex, topic, folderName, currentSection, imageModel } = req.body;
    
    if (!prompt || typeof imageIndex !== 'number') {
      return res.status(400).json({ error: 'Prompt e √≠ndice de imagen requeridos' });
    }

    if (!topic || !currentSection) {
      return res.status(400).json({ error: 'Tema y secci√≥n requeridos para organizar archivos' });
    }

    const selectedImageModel = 'gemini2'; // TEMPORAL: Forzar Gemini 2.0 para depuraci√≥n
    console.log(`üîÑ Regenerando imagen ${imageIndex + 1} con nuevo prompt...`);
    console.log(`ü§ñ Forzando uso de Gemini 2.0 Flash para depuraci√≥n...`);
    console.log(`üîç Modelo recibido del frontend: ${imageModel}`);
    console.log(`üîç Modelo que se usar√°: ${selectedImageModel}`);
    
    // Crear estructura de carpetas
    const folderStructure = createProjectStructure(topic, currentSection, folderName);
    
    try {
      console.log(`üîç DEBUG REGENERACION - Iniciando proceso de regeneraci√≥n...`);
      console.log(`üîç DEBUG REGENERACION - Prompt recibido: ${prompt.substring(0, 50)}...`);
      
      // Agregar especificaciones de estilo oscuro 2D al prompt
      const enhancedPrompt = `${prompt.trim()}. `;
      console.log(`üîç DEBUG REGENERACION - Enhanced prompt: ${enhancedPrompt.substring(0, 50)}...`);
      console.log(`üîç DEBUG REGENERACION - Llamando a generateImageWithModel con modelo: ${selectedImageModel}`);

      const imageResponse = await generateImageWithModel(ai, enhancedPrompt, selectedImageModel);
      console.log(`üîç DEBUG REGENERACION - Respuesta recibida:`, !!imageResponse);

      if (imageResponse.generatedImages && imageResponse.generatedImages.length > 0) {
        const regeneratedImages = [];
        
        // Procesar las im√°genes generadas
        for (let varIndex = 0; varIndex < imageResponse.generatedImages.length; varIndex++) {
          const generatedImage = imageResponse.generatedImages[varIndex];
          const imageData = generatedImage.image.imageBytes;
          
          // Guardar imagen regenerada con un nombre √∫nico
          const timestamp = Date.now();
          const imageFileName = `${folderStructure.safeTopicName}_seccion_${currentSection}_imagen_${imageIndex + 1}_regenerated_${timestamp}.png`;
          const imageFilePath = path.join(folderStructure.sectionDir, imageFileName);
          const imageBuffer = Buffer.from(imageData, 'base64');
          
          fs.writeFileSync(imageFilePath, imageBuffer);
          console.log(`üíæ Imagen regenerada ${imageIndex + 1} guardada en: ${imageFilePath}`);
          console.log(`ü§ñ Regenerada con: ${selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'}`);
          
          // Retornar ruta relativa para acceso web
          const relativePath = path.relative('./public', imageFilePath).replace(/\\/g, '/');
          
          regeneratedImages.push({
            image: imageData,
            imagePath: relativePath,
            variationIndex: varIndex,
            model: selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'
          });
        }
        
        res.json({ 
          success: true,
          images: regeneratedImages,
          prompt: enhancedPrompt,
          imageIndex: imageIndex,
          model: selectedImageModel === 'gemini2' ? 'Gemini 2.0 Flash' : 'Imagen 4.0'
        });
        return;
      }
      
      res.status(500).json({ error: 'No se pudo regenerar la imagen' });
      
    } catch (error) {
      console.error('‚ùå Error regenerando imagen:', error.message);
      res.status(500).json({ 
        error: 'Error regenerando imagen',
        details: error.message
      });
    }
  } catch (error) {
    console.error('‚ùå Error general en endpoint de regenerar imagen:', error);
    res.status(500).json({ error: 'Error procesando solicitud de regeneraci√≥n' });
  }
});

// Nueva ruta para generar audio de secci√≥n espec√≠fica usando cliente Applio Node.js
app.post('/generate-section-audio', async (req, res) => {
  try {
    const { script, topic, folderName, currentSection, voice } = req.body;
    
    if (!script || !topic || !currentSection) {
      return res.status(400).json({ 
        error: 'Script, tema y n√∫mero de secci√≥n son requeridos' 
      });
    }

    const section = parseInt(currentSection);
    
    // Crear estructura de carpetas
    const folderStructure = createProjectStructure(topic, section, folderName);
    
    console.log(`üéµ Generando audio con Applio Node.js para secci√≥n ${section}...`);
    
    try {
      // Verificar conexi√≥n con Applio primero
      const isConnected = await applioClient.checkConnection();
      if (!isConnected) {
        throw new Error('Applio no est√° disponible en el puerto 6969');
      }
      
      // Crear nombre del archivo
      const safeTopicName = createSafeFolderName(topic);
      const fileName = `${safeTopicName}_seccion_${section}_applio_${Date.now()}.wav`;
      const filePath = path.join(folderStructure.sectionDir, fileName);
      
      console.log(`üìÅ Guardando audio en: ${filePath}`);
      
      // Generar audio con Applio
      const result = await applioClient.textToSpeech(script, filePath, {
        model: "fr-FR-RemyMultilingualNeural",
        speed: 0,
        pitch: 0
      });
      
      if (!result.success) {
        throw new Error('Applio no gener√≥ el audio correctamente');
      }
      
      console.log(`‚úÖ Audio Applio generado exitosamente: ${filePath}`);
      console.log(`üìä Tama√±o del archivo: ${(result.size / 1024).toFixed(1)} KB`);
      
      // Retornar la ruta relativa para acceso web
      const relativePath = path.relative('./public', filePath).replace(/\\/g, '/');
      
      res.json({ 
        success: true,
        audioFile: relativePath,
        method: 'Applio Node.js',
        section: section,
        size: result.size,
        message: `Audio generado con Applio para la secci√≥n ${section}`
      });
      
    } catch (applioError) {
      console.error('‚ùå Error con cliente Applio Node.js:', applioError);
      
      if (applioError.message.includes('6969') || applioError.message.includes('Timeout')) {
        res.status(503).json({ 
          error: 'Applio no disponible',
          details: 'Aseg√∫rate de que Applio est√© corriendo en el puerto 6969',
          suggestion: 'Abre la interfaz de Applio y verifica que est√© en el puerto 6969'
        });
      } else {
        res.status(500).json({ 
          error: 'Error generando audio con Applio',
          details: applioError.message
        });
      }
    }
    
  } catch (error) {
    console.error('‚ùå Error general:', error);
    res.status(500).json({ error: 'Error procesando solicitud' });
  }
});

// Ruta para subir archivo para transcripci√≥n
app.post('/upload-audio', upload.single('file'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No se recibi√≥ ning√∫n archivo' });
    }

    console.log(`üìÅ Archivo subido: ${req.file.filename}`);
    res.json({ 
      success: true, 
      filePath: req.file.path,
      originalName: req.file.originalname 
    });
    
  } catch (error) {
    console.error('‚ùå Error subiendo archivo:', error);
    res.status(500).json({ error: 'Error subiendo archivo: ' + error.message });
  }
});

// Ruta para obtener pistas de audio de un archivo
app.post('/get-audio-tracks', async (req, res) => {
  try {
    const { filePath } = req.body;
    
    if (!filePath) {
      return res.status(400).json({ error: 'Ruta del archivo requerida' });
    }

    console.log(`üéµ Obteniendo pistas de audio de: ${filePath}`);
    const tracks = await getAudioTracks(filePath);
    
    res.json({ tracks });
  } catch (error) {
    console.error('‚ùå Error obteniendo pistas de audio:', error);
    res.status(500).json({ error: 'Error obteniendo pistas de audio: ' + error.message });
  }
});

// Ruta para transcribir audio/video con Whisper LOCAL
app.post('/transcribe-audio-local', async (req, res) => {
  try {
    const { filePath, audioTrackIndex, modelSize = 'medium', language } = req.body;
    
    if (!filePath) {
      return res.status(400).json({ error: 'Ruta del archivo requerida' });
    }

    console.log(`üé§ Iniciando transcripci√≥n LOCAL de: ${filePath}`);
    console.log(`üîß Modelo: ${modelSize} | Idioma: ${language || 'auto-detectar'}`);
    if (audioTrackIndex !== undefined) {
      console.log(`üì° Usando pista de audio: ${audioTrackIndex}`);
    }

    // Importar din√°micamente el m√≥dulo local de Python
    const { spawn } = await import('child_process');
    
    // Crear script Python temporal para la transcripci√≥n
    const pythonScript = `
# -*- coding: utf-8 -*-
import sys
import json
import os
import subprocess
import tempfile
import shutil
from pathlib import Path

# Configurar codificaci√≥n UTF-8 para Windows
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.detach())
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.detach())

sys.path.append('${process.cwd().replace(/\\/g, '/')}')

from whisper_local import whisper_local

def extract_audio_from_mp4(input_path, output_path, track_index=None):
    """Extrae audio de MP4 usando FFmpeg"""
    try:
        cmd = ['ffmpeg', '-y', '-i', input_path]
        
        if track_index is not None:
            cmd.extend(['-map', f'0:a:{track_index}'])
        else:
            cmd.extend(['-map', '0:a:0'])  # Primera pista de audio por defecto
        
        cmd.extend(['-acodec', 'libmp3lame', '-ab', '192k', output_path])
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"Error FFmpeg: {result.stderr}")
            return False
        
        return True
        
    except Exception as e:
        print(f"Error extrayendo audio: {e}")
        return False

def main():
    file_path = r'${filePath}'
    audio_track_index = ${audioTrackIndex || 'None'}
    model_size = '${modelSize}'
    language = ${language ? `'${language}'` : 'None'}
    
    temp_audio_file = None
    
    try:
        # Verificar que el archivo existe
        if not os.path.exists(file_path):
            raise Exception(f"Archivo no encontrado: {file_path}")
        
        # Determinar archivo de audio a procesar
        if file_path.lower().endswith('.mp4'):
            # Extraer audio de MP4
            temp_audio_file = tempfile.mktemp(suffix='.mp3')
            print(f"Extrayendo audio de MP4 a: {temp_audio_file}")
            
            if not extract_audio_from_mp4(file_path, temp_audio_file, audio_track_index):
                raise Exception("Error extrayendo audio del MP4")
            
            audio_file = temp_audio_file
        else:
            # Usar archivo de audio directamente
            audio_file = file_path
        
        # Cargar modelo si no est√° cargado
        if not whisper_local.is_loaded or whisper_local.model_size != model_size:
            print(f"Cargando modelo {model_size}...")
            if not whisper_local.load_model(model_size):
                raise Exception(f"No se pudo cargar el modelo {model_size}")
        
        # Transcribir
        print(f"Transcribiendo archivo: {os.path.basename(audio_file)}")
        result = whisper_local.transcribe_audio(audio_file, language)
        
        if result['success']:
            print(json.dumps({
                'success': True,
                'transcript': result['transcript'],
                'language': result['language'],
                'duration': result['duration'],
                'model_info': result['model_info'],
                'stats': result['stats']
            }, ensure_ascii=False))
        else:
            print(json.dumps({
                'success': False,
                'error': result['error']
            }, ensure_ascii=False))
            
    except Exception as e:
        print(json.dumps({
            'success': False,
            'error': str(e)
        }, ensure_ascii=False))
    
    finally:
        # Limpiar archivo temporal de audio si se cre√≥
        if temp_audio_file and os.path.exists(temp_audio_file):
            try:
                os.unlink(temp_audio_file)
                print(f"Archivo temporal de audio eliminado: {temp_audio_file}")
            except:
                pass

if __name__ == '__main__':
    main()
`;

    // Escribir script temporal
    const tempScriptPath = path.join(process.cwd(), 'temp', `transcribe_${Date.now()}.py`);
    fs.mkdirSync(path.dirname(tempScriptPath), { recursive: true });
    fs.writeFileSync(tempScriptPath, pythonScript);

    // Ejecutar transcripci√≥n
    const pythonProcess = spawn('python', [tempScriptPath], {
      cwd: process.cwd(),
      stdio: ['pipe', 'pipe', 'pipe'],
      env: { 
        ...process.env, 
        PYTHONIOENCODING: 'utf-8',
        PYTHONUTF8: '1'
      }
    });

    let stdout = '';
    let stderr = '';

    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });

    pythonProcess.stderr.on('data', (data) => {
      stderr += data.toString();
    });

    pythonProcess.on('close', (code) => {
      // Limpiar script temporal
      try {
        fs.unlinkSync(tempScriptPath);
      } catch (e) {
        console.warn('No se pudo eliminar script temporal:', e.message);
      }

      // Limpiar archivo de audio temporal
      try {
        if (fs.existsSync(filePath)) {
          fs.unlinkSync(filePath);
          console.log(`üóëÔ∏è Archivo temporal eliminado: ${filePath}`);
        }
      } catch (cleanupError) {
        console.warn('‚ö†Ô∏è No se pudo eliminar archivo temporal:', cleanupError.message);
      }

      if (code !== 0) {
        console.error('‚ùå Error en transcripci√≥n local:', stderr);
        return res.status(500).json({ 
          error: 'Error en transcripci√≥n local: ' + stderr,
          stdout: stdout 
        });
      }

      try {
        // Buscar la √∫ltima l√≠nea que sea JSON v√°lido
        const lines = stdout.trim().split('\n');
        let result = null;
        
        for (let i = lines.length - 1; i >= 0; i--) {
          try {
            result = JSON.parse(lines[i]);
            break;
          } catch (e) {
            continue;
          }
        }

        if (!result) {
          throw new Error('No se pudo parsear el resultado');
        }

        if (result.success) {
          console.log(`‚úÖ Transcripci√≥n LOCAL completada. Caracteres: ${result.transcript.length}`);
          console.log(`üìä Velocidad: ${result.stats.processing_speed.toFixed(1)}x tiempo real`);
          console.log(`üåç Idioma: ${result.language}`);
          
          res.json({
            transcript: result.transcript,
            language: result.language,
            duration: result.duration,
            model_info: result.model_info,
            stats: result.stats,
            method: 'local'
          });
        } else {
          throw new Error(result.error);
        }

      } catch (parseError) {
        console.error('‚ùå Error parseando resultado:', parseError);
        console.log('Raw stdout:', stdout);
        res.status(500).json({ 
          error: 'Error parseando resultado de transcripci√≥n',
          stdout: stdout,
          stderr: stderr 
        });
      }
    });

    pythonProcess.on('error', (error) => {
      console.error('‚ùå Error ejecutando Python:', error);
      res.status(500).json({ error: 'Error ejecutando transcripci√≥n local: ' + error.message });
    });
    
  } catch (error) {
    console.error('‚ùå Error en transcripci√≥n local:', error);
    res.status(500).json({ error: 'Error en transcripci√≥n local: ' + error.message });
  }
});

// Ruta para obtener informaci√≥n del modelo local
app.get('/whisper-local-info', async (req, res) => {
  try {
    const { spawn } = await import('child_process');
    
    const pythonScript = `
import sys
import json
sys.path.append('${process.cwd().replace(/\\/g, '/')}')

from whisper_local import whisper_local

try:
    info = whisper_local.get_model_info()
    print(json.dumps(info))
except Exception as e:
    print(json.dumps({'error': str(e)}))
`;

    const tempScriptPath = path.join(process.cwd(), 'temp', `info_${Date.now()}.py`);
    fs.mkdirSync(path.dirname(tempScriptPath), { recursive: true });
    fs.writeFileSync(tempScriptPath, pythonScript);

    const pythonProcess = spawn('python', [tempScriptPath], {
      env: { 
        ...process.env, 
        PYTHONIOENCODING: 'utf-8',
        PYTHONUTF8: '1'
      }
    });
    let stdout = '';

    pythonProcess.stdout.on('data', (data) => {
      stdout += data.toString();
    });

    pythonProcess.on('close', (code) => {
      try {
        fs.unlinkSync(tempScriptPath);
      } catch (e) {}

      try {
        const result = JSON.parse(stdout.trim());
        res.json(result);
      } catch (error) {
        res.status(500).json({ error: 'Error obteniendo informaci√≥n del modelo' });
      }
    });

  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// Ruta para transcribir audio/video
app.post('/transcribe-audio', async (req, res) => {
  try {
    const { filePath, audioTrackIndex } = req.body;
    
    if (!filePath) {
      return res.status(400).json({ error: 'Ruta del archivo requerida' });
    }

    console.log(`üé§ Iniciando transcripci√≥n de: ${filePath}`);
    if (audioTrackIndex !== undefined) {
      console.log(`üì° Usando pista de audio: ${audioTrackIndex}`);
    }

    const transcript = await transcribeAudio({
      filePath,
      audioTrackIndex,
      onUploadProgress: (percent) => {
        // Aqu√≠ podr√≠as implementar WebSockets para progreso en tiempo real si quisieras
        console.log(`üìä Progreso de transcripci√≥n: ${percent}%`);
      }
    });

    console.log(`‚úÖ Transcripci√≥n completada. Caracteres: ${transcript.length}`);
    
    // Limpiar archivo temporal despu√©s de la transcripci√≥n
    try {
      if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
        console.log(`üóëÔ∏è Archivo temporal eliminado: ${filePath}`);
      }
    } catch (cleanupError) {
      console.warn('‚ö†Ô∏è No se pudo eliminar archivo temporal:', cleanupError.message);
    }
    
    res.json({ transcript });
    
  } catch (error) {
    console.error('‚ùå Error transcribiendo audio:', error);
    res.status(500).json({ error: 'Error transcribiendo audio: ' + error.message });
  }
});

// Endpoint para generar t√≠tulos, descripci√≥n y etiquetas para YouTube
app.post('/generate-youtube-metadata', async (req, res) => {
  try {
    const { topic, allSections } = req.body;

    if (!topic || !allSections || allSections.length === 0) {
      return res.status(400).json({ error: 'Tema y secciones requeridos' });
    }

    console.log(`üé¨ Generando metadata de YouTube para: ${topic}`);
    console.log(`üìù N√∫mero de secciones: ${allSections.length}`);

    // Combinar todas las secciones en un resumen
    const fullScript = allSections.join('\n\n--- SECCI√ìN ---\n\n');

    const prompt = `
Bas√°ndote en el siguiente tema y gui√≥n completo de un video de gaming, genera metadata optimizada para YouTube:

**TEMA:** ${topic}

**GUI√ìN COMPLETO:**
${fullScript}

Por favor genera:

1. **10 T√çTULOS CLICKBAIT** (cada uno en una l√≠nea, numerados):
   - Usa palabras que generen curiosidad como "QUE PASA CUANDO", "POR QUE", "HICE ESTO Y PASO ESTO", "NO VAS A CREER", "ESTO CAMBI√ì TODO"
   - Que sean pol√©micos pero relacionados al contenido
   - M√°ximo 60 caracteres cada uno
   - Incluye emojis relevantes

2. **DESCRIPCI√ìN PARA VIDEO** (optimizada para SEO):
   - Entre 150-300 palabras
   - Incluye palabras clave relevantes del gaming
   - Menciona el contenido principal del video
   - Incluye call-to-action para suscribirse
   - Formato atractivo con emojis

3. **25 ETIQUETAS** (separadas por comas):
   - Palabras clave relacionadas al tema
   - Tags de gaming populares
   - T√©rminos de b√∫squeda relevantes
   - Sin espacios en tags compuestos (usar guiones o camelCase)

Formato de respuesta:
**T√çTULOS CLICKBAIT:**
1. [t√≠tulo]
2. [t√≠tulo]
...

**DESCRIPCI√ìN:**
[descripci√≥n completa]

**ETIQUETAS:**
tag1, tag2, tag3, ...
    `;

    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash-exp",
      contents: [{
        role: "user",
        parts: [{ text: prompt }]
      }]
    });

    const responseText = response.text;

    console.log(`‚úÖ Metadata de YouTube generada exitosamente`);
    
    res.json({
      success: true,
      metadata: responseText,
      topic: topic,
      sectionsCount: allSections.length
    });

  } catch (error) {
    console.error('‚ùå Error generando metadata de YouTube:', error);
    res.status(500).json({ 
      success: false, 
      error: 'Error generando metadata de YouTube: ' + error.message 
    });
  }
});

app.listen(PORT, () => {
  console.log(`üöÄ Servidor corriendo en http://localhost:${PORT}`);
});
